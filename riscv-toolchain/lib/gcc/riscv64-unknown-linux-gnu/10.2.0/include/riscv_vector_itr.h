/* DO NOT EDIT, please edit generator instead.
   This file was generated by gen-vector-iterator with the command:
   $ ./gen-vector-iterator -usr-c > riscv_vector_itr.h  */
#ifndef _GCC_RISCV_VECTOR_H

#error "Never included riscv_vector_itr.h, plz include riscv_vector.h"

#endif

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector and integer types.  */
#define _RVV_INT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t) \
  MACRO (8, f4, 32, int8_t) \
  MACRO (8, f2, 16, int8_t) \
  MACRO (8, 1, 8, int8_t) \
  MACRO (8, 2, 4, int8_t) \
  MACRO (8, 4, 2, int8_t) \
  MACRO (8, 8, 1, int8_t) \
  MACRO (16, f4, 64, int16_t) \
  MACRO (16, f2, 32, int16_t) \
  MACRO (16, 1, 16, int16_t) \
  MACRO (16, 2, 8, int16_t) \
  MACRO (16, 4, 4, int16_t) \
  MACRO (16, 8, 2, int16_t) \
  MACRO (32, f2, 64, int32_t) \
  MACRO (32, 1, 32, int32_t) \
  MACRO (32, 2, 16, int32_t) \
  MACRO (32, 4, 8, int32_t) \
  MACRO (32, 8, 4, int32_t) \
  MACRO (64, 1, 64, int64_t) \
  MACRO (64, 2, 32, int64_t) \
  MACRO (64, 4, 16, int64_t) \
  MACRO (64, 8, 8, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding widening vector type.  */
#define _RVV_WINT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 16, f4, int16_t) \
  MACRO (8, f4, 32, int8_t, 16, f2, int16_t) \
  MACRO (8, f2, 16, int8_t, 16, 1, int16_t) \
  MACRO (8, 1, 8, int8_t, 16, 2, int16_t) \
  MACRO (8, 2, 4, int8_t, 16, 4, int16_t) \
  MACRO (8, 4, 2, int8_t, 16, 8, int16_t) \
  MACRO (16, f4, 64, int16_t, 32, f2, int32_t) \
  MACRO (16, f2, 32, int16_t, 32, 1, int32_t) \
  MACRO (16, 1, 16, int16_t, 32, 2, int32_t) \
  MACRO (16, 2, 8, int16_t, 32, 4, int32_t) \
  MACRO (16, 4, 4, int16_t, 32, 8, int32_t) \
  MACRO (32, f2, 64, int32_t, 64, 1, int64_t) \
  MACRO (32, 1, 32, int32_t, 64, 2, int64_t) \
  MACRO (32, 2, 16, int32_t, 64, 4, int64_t) \
  MACRO (32, 4, 8, int32_t, 64, 8, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_WINT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 16, f4, int16_t, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 16, f2, int16_t, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 16, 2, int16_t, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 16, 4, int16_t, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 16, 8, int16_t, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 32, f2, int32_t, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 32, 2, int32_t, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 32, 4, int32_t, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 32, 8, int32_t, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 64, 2, int64_t, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 64, 4, int64_t, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 64, 8, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding widening vector type but with LMUL 1.  */
#define _RVV_WRED_INT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 16, 1, int16_t) \
  MACRO (8, f4, 32, int8_t, 16, 1, int16_t) \
  MACRO (8, f2, 16, int8_t, 16, 1, int16_t) \
  MACRO (8, 1, 8, int8_t, 16, 1, int16_t) \
  MACRO (8, 2, 4, int8_t, 16, 1, int16_t) \
  MACRO (8, 4, 2, int8_t, 16, 1, int16_t) \
  MACRO (8, 8, 1, int8_t, 16, 1, int16_t) \
  MACRO (16, f4, 64, int16_t, 32, 1, int32_t) \
  MACRO (16, f2, 32, int16_t, 32, 1, int32_t) \
  MACRO (16, 1, 16, int16_t, 32, 1, int32_t) \
  MACRO (16, 2, 8, int16_t, 32, 1, int32_t) \
  MACRO (16, 4, 4, int16_t, 32, 1, int32_t) \
  MACRO (16, 8, 2, int16_t, 32, 1, int32_t) \
  MACRO (32, f2, 64, int32_t, 64, 1, int64_t) \
  MACRO (32, 1, 32, int32_t, 64, 1, int64_t) \
  MACRO (32, 2, 16, int32_t, 64, 1, int64_t) \
  MACRO (32, 4, 8, int32_t, 64, 1, int64_t) \
  MACRO (32, 8, 4, int32_t, 64, 1, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_WRED_INT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 16, 1, int16_t, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 64, 1, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding quad widening vector type.  */
#define _RVV_QINT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 32, f2, int32_t) \
  MACRO (8, f4, 32, int8_t, 32, 1, int32_t) \
  MACRO (8, f2, 16, int8_t, 32, 2, int32_t) \
  MACRO (8, 1, 8, int8_t, 32, 4, int32_t) \
  MACRO (8, 2, 4, int8_t, 32, 8, int32_t) \
  MACRO (16, f4, 64, int16_t, 64, 1, int64_t) \
  MACRO (16, f2, 32, int16_t, 64, 2, int64_t) \
  MACRO (16, 1, 16, int16_t, 64, 4, int64_t) \
  MACRO (16, 2, 8, int16_t, 64, 8, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_QINT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 32, f2, int32_t, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 32, 1, int32_t, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 32, 2, int32_t, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 32, 4, int32_t, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 32, 8, int32_t, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 64, 2, int64_t, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 64, 4, int64_t, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 64, 8, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer modes, and info for
   corresponding eightfold widening vector type.  */
#define _RVV_EINT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 64, 1, int64_t) \
  MACRO (8, f4, 32, int8_t, 64, 2, int64_t) \
  MACRO (8, f2, 16, int8_t, 64, 4, int64_t) \
  MACRO (8, 1, 8, int8_t, 64, 8, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_EINT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 64, 1, int64_t, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 64, 2, int64_t, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 64, 4, int64_t, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 64, 8, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector and floating point modes.  */
#define _RVV_FLOAT_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t) \
  MACRO (16, f2, 32, __float16_t) \
  MACRO (16, 1, 16, __float16_t) \
  MACRO (16, 2, 8, __float16_t) \
  MACRO (16, 4, 4, __float16_t) \
  MACRO (16, 8, 2, __float16_t) \
  MACRO (32, f2, 64, __float32_t) \
  MACRO (32, 1, 32, __float32_t) \
  MACRO (32, 2, 16, __float32_t) \
  MACRO (32, 4, 8, __float32_t) \
  MACRO (32, 8, 4, __float32_t) \
  MACRO (64, 1, 64, __float64_t) \
  MACRO (64, 2, 32, __float64_t) \
  MACRO (64, 4, 16, __float64_t) \
  MACRO (64, 8, 8, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, floating modes, and info for
   corresponding widening vector type.  */
#define _RVV_WFLOAT_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t, 32, f2, __float32_t) \
  MACRO (16, f2, 32, __float16_t, 32, 1, __float32_t) \
  MACRO (16, 1, 16, __float16_t, 32, 2, __float32_t) \
  MACRO (16, 2, 8, __float16_t, 32, 4, __float32_t) \
  MACRO (16, 4, 4, __float16_t, 32, 8, __float32_t) \
  MACRO (32, f2, 64, __float32_t, 64, 1, __float64_t) \
  MACRO (32, 1, 32, __float32_t, 64, 2, __float64_t) \
  MACRO (32, 2, 16, __float32_t, 64, 4, __float64_t) \
  MACRO (32, 4, 8, __float32_t, 64, 8, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_WFLOAT_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, 32, f2, __float32_t, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 32, 2, __float32_t, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 32, 4, __float32_t, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 32, 8, __float32_t, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 64, 2, __float64_t, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 64, 4, __float64_t, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 64, 8, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, floating types, and info for
   corresponding widening vector type but with LMUL 1.  */
#define _RVV_WRED_FLOAT_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t, 32, 1, __float32_t) \
  MACRO (16, f2, 32, __float16_t, 32, 1, __float32_t) \
  MACRO (16, 1, 16, __float16_t, 32, 1, __float32_t) \
  MACRO (16, 2, 8, __float16_t, 32, 1, __float32_t) \
  MACRO (16, 4, 4, __float16_t, 32, 1, __float32_t) \
  MACRO (16, 8, 2, __float16_t, 32, 1, __float32_t) \
  MACRO (32, f2, 64, __float32_t, 64, 1, __float64_t) \
  MACRO (32, 1, 32, __float32_t, 64, 1, __float64_t) \
  MACRO (32, 2, 16, __float32_t, 64, 1, __float64_t) \
  MACRO (32, 4, 8, __float32_t, 64, 1, __float64_t) \
  MACRO (32, 8, 4, __float32_t, 64, 1, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_WRED_FLOAT_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 32, 1, __float32_t, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 64, 1, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding integer and vector type.  */
#define _RVV_FLOAT_INT_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t, int16_t) \
  MACRO (16, f2, 32, __float16_t, int16_t) \
  MACRO (16, 1, 16, __float16_t, int16_t) \
  MACRO (16, 2, 8, __float16_t, int16_t) \
  MACRO (16, 4, 4, __float16_t, int16_t) \
  MACRO (16, 8, 2, __float16_t, int16_t) \
  MACRO (32, f2, 64, __float32_t, int32_t) \
  MACRO (32, 1, 32, __float32_t, int32_t) \
  MACRO (32, 2, 16, __float32_t, int32_t) \
  MACRO (32, 4, 8, __float32_t, int32_t) \
  MACRO (32, 8, 4, __float32_t, int32_t) \
  MACRO (64, 1, 64, __float64_t, int64_t) \
  MACRO (64, 2, 32, __float64_t, int64_t) \
  MACRO (64, 4, 16, __float64_t, int64_t) \
  MACRO (64, 8, 8, __float64_t, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_INT_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, int16_t, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, int32_t, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, int32_t, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, int64_t, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, int64_t, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding integer and vector type.  */
#define _RVV_INT_INDEX_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 8, f8) \
  MACRO (8, f8, 64, int8_t, 16, f4) \
  MACRO (8, f8, 64, int8_t, 32, f2) \
  MACRO (8, f8, 64, int8_t, 64, 1) \
  MACRO (8, f4, 32, int8_t, 8, f4) \
  MACRO (8, f4, 32, int8_t, 16, f2) \
  MACRO (8, f4, 32, int8_t, 32, 1) \
  MACRO (8, f4, 32, int8_t, 64, 2) \
  MACRO (8, f2, 16, int8_t, 8, f2) \
  MACRO (8, f2, 16, int8_t, 16, 1) \
  MACRO (8, f2, 16, int8_t, 32, 2) \
  MACRO (8, f2, 16, int8_t, 64, 4) \
  MACRO (8, 1, 8, int8_t, 8, 1) \
  MACRO (8, 1, 8, int8_t, 16, 2) \
  MACRO (8, 1, 8, int8_t, 32, 4) \
  MACRO (8, 1, 8, int8_t, 64, 8) \
  MACRO (8, 2, 4, int8_t, 8, 2) \
  MACRO (8, 2, 4, int8_t, 16, 4) \
  MACRO (8, 2, 4, int8_t, 32, 8) \
  MACRO (8, 4, 2, int8_t, 8, 4) \
  MACRO (8, 4, 2, int8_t, 16, 8) \
  MACRO (8, 8, 1, int8_t, 8, 8) \
  MACRO (16, f4, 64, int16_t, 8, f8) \
  MACRO (16, f4, 64, int16_t, 16, f4) \
  MACRO (16, f4, 64, int16_t, 32, f2) \
  MACRO (16, f4, 64, int16_t, 64, 1) \
  MACRO (16, f2, 32, int16_t, 8, f4) \
  MACRO (16, f2, 32, int16_t, 16, f2) \
  MACRO (16, f2, 32, int16_t, 32, 1) \
  MACRO (16, f2, 32, int16_t, 64, 2) \
  MACRO (16, 1, 16, int16_t, 8, f2) \
  MACRO (16, 1, 16, int16_t, 16, 1) \
  MACRO (16, 1, 16, int16_t, 32, 2) \
  MACRO (16, 1, 16, int16_t, 64, 4) \
  MACRO (16, 2, 8, int16_t, 8, 1) \
  MACRO (16, 2, 8, int16_t, 16, 2) \
  MACRO (16, 2, 8, int16_t, 32, 4) \
  MACRO (16, 2, 8, int16_t, 64, 8) \
  MACRO (16, 4, 4, int16_t, 8, 2) \
  MACRO (16, 4, 4, int16_t, 16, 4) \
  MACRO (16, 4, 4, int16_t, 32, 8) \
  MACRO (16, 8, 2, int16_t, 8, 4) \
  MACRO (16, 8, 2, int16_t, 16, 8) \
  MACRO (32, f2, 64, int32_t, 8, f8) \
  MACRO (32, f2, 64, int32_t, 16, f4) \
  MACRO (32, f2, 64, int32_t, 32, f2) \
  MACRO (32, f2, 64, int32_t, 64, 1) \
  MACRO (32, 1, 32, int32_t, 8, f4) \
  MACRO (32, 1, 32, int32_t, 16, f2) \
  MACRO (32, 1, 32, int32_t, 32, 1) \
  MACRO (32, 1, 32, int32_t, 64, 2) \
  MACRO (32, 2, 16, int32_t, 8, f2) \
  MACRO (32, 2, 16, int32_t, 16, 1) \
  MACRO (32, 2, 16, int32_t, 32, 2) \
  MACRO (32, 2, 16, int32_t, 64, 4) \
  MACRO (32, 4, 8, int32_t, 8, 1) \
  MACRO (32, 4, 8, int32_t, 16, 2) \
  MACRO (32, 4, 8, int32_t, 32, 4) \
  MACRO (32, 4, 8, int32_t, 64, 8) \
  MACRO (32, 8, 4, int32_t, 8, 2) \
  MACRO (32, 8, 4, int32_t, 16, 4) \
  MACRO (32, 8, 4, int32_t, 32, 8) \
  MACRO (64, 1, 64, int64_t, 8, f8) \
  MACRO (64, 1, 64, int64_t, 16, f4) \
  MACRO (64, 1, 64, int64_t, 32, f2) \
  MACRO (64, 1, 64, int64_t, 64, 1) \
  MACRO (64, 2, 32, int64_t, 8, f4) \
  MACRO (64, 2, 32, int64_t, 16, f2) \
  MACRO (64, 2, 32, int64_t, 32, 1) \
  MACRO (64, 2, 32, int64_t, 64, 2) \
  MACRO (64, 4, 16, int64_t, 8, f2) \
  MACRO (64, 4, 16, int64_t, 16, 1) \
  MACRO (64, 4, 16, int64_t, 32, 2) \
  MACRO (64, 4, 16, int64_t, 64, 4) \
  MACRO (64, 8, 8, int64_t, 8, 1) \
  MACRO (64, 8, 8, int64_t, 16, 2) \
  MACRO (64, 8, 8, int64_t, 32, 4) \
  MACRO (64, 8, 8, int64_t, 64, 8) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 16, f4, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 32, f2, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 64, 1, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 16, f2, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 32, 1, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 64, 2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 16, 1, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 32, 2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 64, 4, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 16, 8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 8, f8, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 32, f2, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 64, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 8, f4, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 32, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 64, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 8, f2, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 32, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 8, 4, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 8, f8, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 16, f4, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 64, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 8, f4, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 16, f2, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 8, f2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 8, 2, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 16, 4, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 32, 8, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 8, f8, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 16, f4, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 32, f2, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 8, f4, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 16, f2, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 8, f2, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 8, 1, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 16, 2, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 32, 4, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 64, 8, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point types, and info for
   corresponding floating point and vector type.  */
#define _RVV_FLOAT_INDEX_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t, 8, f8) \
  MACRO (16, f4, 64, __float16_t, 16, f4) \
  MACRO (16, f4, 64, __float16_t, 32, f2) \
  MACRO (16, f4, 64, __float16_t, 64, 1) \
  MACRO (16, f2, 32, __float16_t, 8, f4) \
  MACRO (16, f2, 32, __float16_t, 16, f2) \
  MACRO (16, f2, 32, __float16_t, 32, 1) \
  MACRO (16, f2, 32, __float16_t, 64, 2) \
  MACRO (16, 1, 16, __float16_t, 8, f2) \
  MACRO (16, 1, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 16, __float16_t, 64, 4) \
  MACRO (16, 2, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 8, __float16_t, 64, 8) \
  MACRO (16, 4, 4, __float16_t, 8, 2) \
  MACRO (16, 4, 4, __float16_t, 16, 4) \
  MACRO (16, 4, 4, __float16_t, 32, 8) \
  MACRO (16, 8, 2, __float16_t, 8, 4) \
  MACRO (16, 8, 2, __float16_t, 16, 8) \
  MACRO (32, f2, 64, __float32_t, 8, f8) \
  MACRO (32, f2, 64, __float32_t, 16, f4) \
  MACRO (32, f2, 64, __float32_t, 32, f2) \
  MACRO (32, f2, 64, __float32_t, 64, 1) \
  MACRO (32, 1, 32, __float32_t, 8, f4) \
  MACRO (32, 1, 32, __float32_t, 16, f2) \
  MACRO (32, 1, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 32, __float32_t, 64, 2) \
  MACRO (32, 2, 16, __float32_t, 8, f2) \
  MACRO (32, 2, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 16, __float32_t, 64, 4) \
  MACRO (32, 4, 8, __float32_t, 8, 1) \
  MACRO (32, 4, 8, __float32_t, 16, 2) \
  MACRO (32, 4, 8, __float32_t, 32, 4) \
  MACRO (32, 4, 8, __float32_t, 64, 8) \
  MACRO (32, 8, 4, __float32_t, 8, 2) \
  MACRO (32, 8, 4, __float32_t, 16, 4) \
  MACRO (32, 8, 4, __float32_t, 32, 8) \
  MACRO (64, 1, 64, __float64_t, 8, f8) \
  MACRO (64, 1, 64, __float64_t, 16, f4) \
  MACRO (64, 1, 64, __float64_t, 32, f2) \
  MACRO (64, 1, 64, __float64_t, 64, 1) \
  MACRO (64, 2, 32, __float64_t, 8, f4) \
  MACRO (64, 2, 32, __float64_t, 16, f2) \
  MACRO (64, 2, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 32, __float64_t, 64, 2) \
  MACRO (64, 4, 16, __float64_t, 8, f2) \
  MACRO (64, 4, 16, __float64_t, 16, 1) \
  MACRO (64, 4, 16, __float64_t, 32, 2) \
  MACRO (64, 4, 16, __float64_t, 64, 4) \
  MACRO (64, 8, 8, __float64_t, 8, 1) \
  MACRO (64, 8, 8, __float64_t, 16, 2) \
  MACRO (64, 8, 8, __float64_t, 32, 4) \
  MACRO (64, 8, 8, __float64_t, 64, 8) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, 8, f8, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 32, f2, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 64, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 8, f4, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 32, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 64, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 8, f2, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 32, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 8, 4, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 8, f8, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 16, f4, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 64, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 8, f4, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 16, f2, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 8, f2, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 8, 2, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 16, 4, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 32, 8, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 8, f8, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 16, f4, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 32, f2, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 8, f4, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 16, f2, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 8, f2, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 8, 1, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 16, 2, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 32, 4, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 64, 8, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding integer and vector type.  */
#define _RVV_INT_REINT_ITERATOR(MACRO) \
  MACRO (8, f8, 64, int8_t, 8, f4) \
  MACRO (8, f8, 64, int8_t, 8, f2) \
  MACRO (8, f8, 64, int8_t, 8, 1) \
  MACRO (8, f8, 64, int8_t, 8, 2) \
  MACRO (8, f8, 64, int8_t, 8, 4) \
  MACRO (8, f8, 64, int8_t, 8, 8) \
  MACRO (8, f4, 32, int8_t, 16, f4) \
  MACRO (8, f4, 32, int8_t, 8, f8) \
  MACRO (8, f4, 32, int8_t, 8, f2) \
  MACRO (8, f4, 32, int8_t, 8, 1) \
  MACRO (8, f4, 32, int8_t, 8, 2) \
  MACRO (8, f4, 32, int8_t, 8, 4) \
  MACRO (8, f4, 32, int8_t, 8, 8) \
  MACRO (8, f2, 16, int8_t, 16, f2) \
  MACRO (8, f2, 16, int8_t, 32, f2) \
  MACRO (8, f2, 16, int8_t, 8, f8) \
  MACRO (8, f2, 16, int8_t, 8, f4) \
  MACRO (8, f2, 16, int8_t, 8, 1) \
  MACRO (8, f2, 16, int8_t, 8, 2) \
  MACRO (8, f2, 16, int8_t, 8, 4) \
  MACRO (8, f2, 16, int8_t, 8, 8) \
  MACRO (8, 1, 8, int8_t, 16, 1) \
  MACRO (8, 1, 8, int8_t, 32, 1) \
  MACRO (8, 1, 8, int8_t, 64, 1) \
  MACRO (8, 1, 8, int8_t, 8, f8) \
  MACRO (8, 1, 8, int8_t, 8, f4) \
  MACRO (8, 1, 8, int8_t, 8, f2) \
  MACRO (8, 1, 8, int8_t, 8, 2) \
  MACRO (8, 1, 8, int8_t, 8, 4) \
  MACRO (8, 1, 8, int8_t, 8, 8) \
  MACRO (8, 2, 4, int8_t, 16, 2) \
  MACRO (8, 2, 4, int8_t, 32, 2) \
  MACRO (8, 2, 4, int8_t, 64, 2) \
  MACRO (8, 2, 4, int8_t, 8, f8) \
  MACRO (8, 2, 4, int8_t, 8, f4) \
  MACRO (8, 2, 4, int8_t, 8, f2) \
  MACRO (8, 2, 4, int8_t, 8, 1) \
  MACRO (8, 2, 4, int8_t, 8, 4) \
  MACRO (8, 2, 4, int8_t, 8, 8) \
  MACRO (8, 4, 2, int8_t, 16, 4) \
  MACRO (8, 4, 2, int8_t, 32, 4) \
  MACRO (8, 4, 2, int8_t, 64, 4) \
  MACRO (8, 4, 2, int8_t, 8, f8) \
  MACRO (8, 4, 2, int8_t, 8, f4) \
  MACRO (8, 4, 2, int8_t, 8, f2) \
  MACRO (8, 4, 2, int8_t, 8, 1) \
  MACRO (8, 4, 2, int8_t, 8, 2) \
  MACRO (8, 4, 2, int8_t, 8, 8) \
  MACRO (8, 8, 1, int8_t, 16, 8) \
  MACRO (8, 8, 1, int8_t, 32, 8) \
  MACRO (8, 8, 1, int8_t, 64, 8) \
  MACRO (8, 8, 1, int8_t, 8, f8) \
  MACRO (8, 8, 1, int8_t, 8, f4) \
  MACRO (8, 8, 1, int8_t, 8, f2) \
  MACRO (8, 8, 1, int8_t, 8, 1) \
  MACRO (8, 8, 1, int8_t, 8, 2) \
  MACRO (8, 8, 1, int8_t, 8, 4) \
  MACRO (16, f4, 64, int16_t, 8, f4) \
  MACRO (16, f4, 64, int16_t, 16, f2) \
  MACRO (16, f4, 64, int16_t, 16, 1) \
  MACRO (16, f4, 64, int16_t, 16, 2) \
  MACRO (16, f4, 64, int16_t, 16, 4) \
  MACRO (16, f4, 64, int16_t, 16, 8) \
  MACRO (16, f2, 32, int16_t, 8, f2) \
  MACRO (16, f2, 32, int16_t, 32, f2) \
  MACRO (16, f2, 32, int16_t, 16, f4) \
  MACRO (16, f2, 32, int16_t, 16, 1) \
  MACRO (16, f2, 32, int16_t, 16, 2) \
  MACRO (16, f2, 32, int16_t, 16, 4) \
  MACRO (16, f2, 32, int16_t, 16, 8) \
  MACRO (16, 1, 16, int16_t, 8, 1) \
  MACRO (16, 1, 16, int16_t, 32, 1) \
  MACRO (16, 1, 16, int16_t, 64, 1) \
  MACRO (16, 1, 16, int16_t, 16, f4) \
  MACRO (16, 1, 16, int16_t, 16, f2) \
  MACRO (16, 1, 16, int16_t, 16, 2) \
  MACRO (16, 1, 16, int16_t, 16, 4) \
  MACRO (16, 1, 16, int16_t, 16, 8) \
  MACRO (16, 2, 8, int16_t, 8, 2) \
  MACRO (16, 2, 8, int16_t, 32, 2) \
  MACRO (16, 2, 8, int16_t, 64, 2) \
  MACRO (16, 2, 8, int16_t, 16, f4) \
  MACRO (16, 2, 8, int16_t, 16, f2) \
  MACRO (16, 2, 8, int16_t, 16, 1) \
  MACRO (16, 2, 8, int16_t, 16, 4) \
  MACRO (16, 2, 8, int16_t, 16, 8) \
  MACRO (16, 4, 4, int16_t, 8, 4) \
  MACRO (16, 4, 4, int16_t, 32, 4) \
  MACRO (16, 4, 4, int16_t, 64, 4) \
  MACRO (16, 4, 4, int16_t, 16, f4) \
  MACRO (16, 4, 4, int16_t, 16, f2) \
  MACRO (16, 4, 4, int16_t, 16, 1) \
  MACRO (16, 4, 4, int16_t, 16, 2) \
  MACRO (16, 4, 4, int16_t, 16, 8) \
  MACRO (16, 8, 2, int16_t, 8, 8) \
  MACRO (16, 8, 2, int16_t, 32, 8) \
  MACRO (16, 8, 2, int16_t, 64, 8) \
  MACRO (16, 8, 2, int16_t, 16, f4) \
  MACRO (16, 8, 2, int16_t, 16, f2) \
  MACRO (16, 8, 2, int16_t, 16, 1) \
  MACRO (16, 8, 2, int16_t, 16, 2) \
  MACRO (16, 8, 2, int16_t, 16, 4) \
  MACRO (32, f2, 64, int32_t, 8, f2) \
  MACRO (32, f2, 64, int32_t, 16, f2) \
  MACRO (32, f2, 64, int32_t, 32, 1) \
  MACRO (32, f2, 64, int32_t, 32, 2) \
  MACRO (32, f2, 64, int32_t, 32, 4) \
  MACRO (32, f2, 64, int32_t, 32, 8) \
  MACRO (32, 1, 32, int32_t, 8, 1) \
  MACRO (32, 1, 32, int32_t, 16, 1) \
  MACRO (32, 1, 32, int32_t, 64, 1) \
  MACRO (32, 1, 32, int32_t, 32, f2) \
  MACRO (32, 1, 32, int32_t, 32, 2) \
  MACRO (32, 1, 32, int32_t, 32, 4) \
  MACRO (32, 1, 32, int32_t, 32, 8) \
  MACRO (32, 2, 16, int32_t, 8, 2) \
  MACRO (32, 2, 16, int32_t, 16, 2) \
  MACRO (32, 2, 16, int32_t, 64, 2) \
  MACRO (32, 2, 16, int32_t, 32, f2) \
  MACRO (32, 2, 16, int32_t, 32, 1) \
  MACRO (32, 2, 16, int32_t, 32, 4) \
  MACRO (32, 2, 16, int32_t, 32, 8) \
  MACRO (32, 4, 8, int32_t, 8, 4) \
  MACRO (32, 4, 8, int32_t, 16, 4) \
  MACRO (32, 4, 8, int32_t, 64, 4) \
  MACRO (32, 4, 8, int32_t, 32, f2) \
  MACRO (32, 4, 8, int32_t, 32, 1) \
  MACRO (32, 4, 8, int32_t, 32, 2) \
  MACRO (32, 4, 8, int32_t, 32, 8) \
  MACRO (32, 8, 4, int32_t, 8, 8) \
  MACRO (32, 8, 4, int32_t, 16, 8) \
  MACRO (32, 8, 4, int32_t, 64, 8) \
  MACRO (32, 8, 4, int32_t, 32, f2) \
  MACRO (32, 8, 4, int32_t, 32, 1) \
  MACRO (32, 8, 4, int32_t, 32, 2) \
  MACRO (32, 8, 4, int32_t, 32, 4) \
  MACRO (64, 1, 64, int64_t, 8, 1) \
  MACRO (64, 1, 64, int64_t, 16, 1) \
  MACRO (64, 1, 64, int64_t, 32, 1) \
  MACRO (64, 1, 64, int64_t, 64, 2) \
  MACRO (64, 1, 64, int64_t, 64, 4) \
  MACRO (64, 1, 64, int64_t, 64, 8) \
  MACRO (64, 2, 32, int64_t, 8, 2) \
  MACRO (64, 2, 32, int64_t, 16, 2) \
  MACRO (64, 2, 32, int64_t, 32, 2) \
  MACRO (64, 2, 32, int64_t, 64, 1) \
  MACRO (64, 2, 32, int64_t, 64, 4) \
  MACRO (64, 2, 32, int64_t, 64, 8) \
  MACRO (64, 4, 16, int64_t, 8, 4) \
  MACRO (64, 4, 16, int64_t, 16, 4) \
  MACRO (64, 4, 16, int64_t, 32, 4) \
  MACRO (64, 4, 16, int64_t, 64, 1) \
  MACRO (64, 4, 16, int64_t, 64, 2) \
  MACRO (64, 4, 16, int64_t, 64, 8) \
  MACRO (64, 8, 8, int64_t, 8, 8) \
  MACRO (64, 8, 8, int64_t, 16, 8) \
  MACRO (64, 8, 8, int64_t, 32, 8) \
  MACRO (64, 8, 8, int64_t, 64, 1) \
  MACRO (64, 8, 8, int64_t, 64, 2) \
  MACRO (64, 8, 8, int64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_REINT_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, f8, 64, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, f8, 64, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 16, f4, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, f4, 32, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 16, f2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 32, f2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, f2, 16, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 16, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 32, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 64, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, 1, 8, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 32, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 64, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, 2, 4, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 64, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 4, 2, int8_t, 8, 8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 16, 8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, f8, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, f4, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, f2, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 8, 1, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 8, f4, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, f4, 64, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 8, f2, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 32, f2, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, f2, 32, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 32, 1, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 64, 1, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 1, 16, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 64, 2, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 8, 4, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 4, 4, int16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 8, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 32, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 8, 2, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 8, f2, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 16, f2, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, f2, 64, int32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 64, 1, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 1, 32, int32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 8, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 2, 16, int32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 8, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 16, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 4, 8, int32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 8, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 16, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 8, 4, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 8, 1, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 64, int64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 8, 2, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 16, 2, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 2, 32, int64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 8, 4, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 16, 4, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 32, 4, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, int64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 8, 8, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 16, 8, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 32, 8, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 8, 8, int64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point types, and info for
   corresponding floating and vector type.  */
#define _RVV_FLOAT_REINT_ITERATOR(MACRO) \
  MACRO (16, f4, 64, __float16_t, 16, f2) \
  MACRO (16, f4, 64, __float16_t, 16, 1) \
  MACRO (16, f4, 64, __float16_t, 16, 2) \
  MACRO (16, f4, 64, __float16_t, 16, 4) \
  MACRO (16, f4, 64, __float16_t, 16, 8) \
  MACRO (16, f2, 32, __float16_t, 16, f4) \
  MACRO (16, f2, 32, __float16_t, 16, 1) \
  MACRO (16, f2, 32, __float16_t, 16, 2) \
  MACRO (16, f2, 32, __float16_t, 16, 4) \
  MACRO (16, f2, 32, __float16_t, 16, 8) \
  MACRO (16, 1, 16, __float16_t, 16, f4) \
  MACRO (16, 1, 16, __float16_t, 16, f2) \
  MACRO (16, 1, 16, __float16_t, 16, 2) \
  MACRO (16, 1, 16, __float16_t, 16, 4) \
  MACRO (16, 1, 16, __float16_t, 16, 8) \
  MACRO (16, 2, 8, __float16_t, 16, f4) \
  MACRO (16, 2, 8, __float16_t, 16, f2) \
  MACRO (16, 2, 8, __float16_t, 16, 1) \
  MACRO (16, 2, 8, __float16_t, 16, 4) \
  MACRO (16, 2, 8, __float16_t, 16, 8) \
  MACRO (16, 4, 4, __float16_t, 16, f4) \
  MACRO (16, 4, 4, __float16_t, 16, f2) \
  MACRO (16, 4, 4, __float16_t, 16, 1) \
  MACRO (16, 4, 4, __float16_t, 16, 2) \
  MACRO (16, 4, 4, __float16_t, 16, 8) \
  MACRO (16, 8, 2, __float16_t, 16, f4) \
  MACRO (16, 8, 2, __float16_t, 16, f2) \
  MACRO (16, 8, 2, __float16_t, 16, 1) \
  MACRO (16, 8, 2, __float16_t, 16, 2) \
  MACRO (16, 8, 2, __float16_t, 16, 4) \
  MACRO (32, f2, 64, __float32_t, 32, 1) \
  MACRO (32, f2, 64, __float32_t, 32, 2) \
  MACRO (32, f2, 64, __float32_t, 32, 4) \
  MACRO (32, f2, 64, __float32_t, 32, 8) \
  MACRO (32, 1, 32, __float32_t, 32, f2) \
  MACRO (32, 1, 32, __float32_t, 32, 2) \
  MACRO (32, 1, 32, __float32_t, 32, 4) \
  MACRO (32, 1, 32, __float32_t, 32, 8) \
  MACRO (32, 2, 16, __float32_t, 32, f2) \
  MACRO (32, 2, 16, __float32_t, 32, 1) \
  MACRO (32, 2, 16, __float32_t, 32, 4) \
  MACRO (32, 2, 16, __float32_t, 32, 8) \
  MACRO (32, 4, 8, __float32_t, 32, f2) \
  MACRO (32, 4, 8, __float32_t, 32, 1) \
  MACRO (32, 4, 8, __float32_t, 32, 2) \
  MACRO (32, 4, 8, __float32_t, 32, 8) \
  MACRO (32, 8, 4, __float32_t, 32, f2) \
  MACRO (32, 8, 4, __float32_t, 32, 1) \
  MACRO (32, 8, 4, __float32_t, 32, 2) \
  MACRO (32, 8, 4, __float32_t, 32, 4) \
  MACRO (64, 1, 64, __float64_t, 64, 2) \
  MACRO (64, 1, 64, __float64_t, 64, 4) \
  MACRO (64, 1, 64, __float64_t, 64, 8) \
  MACRO (64, 2, 32, __float64_t, 64, 1) \
  MACRO (64, 2, 32, __float64_t, 64, 4) \
  MACRO (64, 2, 32, __float64_t, 64, 8) \
  MACRO (64, 4, 16, __float64_t, 64, 1) \
  MACRO (64, 4, 16, __float64_t, 64, 2) \
  MACRO (64, 4, 16, __float64_t, 64, 8) \
  MACRO (64, 8, 8, __float64_t, 64, 1) \
  MACRO (64, 8, 8, __float64_t, 64, 2) \
  MACRO (64, 8, 8, __float64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_REINT_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, f4, 64, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, f4, 64, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, f2, 32, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 1, 16, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 2, 8, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 4, 4, __float16_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, f4, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, f2, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 8, 2, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, f2, 64, __float32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 1, 32, __float32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 2, 16, __float32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 4, 8, __float32_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 32, f2, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 8, 4, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 64, __float64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 2, 32, __float64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 16, __float64_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 8, 8, __float64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, integer types, and info for
   corresponding widening vector LMUL.  */
#define _RVV_INT_WLMUL_ITERATOR(MACRO) \
  MACRO (8, 2, 1, 8, int8_t) \
  MACRO (8, 4, 2, 4, int8_t) \
  MACRO (8, 8, 4, 2, int8_t) \
  MACRO (16, 2, 1, 16, int16_t) \
  MACRO (16, 4, 2, 8, int16_t) \
  MACRO (16, 8, 4, 4, int16_t) \
  MACRO (32, 2, 1, 32, int32_t) \
  MACRO (32, 4, 2, 16, int32_t) \
  MACRO (32, 8, 4, 8, int32_t) \
  MACRO (64, 2, 1, 64, int64_t) \
  MACRO (64, 4, 2, 32, int64_t) \
  MACRO (64, 8, 4, 16, int64_t) \
  MACRO (8, 4, 1, 8, int8_t) \
  MACRO (8, 8, 2, 4, int8_t) \
  MACRO (16, 4, 1, 16, int16_t) \
  MACRO (16, 8, 2, 8, int16_t) \
  MACRO (32, 4, 1, 32, int32_t) \
  MACRO (32, 8, 2, 16, int32_t) \
  MACRO (64, 4, 1, 64, int64_t) \
  MACRO (64, 8, 2, 32, int64_t) \
  MACRO (8, 8, 1, 8, int8_t) \
  MACRO (16, 8, 1, 16, int16_t) \
  MACRO (32, 8, 1, 32, int32_t) \
  MACRO (64, 8, 1, 64, int64_t) \

/* An iterator to call a macro with every supported SEW, LMUL and MLEN value,
   along with its corresponding vector, float types, and info for
   corresponding widening vector LMUL.  */
#define _RVV_FLOAT_WLMUL_ITERATOR(MACRO) \
  MACRO (16, 2, 1, 16, __float16_t) \
  MACRO (16, 4, 2, 8, __float16_t) \
  MACRO (16, 8, 4, 4, __float16_t) \
  MACRO (32, 2, 1, 32, __float32_t) \
  MACRO (32, 4, 2, 16, __float32_t) \
  MACRO (32, 8, 4, 8, __float32_t) \
  MACRO (64, 2, 1, 64, __float64_t) \
  MACRO (64, 4, 2, 32, __float64_t) \
  MACRO (64, 8, 4, 16, __float64_t) \
  MACRO (16, 4, 1, 16, __float16_t) \
  MACRO (16, 8, 2, 8, __float16_t) \
  MACRO (32, 4, 1, 32, __float32_t) \
  MACRO (32, 8, 2, 16, __float32_t) \
  MACRO (64, 4, 1, 64, __float64_t) \
  MACRO (64, 8, 2, 32, __float64_t) \
  MACRO (16, 8, 1, 16, __float16_t) \
  MACRO (32, 8, 1, 32, __float32_t) \
  MACRO (64, 8, 1, 64, __float64_t) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_ITERATOR(MACRO) \
  MACRO (8, 1, 2, 8, int8_t) \
  MACRO (8, 1, 3, 8, int8_t) \
  MACRO (8, 1, 4, 8, int8_t) \
  MACRO (8, 1, 5, 8, int8_t) \
  MACRO (8, 1, 6, 8, int8_t) \
  MACRO (8, 1, 7, 8, int8_t) \
  MACRO (8, 1, 8, 8, int8_t) \
  MACRO (8, 2, 2, 4, int8_t) \
  MACRO (8, 2, 3, 4, int8_t) \
  MACRO (8, 2, 4, 4, int8_t) \
  MACRO (8, 4, 2, 2, int8_t) \
  MACRO (16, 1, 2, 16, int16_t) \
  MACRO (16, 1, 3, 16, int16_t) \
  MACRO (16, 1, 4, 16, int16_t) \
  MACRO (16, 1, 5, 16, int16_t) \
  MACRO (16, 1, 6, 16, int16_t) \
  MACRO (16, 1, 7, 16, int16_t) \
  MACRO (16, 1, 8, 16, int16_t) \
  MACRO (16, 2, 2, 8, int16_t) \
  MACRO (16, 2, 3, 8, int16_t) \
  MACRO (16, 2, 4, 8, int16_t) \
  MACRO (16, 4, 2, 4, int16_t) \
  MACRO (32, 1, 2, 32, int32_t) \
  MACRO (32, 1, 3, 32, int32_t) \
  MACRO (32, 1, 4, 32, int32_t) \
  MACRO (32, 1, 5, 32, int32_t) \
  MACRO (32, 1, 6, 32, int32_t) \
  MACRO (32, 1, 7, 32, int32_t) \
  MACRO (32, 1, 8, 32, int32_t) \
  MACRO (32, 2, 2, 16, int32_t) \
  MACRO (32, 2, 3, 16, int32_t) \
  MACRO (32, 2, 4, 16, int32_t) \
  MACRO (32, 4, 2, 8, int32_t) \
  MACRO (64, 1, 2, 64, int64_t) \
  MACRO (64, 1, 3, 64, int64_t) \
  MACRO (64, 1, 4, 64, int64_t) \
  MACRO (64, 1, 5, 64, int64_t) \
  MACRO (64, 1, 6, 64, int64_t) \
  MACRO (64, 1, 7, 64, int64_t) \
  MACRO (64, 1, 8, 64, int64_t) \
  MACRO (64, 2, 2, 32, int64_t) \
  MACRO (64, 2, 3, 32, int64_t) \
  MACRO (64, 2, 4, 32, int64_t) \
  MACRO (64, 4, 2, 16, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 2, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 2, 8, int8_t, 8, 1) \
  MACRO (8, 1, 2, 8, int8_t, 16, 2) \
  MACRO (8, 1, 2, 8, int8_t, 32, 4) \
  MACRO (8, 1, 2, 8, int8_t, 64, 8) \
  MACRO (8, 1, 3, 8, int8_t, 8, 1) \
  MACRO (8, 1, 3, 8, int8_t, 16, 2) \
  MACRO (8, 1, 3, 8, int8_t, 32, 4) \
  MACRO (8, 1, 3, 8, int8_t, 64, 8) \
  MACRO (8, 1, 4, 8, int8_t, 8, 1) \
  MACRO (8, 1, 4, 8, int8_t, 16, 2) \
  MACRO (8, 1, 4, 8, int8_t, 32, 4) \
  MACRO (8, 1, 4, 8, int8_t, 64, 8) \
  MACRO (8, 1, 5, 8, int8_t, 8, 1) \
  MACRO (8, 1, 5, 8, int8_t, 16, 2) \
  MACRO (8, 1, 5, 8, int8_t, 32, 4) \
  MACRO (8, 1, 5, 8, int8_t, 64, 8) \
  MACRO (8, 1, 6, 8, int8_t, 8, 1) \
  MACRO (8, 1, 6, 8, int8_t, 16, 2) \
  MACRO (8, 1, 6, 8, int8_t, 32, 4) \
  MACRO (8, 1, 6, 8, int8_t, 64, 8) \
  MACRO (8, 1, 7, 8, int8_t, 8, 1) \
  MACRO (8, 1, 7, 8, int8_t, 16, 2) \
  MACRO (8, 1, 7, 8, int8_t, 32, 4) \
  MACRO (8, 1, 7, 8, int8_t, 64, 8) \
  MACRO (8, 1, 8, 8, int8_t, 8, 1) \
  MACRO (8, 1, 8, 8, int8_t, 16, 2) \
  MACRO (8, 1, 8, 8, int8_t, 32, 4) \
  MACRO (8, 1, 8, 8, int8_t, 64, 8) \
  MACRO (8, 2, 2, 4, int8_t, 8, 2) \
  MACRO (8, 2, 2, 4, int8_t, 16, 4) \
  MACRO (8, 2, 2, 4, int8_t, 32, 8) \
  MACRO (8, 2, 3, 4, int8_t, 8, 2) \
  MACRO (8, 2, 3, 4, int8_t, 16, 4) \
  MACRO (8, 2, 3, 4, int8_t, 32, 8) \
  MACRO (8, 2, 4, 4, int8_t, 8, 2) \
  MACRO (8, 2, 4, 4, int8_t, 16, 4) \
  MACRO (8, 2, 4, 4, int8_t, 32, 8) \
  MACRO (8, 4, 2, 2, int8_t, 8, 4) \
  MACRO (8, 4, 2, 2, int8_t, 16, 8) \
  MACRO (16, 1, 2, 16, int16_t, 16, 1) \
  MACRO (16, 1, 2, 16, int16_t, 32, 2) \
  MACRO (16, 1, 2, 16, int16_t, 64, 4) \
  MACRO (16, 1, 3, 16, int16_t, 16, 1) \
  MACRO (16, 1, 3, 16, int16_t, 32, 2) \
  MACRO (16, 1, 3, 16, int16_t, 64, 4) \
  MACRO (16, 1, 4, 16, int16_t, 16, 1) \
  MACRO (16, 1, 4, 16, int16_t, 32, 2) \
  MACRO (16, 1, 4, 16, int16_t, 64, 4) \
  MACRO (16, 1, 5, 16, int16_t, 16, 1) \
  MACRO (16, 1, 5, 16, int16_t, 32, 2) \
  MACRO (16, 1, 5, 16, int16_t, 64, 4) \
  MACRO (16, 1, 6, 16, int16_t, 16, 1) \
  MACRO (16, 1, 6, 16, int16_t, 32, 2) \
  MACRO (16, 1, 6, 16, int16_t, 64, 4) \
  MACRO (16, 1, 7, 16, int16_t, 16, 1) \
  MACRO (16, 1, 7, 16, int16_t, 32, 2) \
  MACRO (16, 1, 7, 16, int16_t, 64, 4) \
  MACRO (16, 1, 8, 16, int16_t, 16, 1) \
  MACRO (16, 1, 8, 16, int16_t, 32, 2) \
  MACRO (16, 1, 8, 16, int16_t, 64, 4) \
  MACRO (16, 2, 2, 8, int16_t, 8, 1) \
  MACRO (16, 2, 2, 8, int16_t, 16, 2) \
  MACRO (16, 2, 2, 8, int16_t, 32, 4) \
  MACRO (16, 2, 2, 8, int16_t, 64, 8) \
  MACRO (16, 2, 3, 8, int16_t, 8, 1) \
  MACRO (16, 2, 3, 8, int16_t, 16, 2) \
  MACRO (16, 2, 3, 8, int16_t, 32, 4) \
  MACRO (16, 2, 3, 8, int16_t, 64, 8) \
  MACRO (16, 2, 4, 8, int16_t, 8, 1) \
  MACRO (16, 2, 4, 8, int16_t, 16, 2) \
  MACRO (16, 2, 4, 8, int16_t, 32, 4) \
  MACRO (16, 2, 4, 8, int16_t, 64, 8) \
  MACRO (16, 4, 2, 4, int16_t, 8, 2) \
  MACRO (16, 4, 2, 4, int16_t, 16, 4) \
  MACRO (16, 4, 2, 4, int16_t, 32, 8) \
  MACRO (32, 1, 2, 32, int32_t, 32, 1) \
  MACRO (32, 1, 2, 32, int32_t, 64, 2) \
  MACRO (32, 1, 3, 32, int32_t, 32, 1) \
  MACRO (32, 1, 3, 32, int32_t, 64, 2) \
  MACRO (32, 1, 4, 32, int32_t, 32, 1) \
  MACRO (32, 1, 4, 32, int32_t, 64, 2) \
  MACRO (32, 1, 5, 32, int32_t, 32, 1) \
  MACRO (32, 1, 5, 32, int32_t, 64, 2) \
  MACRO (32, 1, 6, 32, int32_t, 32, 1) \
  MACRO (32, 1, 6, 32, int32_t, 64, 2) \
  MACRO (32, 1, 7, 32, int32_t, 32, 1) \
  MACRO (32, 1, 7, 32, int32_t, 64, 2) \
  MACRO (32, 1, 8, 32, int32_t, 32, 1) \
  MACRO (32, 1, 8, 32, int32_t, 64, 2) \
  MACRO (32, 2, 2, 16, int32_t, 16, 1) \
  MACRO (32, 2, 2, 16, int32_t, 32, 2) \
  MACRO (32, 2, 2, 16, int32_t, 64, 4) \
  MACRO (32, 2, 3, 16, int32_t, 16, 1) \
  MACRO (32, 2, 3, 16, int32_t, 32, 2) \
  MACRO (32, 2, 3, 16, int32_t, 64, 4) \
  MACRO (32, 2, 4, 16, int32_t, 16, 1) \
  MACRO (32, 2, 4, 16, int32_t, 32, 2) \
  MACRO (32, 2, 4, 16, int32_t, 64, 4) \
  MACRO (32, 4, 2, 8, int32_t, 8, 1) \
  MACRO (32, 4, 2, 8, int32_t, 16, 2) \
  MACRO (32, 4, 2, 8, int32_t, 32, 4) \
  MACRO (32, 4, 2, 8, int32_t, 64, 8) \
  MACRO (64, 1, 2, 64, int64_t, 64, 1) \
  MACRO (64, 1, 3, 64, int64_t, 64, 1) \
  MACRO (64, 1, 4, 64, int64_t, 64, 1) \
  MACRO (64, 1, 5, 64, int64_t, 64, 1) \
  MACRO (64, 1, 6, 64, int64_t, 64, 1) \
  MACRO (64, 1, 7, 64, int64_t, 64, 1) \
  MACRO (64, 1, 8, 64, int64_t, 64, 1) \
  MACRO (64, 2, 2, 32, int64_t, 32, 1) \
  MACRO (64, 2, 2, 32, int64_t, 64, 2) \
  MACRO (64, 2, 3, 32, int64_t, 32, 1) \
  MACRO (64, 2, 3, 32, int64_t, 64, 2) \
  MACRO (64, 2, 4, 32, int64_t, 32, 1) \
  MACRO (64, 2, 4, 32, int64_t, 64, 2) \
  MACRO (64, 4, 2, 16, int64_t, 16, 1) \
  MACRO (64, 4, 2, 16, int64_t, 32, 2) \
  MACRO (64, 4, 2, 16, int64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 2, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF2_ITERATOR(MACRO) \
  MACRO (8, 1, 2, 8, int8_t) \
  MACRO (8, 2, 2, 4, int8_t) \
  MACRO (8, 4, 2, 2, int8_t) \
  MACRO (16, 1, 2, 16, int16_t) \
  MACRO (16, 2, 2, 8, int16_t) \
  MACRO (16, 4, 2, 4, int16_t) \
  MACRO (32, 1, 2, 32, int32_t) \
  MACRO (32, 2, 2, 16, int32_t) \
  MACRO (32, 4, 2, 8, int32_t) \
  MACRO (64, 1, 2, 64, int64_t) \
  MACRO (64, 2, 2, 32, int64_t) \
  MACRO (64, 4, 2, 16, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF2_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 2, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF3_ITERATOR(MACRO) \
  MACRO (8, 1, 3, 8, int8_t) \
  MACRO (8, 2, 3, 4, int8_t) \
  MACRO (16, 1, 3, 16, int16_t) \
  MACRO (16, 2, 3, 8, int16_t) \
  MACRO (32, 1, 3, 32, int32_t) \
  MACRO (32, 2, 3, 16, int32_t) \
  MACRO (64, 1, 3, 64, int64_t) \
  MACRO (64, 2, 3, 32, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF3_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 3, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF4_ITERATOR(MACRO) \
  MACRO (8, 1, 4, 8, int8_t) \
  MACRO (8, 2, 4, 4, int8_t) \
  MACRO (16, 1, 4, 16, int16_t) \
  MACRO (16, 2, 4, 8, int16_t) \
  MACRO (32, 1, 4, 32, int32_t) \
  MACRO (32, 2, 4, 16, int32_t) \
  MACRO (64, 1, 4, 64, int64_t) \
  MACRO (64, 2, 4, 32, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF4_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 4, 8, int8_t, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, int64_t, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF5_ITERATOR(MACRO) \
  MACRO (8, 1, 5, 8, int8_t) \
  MACRO (16, 1, 5, 16, int16_t) \
  MACRO (32, 1, 5, 32, int32_t) \
  MACRO (64, 1, 5, 64, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF5_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 5, 8, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF6_ITERATOR(MACRO) \
  MACRO (8, 1, 6, 8, int8_t) \
  MACRO (16, 1, 6, 16, int16_t) \
  MACRO (32, 1, 6, 32, int32_t) \
  MACRO (64, 1, 6, 64, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF6_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 6, 8, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF7_ITERATOR(MACRO) \
  MACRO (8, 1, 7, 8, int8_t) \
  MACRO (16, 1, 7, 16, int16_t) \
  MACRO (32, 1, 7, 32, int32_t) \
  MACRO (64, 1, 7, 64, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF7_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 7, 8, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF8_ITERATOR(MACRO) \
  MACRO (8, 1, 8, 8, int8_t) \
  MACRO (16, 1, 8, 16, int16_t) \
  MACRO (32, 1, 8, 32, int32_t) \
  MACRO (64, 1, 8, 64, int64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF8_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 8, 8, int8_t, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, int64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF2_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 2, 8, int8_t, 8, 1) \
  MACRO (8, 1, 2, 8, int8_t, 16, 2) \
  MACRO (8, 1, 2, 8, int8_t, 32, 4) \
  MACRO (8, 1, 2, 8, int8_t, 64, 8) \
  MACRO (8, 2, 2, 4, int8_t, 8, 2) \
  MACRO (8, 2, 2, 4, int8_t, 16, 4) \
  MACRO (8, 2, 2, 4, int8_t, 32, 8) \
  MACRO (8, 4, 2, 2, int8_t, 8, 4) \
  MACRO (8, 4, 2, 2, int8_t, 16, 8) \
  MACRO (16, 1, 2, 16, int16_t, 16, 1) \
  MACRO (16, 1, 2, 16, int16_t, 32, 2) \
  MACRO (16, 1, 2, 16, int16_t, 64, 4) \
  MACRO (16, 2, 2, 8, int16_t, 8, 1) \
  MACRO (16, 2, 2, 8, int16_t, 16, 2) \
  MACRO (16, 2, 2, 8, int16_t, 32, 4) \
  MACRO (16, 2, 2, 8, int16_t, 64, 8) \
  MACRO (16, 4, 2, 4, int16_t, 8, 2) \
  MACRO (16, 4, 2, 4, int16_t, 16, 4) \
  MACRO (16, 4, 2, 4, int16_t, 32, 8) \
  MACRO (32, 1, 2, 32, int32_t, 32, 1) \
  MACRO (32, 1, 2, 32, int32_t, 64, 2) \
  MACRO (32, 2, 2, 16, int32_t, 16, 1) \
  MACRO (32, 2, 2, 16, int32_t, 32, 2) \
  MACRO (32, 2, 2, 16, int32_t, 64, 4) \
  MACRO (32, 4, 2, 8, int32_t, 8, 1) \
  MACRO (32, 4, 2, 8, int32_t, 16, 2) \
  MACRO (32, 4, 2, 8, int32_t, 32, 4) \
  MACRO (32, 4, 2, 8, int32_t, 64, 8) \
  MACRO (64, 1, 2, 64, int64_t, 64, 1) \
  MACRO (64, 2, 2, 32, int64_t, 32, 1) \
  MACRO (64, 2, 2, 32, int64_t, 64, 2) \
  MACRO (64, 4, 2, 16, int64_t, 16, 1) \
  MACRO (64, 4, 2, 16, int64_t, 32, 2) \
  MACRO (64, 4, 2, 16, int64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF2_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 2, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 2, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 2, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, 8, 4, __VA_ARGS__) \
  MACRO (8, 4, 2, 2, int8_t, 16, 8, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, int16_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, int32_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, int64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, int64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF3_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 3, 8, int8_t, 8, 1) \
  MACRO (8, 1, 3, 8, int8_t, 16, 2) \
  MACRO (8, 1, 3, 8, int8_t, 32, 4) \
  MACRO (8, 1, 3, 8, int8_t, 64, 8) \
  MACRO (8, 2, 3, 4, int8_t, 8, 2) \
  MACRO (8, 2, 3, 4, int8_t, 16, 4) \
  MACRO (8, 2, 3, 4, int8_t, 32, 8) \
  MACRO (16, 1, 3, 16, int16_t, 16, 1) \
  MACRO (16, 1, 3, 16, int16_t, 32, 2) \
  MACRO (16, 1, 3, 16, int16_t, 64, 4) \
  MACRO (16, 2, 3, 8, int16_t, 8, 1) \
  MACRO (16, 2, 3, 8, int16_t, 16, 2) \
  MACRO (16, 2, 3, 8, int16_t, 32, 4) \
  MACRO (16, 2, 3, 8, int16_t, 64, 8) \
  MACRO (32, 1, 3, 32, int32_t, 32, 1) \
  MACRO (32, 1, 3, 32, int32_t, 64, 2) \
  MACRO (32, 2, 3, 16, int32_t, 16, 1) \
  MACRO (32, 2, 3, 16, int32_t, 32, 2) \
  MACRO (32, 2, 3, 16, int32_t, 64, 4) \
  MACRO (64, 1, 3, 64, int64_t, 64, 1) \
  MACRO (64, 2, 3, 32, int64_t, 32, 1) \
  MACRO (64, 2, 3, 32, int64_t, 64, 2) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF3_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 3, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 3, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 3, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, int64_t, 64, 2, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF4_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 4, 8, int8_t, 8, 1) \
  MACRO (8, 1, 4, 8, int8_t, 16, 2) \
  MACRO (8, 1, 4, 8, int8_t, 32, 4) \
  MACRO (8, 1, 4, 8, int8_t, 64, 8) \
  MACRO (8, 2, 4, 4, int8_t, 8, 2) \
  MACRO (8, 2, 4, 4, int8_t, 16, 4) \
  MACRO (8, 2, 4, 4, int8_t, 32, 8) \
  MACRO (16, 1, 4, 16, int16_t, 16, 1) \
  MACRO (16, 1, 4, 16, int16_t, 32, 2) \
  MACRO (16, 1, 4, 16, int16_t, 64, 4) \
  MACRO (16, 2, 4, 8, int16_t, 8, 1) \
  MACRO (16, 2, 4, 8, int16_t, 16, 2) \
  MACRO (16, 2, 4, 8, int16_t, 32, 4) \
  MACRO (16, 2, 4, 8, int16_t, 64, 8) \
  MACRO (32, 1, 4, 32, int32_t, 32, 1) \
  MACRO (32, 1, 4, 32, int32_t, 64, 2) \
  MACRO (32, 2, 4, 16, int32_t, 16, 1) \
  MACRO (32, 2, 4, 16, int32_t, 32, 2) \
  MACRO (32, 2, 4, 16, int32_t, 64, 4) \
  MACRO (64, 1, 4, 64, int64_t, 64, 1) \
  MACRO (64, 2, 4, 32, int64_t, 32, 1) \
  MACRO (64, 2, 4, 32, int64_t, 64, 2) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF4_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 4, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 4, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 8, 2, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 16, 4, __VA_ARGS__) \
  MACRO (8, 2, 4, 4, int8_t, 32, 8, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, int16_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, int32_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, int64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, int64_t, 64, 2, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF5_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 5, 8, int8_t, 8, 1) \
  MACRO (8, 1, 5, 8, int8_t, 16, 2) \
  MACRO (8, 1, 5, 8, int8_t, 32, 4) \
  MACRO (8, 1, 5, 8, int8_t, 64, 8) \
  MACRO (16, 1, 5, 16, int16_t, 16, 1) \
  MACRO (16, 1, 5, 16, int16_t, 32, 2) \
  MACRO (16, 1, 5, 16, int16_t, 64, 4) \
  MACRO (32, 1, 5, 32, int32_t, 32, 1) \
  MACRO (32, 1, 5, 32, int32_t, 64, 2) \
  MACRO (64, 1, 5, 64, int64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF5_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 5, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 5, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, int64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF6_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 6, 8, int8_t, 8, 1) \
  MACRO (8, 1, 6, 8, int8_t, 16, 2) \
  MACRO (8, 1, 6, 8, int8_t, 32, 4) \
  MACRO (8, 1, 6, 8, int8_t, 64, 8) \
  MACRO (16, 1, 6, 16, int16_t, 16, 1) \
  MACRO (16, 1, 6, 16, int16_t, 32, 2) \
  MACRO (16, 1, 6, 16, int16_t, 64, 4) \
  MACRO (32, 1, 6, 32, int32_t, 32, 1) \
  MACRO (32, 1, 6, 32, int32_t, 64, 2) \
  MACRO (64, 1, 6, 64, int64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF6_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 6, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 6, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, int64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF7_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 7, 8, int8_t, 8, 1) \
  MACRO (8, 1, 7, 8, int8_t, 16, 2) \
  MACRO (8, 1, 7, 8, int8_t, 32, 4) \
  MACRO (8, 1, 7, 8, int8_t, 64, 8) \
  MACRO (16, 1, 7, 16, int16_t, 16, 1) \
  MACRO (16, 1, 7, 16, int16_t, 32, 2) \
  MACRO (16, 1, 7, 16, int16_t, 64, 4) \
  MACRO (32, 1, 7, 32, int32_t, 32, 1) \
  MACRO (32, 1, 7, 32, int32_t, 64, 2) \
  MACRO (64, 1, 7, 64, int64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF7_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 7, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 7, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, int64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_INT_TUPLE_NF8_INDEX_ITERATOR(MACRO) \
  MACRO (8, 1, 8, 8, int8_t, 8, 1) \
  MACRO (8, 1, 8, 8, int8_t, 16, 2) \
  MACRO (8, 1, 8, 8, int8_t, 32, 4) \
  MACRO (8, 1, 8, 8, int8_t, 64, 8) \
  MACRO (16, 1, 8, 16, int16_t, 16, 1) \
  MACRO (16, 1, 8, 16, int16_t, 32, 2) \
  MACRO (16, 1, 8, 16, int16_t, 64, 4) \
  MACRO (32, 1, 8, 32, int32_t, 32, 1) \
  MACRO (32, 1, 8, 32, int32_t, 64, 2) \
  MACRO (64, 1, 8, 64, int64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_INT_TUPLE_NF8_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (8, 1, 8, 8, int8_t, 8, 1, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 16, 2, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 32, 4, __VA_ARGS__) \
  MACRO (8, 1, 8, 8, int8_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, int16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, int32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, int64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_ITERATOR(MACRO) \
  MACRO (16, 1, 2, 16, __float16_t) \
  MACRO (16, 1, 3, 16, __float16_t) \
  MACRO (16, 1, 4, 16, __float16_t) \
  MACRO (16, 1, 5, 16, __float16_t) \
  MACRO (16, 1, 6, 16, __float16_t) \
  MACRO (16, 1, 7, 16, __float16_t) \
  MACRO (16, 1, 8, 16, __float16_t) \
  MACRO (16, 2, 2, 8, __float16_t) \
  MACRO (16, 2, 3, 8, __float16_t) \
  MACRO (16, 2, 4, 8, __float16_t) \
  MACRO (16, 4, 2, 4, __float16_t) \
  MACRO (32, 1, 2, 32, __float32_t) \
  MACRO (32, 1, 3, 32, __float32_t) \
  MACRO (32, 1, 4, 32, __float32_t) \
  MACRO (32, 1, 5, 32, __float32_t) \
  MACRO (32, 1, 6, 32, __float32_t) \
  MACRO (32, 1, 7, 32, __float32_t) \
  MACRO (32, 1, 8, 32, __float32_t) \
  MACRO (32, 2, 2, 16, __float32_t) \
  MACRO (32, 2, 3, 16, __float32_t) \
  MACRO (32, 2, 4, 16, __float32_t) \
  MACRO (32, 4, 2, 8, __float32_t) \
  MACRO (64, 1, 2, 64, __float64_t) \
  MACRO (64, 1, 3, 64, __float64_t) \
  MACRO (64, 1, 4, 64, __float64_t) \
  MACRO (64, 1, 5, 64, __float64_t) \
  MACRO (64, 1, 6, 64, __float64_t) \
  MACRO (64, 1, 7, 64, __float64_t) \
  MACRO (64, 1, 8, 64, __float64_t) \
  MACRO (64, 2, 2, 32, __float64_t) \
  MACRO (64, 2, 3, 32, __float64_t) \
  MACRO (64, 2, 4, 32, __float64_t) \
  MACRO (64, 4, 2, 16, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 2, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 2, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 2, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 2, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 3, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 3, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 3, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 4, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 4, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 4, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 5, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 5, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 5, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 6, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 6, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 6, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 7, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 7, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 7, 16, __float16_t, 64, 4) \
  MACRO (16, 1, 8, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 8, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 8, 16, __float16_t, 64, 4) \
  MACRO (16, 2, 2, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 2, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 2, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 2, 8, __float16_t, 64, 8) \
  MACRO (16, 2, 3, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 3, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 3, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 3, 8, __float16_t, 64, 8) \
  MACRO (16, 2, 4, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 4, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 4, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 4, 8, __float16_t, 64, 8) \
  MACRO (16, 4, 2, 4, __float16_t, 8, 2) \
  MACRO (16, 4, 2, 4, __float16_t, 16, 4) \
  MACRO (16, 4, 2, 4, __float16_t, 32, 8) \
  MACRO (32, 1, 2, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 2, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 3, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 3, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 4, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 4, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 5, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 5, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 6, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 6, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 7, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 7, 32, __float32_t, 64, 2) \
  MACRO (32, 1, 8, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 8, 32, __float32_t, 64, 2) \
  MACRO (32, 2, 2, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 2, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 2, 16, __float32_t, 64, 4) \
  MACRO (32, 2, 3, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 3, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 3, 16, __float32_t, 64, 4) \
  MACRO (32, 2, 4, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 4, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 4, 16, __float32_t, 64, 4) \
  MACRO (32, 4, 2, 8, __float32_t, 8, 1) \
  MACRO (32, 4, 2, 8, __float32_t, 16, 2) \
  MACRO (32, 4, 2, 8, __float32_t, 32, 4) \
  MACRO (32, 4, 2, 8, __float32_t, 64, 8) \
  MACRO (64, 1, 2, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 3, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 4, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 5, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 6, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 7, 64, __float64_t, 64, 1) \
  MACRO (64, 1, 8, 64, __float64_t, 64, 1) \
  MACRO (64, 2, 2, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 2, 32, __float64_t, 64, 2) \
  MACRO (64, 2, 3, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 3, 32, __float64_t, 64, 2) \
  MACRO (64, 2, 4, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 4, 32, __float64_t, 64, 2) \
  MACRO (64, 4, 2, 16, __float64_t, 16, 1) \
  MACRO (64, 4, 2, 16, __float64_t, 32, 2) \
  MACRO (64, 4, 2, 16, __float64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 2, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF2_ITERATOR(MACRO) \
  MACRO (16, 1, 2, 16, __float16_t) \
  MACRO (16, 2, 2, 8, __float16_t) \
  MACRO (16, 4, 2, 4, __float16_t) \
  MACRO (32, 1, 2, 32, __float32_t) \
  MACRO (32, 2, 2, 16, __float32_t) \
  MACRO (32, 4, 2, 8, __float32_t) \
  MACRO (64, 1, 2, 64, __float64_t) \
  MACRO (64, 2, 2, 32, __float64_t) \
  MACRO (64, 4, 2, 16, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF2_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 2, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF3_ITERATOR(MACRO) \
  MACRO (16, 1, 3, 16, __float16_t) \
  MACRO (16, 2, 3, 8, __float16_t) \
  MACRO (32, 1, 3, 32, __float32_t) \
  MACRO (32, 2, 3, 16, __float32_t) \
  MACRO (64, 1, 3, 64, __float64_t) \
  MACRO (64, 2, 3, 32, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF3_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 3, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF4_ITERATOR(MACRO) \
  MACRO (16, 1, 4, 16, __float16_t) \
  MACRO (16, 2, 4, 8, __float16_t) \
  MACRO (32, 1, 4, 32, __float32_t) \
  MACRO (32, 2, 4, 16, __float32_t) \
  MACRO (64, 1, 4, 64, __float64_t) \
  MACRO (64, 2, 4, 32, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF4_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 4, 16, __float16_t, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, __float64_t, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF5_ITERATOR(MACRO) \
  MACRO (16, 1, 5, 16, __float16_t) \
  MACRO (32, 1, 5, 32, __float32_t) \
  MACRO (64, 1, 5, 64, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF5_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 5, 16, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF6_ITERATOR(MACRO) \
  MACRO (16, 1, 6, 16, __float16_t) \
  MACRO (32, 1, 6, 32, __float32_t) \
  MACRO (64, 1, 6, 64, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF6_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 6, 16, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF7_ITERATOR(MACRO) \
  MACRO (16, 1, 7, 16, __float16_t) \
  MACRO (32, 1, 7, 32, __float32_t) \
  MACRO (64, 1, 7, 64, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF7_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 7, 16, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF8_ITERATOR(MACRO) \
  MACRO (16, 1, 8, 16, __float16_t) \
  MACRO (32, 1, 8, 32, __float32_t) \
  MACRO (64, 1, 8, 64, __float64_t) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF8_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 8, 16, __float16_t, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, __float64_t, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF2_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 2, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 2, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 2, 16, __float16_t, 64, 4) \
  MACRO (16, 2, 2, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 2, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 2, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 2, 8, __float16_t, 64, 8) \
  MACRO (16, 4, 2, 4, __float16_t, 8, 2) \
  MACRO (16, 4, 2, 4, __float16_t, 16, 4) \
  MACRO (16, 4, 2, 4, __float16_t, 32, 8) \
  MACRO (32, 1, 2, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 2, 32, __float32_t, 64, 2) \
  MACRO (32, 2, 2, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 2, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 2, 16, __float32_t, 64, 4) \
  MACRO (32, 4, 2, 8, __float32_t, 8, 1) \
  MACRO (32, 4, 2, 8, __float32_t, 16, 2) \
  MACRO (32, 4, 2, 8, __float32_t, 32, 4) \
  MACRO (32, 4, 2, 8, __float32_t, 64, 8) \
  MACRO (64, 1, 2, 64, __float64_t, 64, 1) \
  MACRO (64, 2, 2, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 2, 32, __float64_t, 64, 2) \
  MACRO (64, 4, 2, 16, __float64_t, 16, 1) \
  MACRO (64, 4, 2, 16, __float64_t, 32, 2) \
  MACRO (64, 4, 2, 16, __float64_t, 64, 4) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF2_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 2, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 2, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 2, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 8, 2, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 16, 4, __VA_ARGS__) \
  MACRO (16, 4, 2, 4, __float16_t, 32, 8, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 2, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 2, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 8, 1, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 16, 2, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 32, 4, __VA_ARGS__) \
  MACRO (32, 4, 2, 8, __float32_t, 64, 8, __VA_ARGS__) \
  MACRO (64, 1, 2, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 2, 32, __float64_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 16, 1, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 32, 2, __VA_ARGS__) \
  MACRO (64, 4, 2, 16, __float64_t, 64, 4, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF3_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 3, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 3, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 3, 16, __float16_t, 64, 4) \
  MACRO (16, 2, 3, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 3, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 3, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 3, 8, __float16_t, 64, 8) \
  MACRO (32, 1, 3, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 3, 32, __float32_t, 64, 2) \
  MACRO (32, 2, 3, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 3, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 3, 16, __float32_t, 64, 4) \
  MACRO (64, 1, 3, 64, __float64_t, 64, 1) \
  MACRO (64, 2, 3, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 3, 32, __float64_t, 64, 2) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF3_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 3, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 3, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 3, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 3, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 3, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 3, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 3, 32, __float64_t, 64, 2, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF4_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 4, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 4, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 4, 16, __float16_t, 64, 4) \
  MACRO (16, 2, 4, 8, __float16_t, 8, 1) \
  MACRO (16, 2, 4, 8, __float16_t, 16, 2) \
  MACRO (16, 2, 4, 8, __float16_t, 32, 4) \
  MACRO (16, 2, 4, 8, __float16_t, 64, 8) \
  MACRO (32, 1, 4, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 4, 32, __float32_t, 64, 2) \
  MACRO (32, 2, 4, 16, __float32_t, 16, 1) \
  MACRO (32, 2, 4, 16, __float32_t, 32, 2) \
  MACRO (32, 2, 4, 16, __float32_t, 64, 4) \
  MACRO (64, 1, 4, 64, __float64_t, 64, 1) \
  MACRO (64, 2, 4, 32, __float64_t, 32, 1) \
  MACRO (64, 2, 4, 32, __float64_t, 64, 2) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF4_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 4, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 4, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 8, 1, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 16, 2, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 32, 4, __VA_ARGS__) \
  MACRO (16, 2, 4, 8, __float16_t, 64, 8, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 4, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 16, 1, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 32, 2, __VA_ARGS__) \
  MACRO (32, 2, 4, 16, __float32_t, 64, 4, __VA_ARGS__) \
  MACRO (64, 1, 4, 64, __float64_t, 64, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, 32, 1, __VA_ARGS__) \
  MACRO (64, 2, 4, 32, __float64_t, 64, 2, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF5_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 5, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 5, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 5, 16, __float16_t, 64, 4) \
  MACRO (32, 1, 5, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 5, 32, __float32_t, 64, 2) \
  MACRO (64, 1, 5, 64, __float64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF5_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 5, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 5, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 5, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 5, 64, __float64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF6_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 6, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 6, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 6, 16, __float16_t, 64, 4) \
  MACRO (32, 1, 6, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 6, 32, __float32_t, 64, 2) \
  MACRO (64, 1, 6, 64, __float64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF6_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 6, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 6, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 6, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 6, 64, __float64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF7_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 7, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 7, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 7, 16, __float16_t, 64, 4) \
  MACRO (32, 1, 7, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 7, 32, __float32_t, 64, 2) \
  MACRO (64, 1, 7, 64, __float64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF7_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 7, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 7, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 7, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 7, 64, __float64_t, 64, 1, __VA_ARGS__) \

/* An iterator to call a macro with every supported NF, SEW, LMUL and MLEN value,
   along with its corresponding vector, floating point modes, and info for
   corresponding floating point and vector tuple type.  */
#define _RVV_FLOAT_TUPLE_NF8_INDEX_ITERATOR(MACRO) \
  MACRO (16, 1, 8, 16, __float16_t, 16, 1) \
  MACRO (16, 1, 8, 16, __float16_t, 32, 2) \
  MACRO (16, 1, 8, 16, __float16_t, 64, 4) \
  MACRO (32, 1, 8, 32, __float32_t, 32, 1) \
  MACRO (32, 1, 8, 32, __float32_t, 64, 2) \
  MACRO (64, 1, 8, 64, __float64_t, 64, 1) \

/* Same as above but with an extra argument.  */
#define _RVV_FLOAT_TUPLE_NF8_INDEX_ITERATOR_ARG(MACRO, ...) \
  MACRO (16, 1, 8, 16, __float16_t, 16, 1, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, 32, 2, __VA_ARGS__) \
  MACRO (16, 1, 8, 16, __float16_t, 64, 4, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, 32, 1, __VA_ARGS__) \
  MACRO (32, 1, 8, 32, __float32_t, 64, 2, __VA_ARGS__) \
  MACRO (64, 1, 8, 64, __float64_t, 64, 1, __VA_ARGS__) \

#if __riscv_v == 7000
/* Wrapper only.  */
#define vle_v_i8m1	vle8_v_i8m1
#define vle_v_u8m1	vle8_v_u8m1
#define vle_v_i8m1_m	vle8_v_i8m1_m
#define vle_v_u8m1_m	vle8_v_u8m1_m
#define vle_v_i8m2	vle8_v_i8m2
#define vle_v_u8m2	vle8_v_u8m2
#define vle_v_i8m2_m	vle8_v_i8m2_m
#define vle_v_u8m2_m	vle8_v_u8m2_m
#define vle_v_i8m4	vle8_v_i8m4
#define vle_v_u8m4	vle8_v_u8m4
#define vle_v_i8m4_m	vle8_v_i8m4_m
#define vle_v_u8m4_m	vle8_v_u8m4_m
#define vle_v_i8m8	vle8_v_i8m8
#define vle_v_u8m8	vle8_v_u8m8
#define vle_v_i8m8_m	vle8_v_i8m8_m
#define vle_v_u8m8_m	vle8_v_u8m8_m
#define vle_v_i16m1	vle16_v_i16m1
#define vle_v_u16m1	vle16_v_u16m1
#define vle_v_i16m1_m	vle16_v_i16m1_m
#define vle_v_u16m1_m	vle16_v_u16m1_m
#define vle_v_i16m2	vle16_v_i16m2
#define vle_v_u16m2	vle16_v_u16m2
#define vle_v_i16m2_m	vle16_v_i16m2_m
#define vle_v_u16m2_m	vle16_v_u16m2_m
#define vle_v_i16m4	vle16_v_i16m4
#define vle_v_u16m4	vle16_v_u16m4
#define vle_v_i16m4_m	vle16_v_i16m4_m
#define vle_v_u16m4_m	vle16_v_u16m4_m
#define vle_v_i16m8	vle16_v_i16m8
#define vle_v_u16m8	vle16_v_u16m8
#define vle_v_i16m8_m	vle16_v_i16m8_m
#define vle_v_u16m8_m	vle16_v_u16m8_m
#define vle_v_i32m1	vle32_v_i32m1
#define vle_v_u32m1	vle32_v_u32m1
#define vle_v_i32m1_m	vle32_v_i32m1_m
#define vle_v_u32m1_m	vle32_v_u32m1_m
#define vle_v_i32m2	vle32_v_i32m2
#define vle_v_u32m2	vle32_v_u32m2
#define vle_v_i32m2_m	vle32_v_i32m2_m
#define vle_v_u32m2_m	vle32_v_u32m2_m
#define vle_v_i32m4	vle32_v_i32m4
#define vle_v_u32m4	vle32_v_u32m4
#define vle_v_i32m4_m	vle32_v_i32m4_m
#define vle_v_u32m4_m	vle32_v_u32m4_m
#define vle_v_i32m8	vle32_v_i32m8
#define vle_v_u32m8	vle32_v_u32m8
#define vle_v_i32m8_m	vle32_v_i32m8_m
#define vle_v_u32m8_m	vle32_v_u32m8_m
#define vle_v_i64m1	vle64_v_i64m1
#define vle_v_u64m1	vle64_v_u64m1
#define vle_v_i64m1_m	vle64_v_i64m1_m
#define vle_v_u64m1_m	vle64_v_u64m1_m
#define vle_v_i64m2	vle64_v_i64m2
#define vle_v_u64m2	vle64_v_u64m2
#define vle_v_i64m2_m	vle64_v_i64m2_m
#define vle_v_u64m2_m	vle64_v_u64m2_m
#define vle_v_i64m4	vle64_v_i64m4
#define vle_v_u64m4	vle64_v_u64m4
#define vle_v_i64m4_m	vle64_v_i64m4_m
#define vle_v_u64m4_m	vle64_v_u64m4_m
#define vle_v_i64m8	vle64_v_i64m8
#define vle_v_u64m8	vle64_v_u64m8
#define vle_v_i64m8_m	vle64_v_i64m8_m
#define vle_v_u64m8_m	vle64_v_u64m8_m
#define vle_v_f16m1	vle16_v_f16m1
#define vle_v_f16m1_m	vle16_v_f16m1_m
#define vle_v_f16m2	vle16_v_f16m2
#define vle_v_f16m2_m	vle16_v_f16m2_m
#define vle_v_f16m4	vle16_v_f16m4
#define vle_v_f16m4_m	vle16_v_f16m4_m
#define vle_v_f16m8	vle16_v_f16m8
#define vle_v_f16m8_m	vle16_v_f16m8_m
#define vle_v_f32m1	vle32_v_f32m1
#define vle_v_f32m1_m	vle32_v_f32m1_m
#define vle_v_f32m2	vle32_v_f32m2
#define vle_v_f32m2_m	vle32_v_f32m2_m
#define vle_v_f32m4	vle32_v_f32m4
#define vle_v_f32m4_m	vle32_v_f32m4_m
#define vle_v_f32m8	vle32_v_f32m8
#define vle_v_f32m8_m	vle32_v_f32m8_m
#define vle_v_f64m1	vle64_v_f64m1
#define vle_v_f64m1_m	vle64_v_f64m1_m
#define vle_v_f64m2	vle64_v_f64m2
#define vle_v_f64m2_m	vle64_v_f64m2_m
#define vle_v_f64m4	vle64_v_f64m4
#define vle_v_f64m4_m	vle64_v_f64m4_m
#define vle_v_f64m8	vle64_v_f64m8
#define vle_v_f64m8_m	vle64_v_f64m8_m

/* Wrapper only.  */
#define vse_v_i8m1	vse8_v_i8m1
#define vse_v_u8m1	vse8_v_u8m1
#define vse_v_i8m1_m	vse8_v_i8m1_m
#define vse_v_u8m1_m	vse8_v_u8m1_m
#define vse_v_i8m2	vse8_v_i8m2
#define vse_v_u8m2	vse8_v_u8m2
#define vse_v_i8m2_m	vse8_v_i8m2_m
#define vse_v_u8m2_m	vse8_v_u8m2_m
#define vse_v_i8m4	vse8_v_i8m4
#define vse_v_u8m4	vse8_v_u8m4
#define vse_v_i8m4_m	vse8_v_i8m4_m
#define vse_v_u8m4_m	vse8_v_u8m4_m
#define vse_v_i8m8	vse8_v_i8m8
#define vse_v_u8m8	vse8_v_u8m8
#define vse_v_i8m8_m	vse8_v_i8m8_m
#define vse_v_u8m8_m	vse8_v_u8m8_m
#define vse_v_i16m1	vse16_v_i16m1
#define vse_v_u16m1	vse16_v_u16m1
#define vse_v_i16m1_m	vse16_v_i16m1_m
#define vse_v_u16m1_m	vse16_v_u16m1_m
#define vse_v_i16m2	vse16_v_i16m2
#define vse_v_u16m2	vse16_v_u16m2
#define vse_v_i16m2_m	vse16_v_i16m2_m
#define vse_v_u16m2_m	vse16_v_u16m2_m
#define vse_v_i16m4	vse16_v_i16m4
#define vse_v_u16m4	vse16_v_u16m4
#define vse_v_i16m4_m	vse16_v_i16m4_m
#define vse_v_u16m4_m	vse16_v_u16m4_m
#define vse_v_i16m8	vse16_v_i16m8
#define vse_v_u16m8	vse16_v_u16m8
#define vse_v_i16m8_m	vse16_v_i16m8_m
#define vse_v_u16m8_m	vse16_v_u16m8_m
#define vse_v_i32m1	vse32_v_i32m1
#define vse_v_u32m1	vse32_v_u32m1
#define vse_v_i32m1_m	vse32_v_i32m1_m
#define vse_v_u32m1_m	vse32_v_u32m1_m
#define vse_v_i32m2	vse32_v_i32m2
#define vse_v_u32m2	vse32_v_u32m2
#define vse_v_i32m2_m	vse32_v_i32m2_m
#define vse_v_u32m2_m	vse32_v_u32m2_m
#define vse_v_i32m4	vse32_v_i32m4
#define vse_v_u32m4	vse32_v_u32m4
#define vse_v_i32m4_m	vse32_v_i32m4_m
#define vse_v_u32m4_m	vse32_v_u32m4_m
#define vse_v_i32m8	vse32_v_i32m8
#define vse_v_u32m8	vse32_v_u32m8
#define vse_v_i32m8_m	vse32_v_i32m8_m
#define vse_v_u32m8_m	vse32_v_u32m8_m
#define vse_v_i64m1	vse64_v_i64m1
#define vse_v_u64m1	vse64_v_u64m1
#define vse_v_i64m1_m	vse64_v_i64m1_m
#define vse_v_u64m1_m	vse64_v_u64m1_m
#define vse_v_i64m2	vse64_v_i64m2
#define vse_v_u64m2	vse64_v_u64m2
#define vse_v_i64m2_m	vse64_v_i64m2_m
#define vse_v_u64m2_m	vse64_v_u64m2_m
#define vse_v_i64m4	vse64_v_i64m4
#define vse_v_u64m4	vse64_v_u64m4
#define vse_v_i64m4_m	vse64_v_i64m4_m
#define vse_v_u64m4_m	vse64_v_u64m4_m
#define vse_v_i64m8	vse64_v_i64m8
#define vse_v_u64m8	vse64_v_u64m8
#define vse_v_i64m8_m	vse64_v_i64m8_m
#define vse_v_u64m8_m	vse64_v_u64m8_m
#define vse_v_f16m1	vse16_v_f16m1
#define vse_v_f16m1_m	vse16_v_f16m1_m
#define vse_v_f16m2	vse16_v_f16m2
#define vse_v_f16m2_m	vse16_v_f16m2_m
#define vse_v_f16m4	vse16_v_f16m4
#define vse_v_f16m4_m	vse16_v_f16m4_m
#define vse_v_f16m8	vse16_v_f16m8
#define vse_v_f16m8_m	vse16_v_f16m8_m
#define vse_v_f32m1	vse32_v_f32m1
#define vse_v_f32m1_m	vse32_v_f32m1_m
#define vse_v_f32m2	vse32_v_f32m2
#define vse_v_f32m2_m	vse32_v_f32m2_m
#define vse_v_f32m4	vse32_v_f32m4
#define vse_v_f32m4_m	vse32_v_f32m4_m
#define vse_v_f32m8	vse32_v_f32m8
#define vse_v_f32m8_m	vse32_v_f32m8_m
#define vse_v_f64m1	vse64_v_f64m1
#define vse_v_f64m1_m	vse64_v_f64m1_m
#define vse_v_f64m2	vse64_v_f64m2
#define vse_v_f64m2_m	vse64_v_f64m2_m
#define vse_v_f64m4	vse64_v_f64m4
#define vse_v_f64m4_m	vse64_v_f64m4_m
#define vse_v_f64m8	vse64_v_f64m8
#define vse_v_f64m8_m	vse64_v_f64m8_m

/* Wrapper only.  */
#define vlse_v_i8m1	vlse8_v_i8m1
#define vlse_v_u8m1	vlse8_v_u8m1
#define vlse_v_i8m1_m	vlse8_v_i8m1_m
#define vlse_v_u8m1_m	vlse8_v_u8m1_m
#define vlse_v_i8m2	vlse8_v_i8m2
#define vlse_v_u8m2	vlse8_v_u8m2
#define vlse_v_i8m2_m	vlse8_v_i8m2_m
#define vlse_v_u8m2_m	vlse8_v_u8m2_m
#define vlse_v_i8m4	vlse8_v_i8m4
#define vlse_v_u8m4	vlse8_v_u8m4
#define vlse_v_i8m4_m	vlse8_v_i8m4_m
#define vlse_v_u8m4_m	vlse8_v_u8m4_m
#define vlse_v_i8m8	vlse8_v_i8m8
#define vlse_v_u8m8	vlse8_v_u8m8
#define vlse_v_i8m8_m	vlse8_v_i8m8_m
#define vlse_v_u8m8_m	vlse8_v_u8m8_m
#define vlse_v_i16m1	vlse16_v_i16m1
#define vlse_v_u16m1	vlse16_v_u16m1
#define vlse_v_i16m1_m	vlse16_v_i16m1_m
#define vlse_v_u16m1_m	vlse16_v_u16m1_m
#define vlse_v_i16m2	vlse16_v_i16m2
#define vlse_v_u16m2	vlse16_v_u16m2
#define vlse_v_i16m2_m	vlse16_v_i16m2_m
#define vlse_v_u16m2_m	vlse16_v_u16m2_m
#define vlse_v_i16m4	vlse16_v_i16m4
#define vlse_v_u16m4	vlse16_v_u16m4
#define vlse_v_i16m4_m	vlse16_v_i16m4_m
#define vlse_v_u16m4_m	vlse16_v_u16m4_m
#define vlse_v_i16m8	vlse16_v_i16m8
#define vlse_v_u16m8	vlse16_v_u16m8
#define vlse_v_i16m8_m	vlse16_v_i16m8_m
#define vlse_v_u16m8_m	vlse16_v_u16m8_m
#define vlse_v_i32m1	vlse32_v_i32m1
#define vlse_v_u32m1	vlse32_v_u32m1
#define vlse_v_i32m1_m	vlse32_v_i32m1_m
#define vlse_v_u32m1_m	vlse32_v_u32m1_m
#define vlse_v_i32m2	vlse32_v_i32m2
#define vlse_v_u32m2	vlse32_v_u32m2
#define vlse_v_i32m2_m	vlse32_v_i32m2_m
#define vlse_v_u32m2_m	vlse32_v_u32m2_m
#define vlse_v_i32m4	vlse32_v_i32m4
#define vlse_v_u32m4	vlse32_v_u32m4
#define vlse_v_i32m4_m	vlse32_v_i32m4_m
#define vlse_v_u32m4_m	vlse32_v_u32m4_m
#define vlse_v_i32m8	vlse32_v_i32m8
#define vlse_v_u32m8	vlse32_v_u32m8
#define vlse_v_i32m8_m	vlse32_v_i32m8_m
#define vlse_v_u32m8_m	vlse32_v_u32m8_m
#define vlse_v_i64m1	vlse64_v_i64m1
#define vlse_v_u64m1	vlse64_v_u64m1
#define vlse_v_i64m1_m	vlse64_v_i64m1_m
#define vlse_v_u64m1_m	vlse64_v_u64m1_m
#define vlse_v_i64m2	vlse64_v_i64m2
#define vlse_v_u64m2	vlse64_v_u64m2
#define vlse_v_i64m2_m	vlse64_v_i64m2_m
#define vlse_v_u64m2_m	vlse64_v_u64m2_m
#define vlse_v_i64m4	vlse64_v_i64m4
#define vlse_v_u64m4	vlse64_v_u64m4
#define vlse_v_i64m4_m	vlse64_v_i64m4_m
#define vlse_v_u64m4_m	vlse64_v_u64m4_m
#define vlse_v_i64m8	vlse64_v_i64m8
#define vlse_v_u64m8	vlse64_v_u64m8
#define vlse_v_i64m8_m	vlse64_v_i64m8_m
#define vlse_v_u64m8_m	vlse64_v_u64m8_m
#define vlse_v_f16m1	vlse16_v_f16m1
#define vlse_v_f16m1_m	vlse16_v_f16m1_m
#define vlse_v_f16m2	vlse16_v_f16m2
#define vlse_v_f16m2_m	vlse16_v_f16m2_m
#define vlse_v_f16m4	vlse16_v_f16m4
#define vlse_v_f16m4_m	vlse16_v_f16m4_m
#define vlse_v_f16m8	vlse16_v_f16m8
#define vlse_v_f16m8_m	vlse16_v_f16m8_m
#define vlse_v_f32m1	vlse32_v_f32m1
#define vlse_v_f32m1_m	vlse32_v_f32m1_m
#define vlse_v_f32m2	vlse32_v_f32m2
#define vlse_v_f32m2_m	vlse32_v_f32m2_m
#define vlse_v_f32m4	vlse32_v_f32m4
#define vlse_v_f32m4_m	vlse32_v_f32m4_m
#define vlse_v_f32m8	vlse32_v_f32m8
#define vlse_v_f32m8_m	vlse32_v_f32m8_m
#define vlse_v_f64m1	vlse64_v_f64m1
#define vlse_v_f64m1_m	vlse64_v_f64m1_m
#define vlse_v_f64m2	vlse64_v_f64m2
#define vlse_v_f64m2_m	vlse64_v_f64m2_m
#define vlse_v_f64m4	vlse64_v_f64m4
#define vlse_v_f64m4_m	vlse64_v_f64m4_m
#define vlse_v_f64m8	vlse64_v_f64m8
#define vlse_v_f64m8_m	vlse64_v_f64m8_m

/* Wrapper only.  */
#define vsse_v_i8m1	vsse8_v_i8m1
#define vsse_v_u8m1	vsse8_v_u8m1
#define vsse_v_i8m1_m	vsse8_v_i8m1_m
#define vsse_v_u8m1_m	vsse8_v_u8m1_m
#define vsse_v_i8m2	vsse8_v_i8m2
#define vsse_v_u8m2	vsse8_v_u8m2
#define vsse_v_i8m2_m	vsse8_v_i8m2_m
#define vsse_v_u8m2_m	vsse8_v_u8m2_m
#define vsse_v_i8m4	vsse8_v_i8m4
#define vsse_v_u8m4	vsse8_v_u8m4
#define vsse_v_i8m4_m	vsse8_v_i8m4_m
#define vsse_v_u8m4_m	vsse8_v_u8m4_m
#define vsse_v_i8m8	vsse8_v_i8m8
#define vsse_v_u8m8	vsse8_v_u8m8
#define vsse_v_i8m8_m	vsse8_v_i8m8_m
#define vsse_v_u8m8_m	vsse8_v_u8m8_m
#define vsse_v_i16m1	vsse16_v_i16m1
#define vsse_v_u16m1	vsse16_v_u16m1
#define vsse_v_i16m1_m	vsse16_v_i16m1_m
#define vsse_v_u16m1_m	vsse16_v_u16m1_m
#define vsse_v_i16m2	vsse16_v_i16m2
#define vsse_v_u16m2	vsse16_v_u16m2
#define vsse_v_i16m2_m	vsse16_v_i16m2_m
#define vsse_v_u16m2_m	vsse16_v_u16m2_m
#define vsse_v_i16m4	vsse16_v_i16m4
#define vsse_v_u16m4	vsse16_v_u16m4
#define vsse_v_i16m4_m	vsse16_v_i16m4_m
#define vsse_v_u16m4_m	vsse16_v_u16m4_m
#define vsse_v_i16m8	vsse16_v_i16m8
#define vsse_v_u16m8	vsse16_v_u16m8
#define vsse_v_i16m8_m	vsse16_v_i16m8_m
#define vsse_v_u16m8_m	vsse16_v_u16m8_m
#define vsse_v_i32m1	vsse32_v_i32m1
#define vsse_v_u32m1	vsse32_v_u32m1
#define vsse_v_i32m1_m	vsse32_v_i32m1_m
#define vsse_v_u32m1_m	vsse32_v_u32m1_m
#define vsse_v_i32m2	vsse32_v_i32m2
#define vsse_v_u32m2	vsse32_v_u32m2
#define vsse_v_i32m2_m	vsse32_v_i32m2_m
#define vsse_v_u32m2_m	vsse32_v_u32m2_m
#define vsse_v_i32m4	vsse32_v_i32m4
#define vsse_v_u32m4	vsse32_v_u32m4
#define vsse_v_i32m4_m	vsse32_v_i32m4_m
#define vsse_v_u32m4_m	vsse32_v_u32m4_m
#define vsse_v_i32m8	vsse32_v_i32m8
#define vsse_v_u32m8	vsse32_v_u32m8
#define vsse_v_i32m8_m	vsse32_v_i32m8_m
#define vsse_v_u32m8_m	vsse32_v_u32m8_m
#define vsse_v_i64m1	vsse64_v_i64m1
#define vsse_v_u64m1	vsse64_v_u64m1
#define vsse_v_i64m1_m	vsse64_v_i64m1_m
#define vsse_v_u64m1_m	vsse64_v_u64m1_m
#define vsse_v_i64m2	vsse64_v_i64m2
#define vsse_v_u64m2	vsse64_v_u64m2
#define vsse_v_i64m2_m	vsse64_v_i64m2_m
#define vsse_v_u64m2_m	vsse64_v_u64m2_m
#define vsse_v_i64m4	vsse64_v_i64m4
#define vsse_v_u64m4	vsse64_v_u64m4
#define vsse_v_i64m4_m	vsse64_v_i64m4_m
#define vsse_v_u64m4_m	vsse64_v_u64m4_m
#define vsse_v_i64m8	vsse64_v_i64m8
#define vsse_v_u64m8	vsse64_v_u64m8
#define vsse_v_i64m8_m	vsse64_v_i64m8_m
#define vsse_v_u64m8_m	vsse64_v_u64m8_m
#define vsse_v_f16m1	vsse16_v_f16m1
#define vsse_v_f16m1_m	vsse16_v_f16m1_m
#define vsse_v_f16m2	vsse16_v_f16m2
#define vsse_v_f16m2_m	vsse16_v_f16m2_m
#define vsse_v_f16m4	vsse16_v_f16m4
#define vsse_v_f16m4_m	vsse16_v_f16m4_m
#define vsse_v_f16m8	vsse16_v_f16m8
#define vsse_v_f16m8_m	vsse16_v_f16m8_m
#define vsse_v_f32m1	vsse32_v_f32m1
#define vsse_v_f32m1_m	vsse32_v_f32m1_m
#define vsse_v_f32m2	vsse32_v_f32m2
#define vsse_v_f32m2_m	vsse32_v_f32m2_m
#define vsse_v_f32m4	vsse32_v_f32m4
#define vsse_v_f32m4_m	vsse32_v_f32m4_m
#define vsse_v_f32m8	vsse32_v_f32m8
#define vsse_v_f32m8_m	vsse32_v_f32m8_m
#define vsse_v_f64m1	vsse64_v_f64m1
#define vsse_v_f64m1_m	vsse64_v_f64m1_m
#define vsse_v_f64m2	vsse64_v_f64m2
#define vsse_v_f64m2_m	vsse64_v_f64m2_m
#define vsse_v_f64m4	vsse64_v_f64m4
#define vsse_v_f64m4_m	vsse64_v_f64m4_m
#define vsse_v_f64m8	vsse64_v_f64m8
#define vsse_v_f64m8_m	vsse64_v_f64m8_m

/* Wrapper only.  */
#define vlxe_v_i8m1	vloxei8_v_i8m1
#define vlxe_v_u8m1	vloxei8_v_u8m1
#define vlxe_v_i8m1_m	vloxei8_v_i8m1_m
#define vlxe_v_u8m1_m	vloxei8_v_u8m1_m
#define vlxe_v_i8m2	vloxei8_v_i8m2
#define vlxe_v_u8m2	vloxei8_v_u8m2
#define vlxe_v_i8m2_m	vloxei8_v_i8m2_m
#define vlxe_v_u8m2_m	vloxei8_v_u8m2_m
#define vlxe_v_i8m4	vloxei8_v_i8m4
#define vlxe_v_u8m4	vloxei8_v_u8m4
#define vlxe_v_i8m4_m	vloxei8_v_i8m4_m
#define vlxe_v_u8m4_m	vloxei8_v_u8m4_m
#define vlxe_v_i8m8	vloxei8_v_i8m8
#define vlxe_v_u8m8	vloxei8_v_u8m8
#define vlxe_v_i8m8_m	vloxei8_v_i8m8_m
#define vlxe_v_u8m8_m	vloxei8_v_u8m8_m
#define vlxe_v_i16m1	vloxei16_v_i16m1
#define vlxe_v_u16m1	vloxei16_v_u16m1
#define vlxe_v_i16m1_m	vloxei16_v_i16m1_m
#define vlxe_v_u16m1_m	vloxei16_v_u16m1_m
#define vlxe_v_i16m2	vloxei16_v_i16m2
#define vlxe_v_u16m2	vloxei16_v_u16m2
#define vlxe_v_i16m2_m	vloxei16_v_i16m2_m
#define vlxe_v_u16m2_m	vloxei16_v_u16m2_m
#define vlxe_v_i16m4	vloxei16_v_i16m4
#define vlxe_v_u16m4	vloxei16_v_u16m4
#define vlxe_v_i16m4_m	vloxei16_v_i16m4_m
#define vlxe_v_u16m4_m	vloxei16_v_u16m4_m
#define vlxe_v_i16m8	vloxei16_v_i16m8
#define vlxe_v_u16m8	vloxei16_v_u16m8
#define vlxe_v_i16m8_m	vloxei16_v_i16m8_m
#define vlxe_v_u16m8_m	vloxei16_v_u16m8_m
#define vlxe_v_i32m1	vloxei32_v_i32m1
#define vlxe_v_u32m1	vloxei32_v_u32m1
#define vlxe_v_i32m1_m	vloxei32_v_i32m1_m
#define vlxe_v_u32m1_m	vloxei32_v_u32m1_m
#define vlxe_v_i32m2	vloxei32_v_i32m2
#define vlxe_v_u32m2	vloxei32_v_u32m2
#define vlxe_v_i32m2_m	vloxei32_v_i32m2_m
#define vlxe_v_u32m2_m	vloxei32_v_u32m2_m
#define vlxe_v_i32m4	vloxei32_v_i32m4
#define vlxe_v_u32m4	vloxei32_v_u32m4
#define vlxe_v_i32m4_m	vloxei32_v_i32m4_m
#define vlxe_v_u32m4_m	vloxei32_v_u32m4_m
#define vlxe_v_i32m8	vloxei32_v_i32m8
#define vlxe_v_u32m8	vloxei32_v_u32m8
#define vlxe_v_i32m8_m	vloxei32_v_i32m8_m
#define vlxe_v_u32m8_m	vloxei32_v_u32m8_m
#define vlxe_v_i64m1	vloxei64_v_i64m1
#define vlxe_v_u64m1	vloxei64_v_u64m1
#define vlxe_v_i64m1_m	vloxei64_v_i64m1_m
#define vlxe_v_u64m1_m	vloxei64_v_u64m1_m
#define vlxe_v_i64m2	vloxei64_v_i64m2
#define vlxe_v_u64m2	vloxei64_v_u64m2
#define vlxe_v_i64m2_m	vloxei64_v_i64m2_m
#define vlxe_v_u64m2_m	vloxei64_v_u64m2_m
#define vlxe_v_i64m4	vloxei64_v_i64m4
#define vlxe_v_u64m4	vloxei64_v_u64m4
#define vlxe_v_i64m4_m	vloxei64_v_i64m4_m
#define vlxe_v_u64m4_m	vloxei64_v_u64m4_m
#define vlxe_v_i64m8	vloxei64_v_i64m8
#define vlxe_v_u64m8	vloxei64_v_u64m8
#define vlxe_v_i64m8_m	vloxei64_v_i64m8_m
#define vlxe_v_u64m8_m	vloxei64_v_u64m8_m
#define vlxe_v_f16m1	vloxei16_v_f16m1
#define vlxe_v_f16m1_m	vloxei16_v_f16m1_m
#define vlxe_v_f16m2	vloxei16_v_f16m2
#define vlxe_v_f16m2_m	vloxei16_v_f16m2_m
#define vlxe_v_f16m4	vloxei16_v_f16m4
#define vlxe_v_f16m4_m	vloxei16_v_f16m4_m
#define vlxe_v_f16m8	vloxei16_v_f16m8
#define vlxe_v_f16m8_m	vloxei16_v_f16m8_m
#define vlxe_v_f32m1	vloxei32_v_f32m1
#define vlxe_v_f32m1_m	vloxei32_v_f32m1_m
#define vlxe_v_f32m2	vloxei32_v_f32m2
#define vlxe_v_f32m2_m	vloxei32_v_f32m2_m
#define vlxe_v_f32m4	vloxei32_v_f32m4
#define vlxe_v_f32m4_m	vloxei32_v_f32m4_m
#define vlxe_v_f32m8	vloxei32_v_f32m8
#define vlxe_v_f32m8_m	vloxei32_v_f32m8_m
#define vlxe_v_f64m1	vloxei64_v_f64m1
#define vlxe_v_f64m1_m	vloxei64_v_f64m1_m
#define vlxe_v_f64m2	vloxei64_v_f64m2
#define vlxe_v_f64m2_m	vloxei64_v_f64m2_m
#define vlxe_v_f64m4	vloxei64_v_f64m4
#define vlxe_v_f64m4_m	vloxei64_v_f64m4_m
#define vlxe_v_f64m8	vloxei64_v_f64m8
#define vlxe_v_f64m8_m	vloxei64_v_f64m8_m

/* Wrapper only.  */
#define vsxe_v_i8m1	vsoxei8_v_i8m1
#define vsxe_v_u8m1	vsoxei8_v_u8m1
#define vsxe_v_i8m1_m	vsoxei8_v_i8m1_m
#define vsxe_v_u8m1_m	vsoxei8_v_u8m1_m
#define vsxe_v_i8m2	vsoxei8_v_i8m2
#define vsxe_v_u8m2	vsoxei8_v_u8m2
#define vsxe_v_i8m2_m	vsoxei8_v_i8m2_m
#define vsxe_v_u8m2_m	vsoxei8_v_u8m2_m
#define vsxe_v_i8m4	vsoxei8_v_i8m4
#define vsxe_v_u8m4	vsoxei8_v_u8m4
#define vsxe_v_i8m4_m	vsoxei8_v_i8m4_m
#define vsxe_v_u8m4_m	vsoxei8_v_u8m4_m
#define vsxe_v_i8m8	vsoxei8_v_i8m8
#define vsxe_v_u8m8	vsoxei8_v_u8m8
#define vsxe_v_i8m8_m	vsoxei8_v_i8m8_m
#define vsxe_v_u8m8_m	vsoxei8_v_u8m8_m
#define vsxe_v_i16m1	vsoxei16_v_i16m1
#define vsxe_v_u16m1	vsoxei16_v_u16m1
#define vsxe_v_i16m1_m	vsoxei16_v_i16m1_m
#define vsxe_v_u16m1_m	vsoxei16_v_u16m1_m
#define vsxe_v_i16m2	vsoxei16_v_i16m2
#define vsxe_v_u16m2	vsoxei16_v_u16m2
#define vsxe_v_i16m2_m	vsoxei16_v_i16m2_m
#define vsxe_v_u16m2_m	vsoxei16_v_u16m2_m
#define vsxe_v_i16m4	vsoxei16_v_i16m4
#define vsxe_v_u16m4	vsoxei16_v_u16m4
#define vsxe_v_i16m4_m	vsoxei16_v_i16m4_m
#define vsxe_v_u16m4_m	vsoxei16_v_u16m4_m
#define vsxe_v_i16m8	vsoxei16_v_i16m8
#define vsxe_v_u16m8	vsoxei16_v_u16m8
#define vsxe_v_i16m8_m	vsoxei16_v_i16m8_m
#define vsxe_v_u16m8_m	vsoxei16_v_u16m8_m
#define vsxe_v_i32m1	vsoxei32_v_i32m1
#define vsxe_v_u32m1	vsoxei32_v_u32m1
#define vsxe_v_i32m1_m	vsoxei32_v_i32m1_m
#define vsxe_v_u32m1_m	vsoxei32_v_u32m1_m
#define vsxe_v_i32m2	vsoxei32_v_i32m2
#define vsxe_v_u32m2	vsoxei32_v_u32m2
#define vsxe_v_i32m2_m	vsoxei32_v_i32m2_m
#define vsxe_v_u32m2_m	vsoxei32_v_u32m2_m
#define vsxe_v_i32m4	vsoxei32_v_i32m4
#define vsxe_v_u32m4	vsoxei32_v_u32m4
#define vsxe_v_i32m4_m	vsoxei32_v_i32m4_m
#define vsxe_v_u32m4_m	vsoxei32_v_u32m4_m
#define vsxe_v_i32m8	vsoxei32_v_i32m8
#define vsxe_v_u32m8	vsoxei32_v_u32m8
#define vsxe_v_i32m8_m	vsoxei32_v_i32m8_m
#define vsxe_v_u32m8_m	vsoxei32_v_u32m8_m
#define vsxe_v_i64m1	vsoxei64_v_i64m1
#define vsxe_v_u64m1	vsoxei64_v_u64m1
#define vsxe_v_i64m1_m	vsoxei64_v_i64m1_m
#define vsxe_v_u64m1_m	vsoxei64_v_u64m1_m
#define vsxe_v_i64m2	vsoxei64_v_i64m2
#define vsxe_v_u64m2	vsoxei64_v_u64m2
#define vsxe_v_i64m2_m	vsoxei64_v_i64m2_m
#define vsxe_v_u64m2_m	vsoxei64_v_u64m2_m
#define vsxe_v_i64m4	vsoxei64_v_i64m4
#define vsxe_v_u64m4	vsoxei64_v_u64m4
#define vsxe_v_i64m4_m	vsoxei64_v_i64m4_m
#define vsxe_v_u64m4_m	vsoxei64_v_u64m4_m
#define vsxe_v_i64m8	vsoxei64_v_i64m8
#define vsxe_v_u64m8	vsoxei64_v_u64m8
#define vsxe_v_i64m8_m	vsoxei64_v_i64m8_m
#define vsxe_v_u64m8_m	vsoxei64_v_u64m8_m
#define vsxe_v_f16m1	vsoxei16_v_f16m1
#define vsxe_v_f16m1_m	vsoxei16_v_f16m1_m
#define vsxe_v_f16m2	vsoxei16_v_f16m2
#define vsxe_v_f16m2_m	vsoxei16_v_f16m2_m
#define vsxe_v_f16m4	vsoxei16_v_f16m4
#define vsxe_v_f16m4_m	vsoxei16_v_f16m4_m
#define vsxe_v_f16m8	vsoxei16_v_f16m8
#define vsxe_v_f16m8_m	vsoxei16_v_f16m8_m
#define vsxe_v_f32m1	vsoxei32_v_f32m1
#define vsxe_v_f32m1_m	vsoxei32_v_f32m1_m
#define vsxe_v_f32m2	vsoxei32_v_f32m2
#define vsxe_v_f32m2_m	vsoxei32_v_f32m2_m
#define vsxe_v_f32m4	vsoxei32_v_f32m4
#define vsxe_v_f32m4_m	vsoxei32_v_f32m4_m
#define vsxe_v_f32m8	vsoxei32_v_f32m8
#define vsxe_v_f32m8_m	vsoxei32_v_f32m8_m
#define vsxe_v_f64m1	vsoxei64_v_f64m1
#define vsxe_v_f64m1_m	vsoxei64_v_f64m1_m
#define vsxe_v_f64m2	vsoxei64_v_f64m2
#define vsxe_v_f64m2_m	vsoxei64_v_f64m2_m
#define vsxe_v_f64m4	vsoxei64_v_f64m4
#define vsxe_v_f64m4_m	vsoxei64_v_f64m4_m
#define vsxe_v_f64m8	vsoxei64_v_f64m8
#define vsxe_v_f64m8_m	vsoxei64_v_f64m8_m

/* Wrapper only.  */
#define vsuxe_v_i8m1	vsuxei8_v_i8m1
#define vsuxe_v_u8m1	vsuxei8_v_u8m1
#define vsuxe_v_i8m1_m	vsuxei8_v_i8m1_m
#define vsuxe_v_u8m1_m	vsuxei8_v_u8m1_m
#define vsuxe_v_i8m2	vsuxei8_v_i8m2
#define vsuxe_v_u8m2	vsuxei8_v_u8m2
#define vsuxe_v_i8m2_m	vsuxei8_v_i8m2_m
#define vsuxe_v_u8m2_m	vsuxei8_v_u8m2_m
#define vsuxe_v_i8m4	vsuxei8_v_i8m4
#define vsuxe_v_u8m4	vsuxei8_v_u8m4
#define vsuxe_v_i8m4_m	vsuxei8_v_i8m4_m
#define vsuxe_v_u8m4_m	vsuxei8_v_u8m4_m
#define vsuxe_v_i8m8	vsuxei8_v_i8m8
#define vsuxe_v_u8m8	vsuxei8_v_u8m8
#define vsuxe_v_i8m8_m	vsuxei8_v_i8m8_m
#define vsuxe_v_u8m8_m	vsuxei8_v_u8m8_m
#define vsuxe_v_i16m1	vsuxei16_v_i16m1
#define vsuxe_v_u16m1	vsuxei16_v_u16m1
#define vsuxe_v_i16m1_m	vsuxei16_v_i16m1_m
#define vsuxe_v_u16m1_m	vsuxei16_v_u16m1_m
#define vsuxe_v_i16m2	vsuxei16_v_i16m2
#define vsuxe_v_u16m2	vsuxei16_v_u16m2
#define vsuxe_v_i16m2_m	vsuxei16_v_i16m2_m
#define vsuxe_v_u16m2_m	vsuxei16_v_u16m2_m
#define vsuxe_v_i16m4	vsuxei16_v_i16m4
#define vsuxe_v_u16m4	vsuxei16_v_u16m4
#define vsuxe_v_i16m4_m	vsuxei16_v_i16m4_m
#define vsuxe_v_u16m4_m	vsuxei16_v_u16m4_m
#define vsuxe_v_i16m8	vsuxei16_v_i16m8
#define vsuxe_v_u16m8	vsuxei16_v_u16m8
#define vsuxe_v_i16m8_m	vsuxei16_v_i16m8_m
#define vsuxe_v_u16m8_m	vsuxei16_v_u16m8_m
#define vsuxe_v_i32m1	vsuxei32_v_i32m1
#define vsuxe_v_u32m1	vsuxei32_v_u32m1
#define vsuxe_v_i32m1_m	vsuxei32_v_i32m1_m
#define vsuxe_v_u32m1_m	vsuxei32_v_u32m1_m
#define vsuxe_v_i32m2	vsuxei32_v_i32m2
#define vsuxe_v_u32m2	vsuxei32_v_u32m2
#define vsuxe_v_i32m2_m	vsuxei32_v_i32m2_m
#define vsuxe_v_u32m2_m	vsuxei32_v_u32m2_m
#define vsuxe_v_i32m4	vsuxei32_v_i32m4
#define vsuxe_v_u32m4	vsuxei32_v_u32m4
#define vsuxe_v_i32m4_m	vsuxei32_v_i32m4_m
#define vsuxe_v_u32m4_m	vsuxei32_v_u32m4_m
#define vsuxe_v_i32m8	vsuxei32_v_i32m8
#define vsuxe_v_u32m8	vsuxei32_v_u32m8
#define vsuxe_v_i32m8_m	vsuxei32_v_i32m8_m
#define vsuxe_v_u32m8_m	vsuxei32_v_u32m8_m
#define vsuxe_v_i64m1	vsuxei64_v_i64m1
#define vsuxe_v_u64m1	vsuxei64_v_u64m1
#define vsuxe_v_i64m1_m	vsuxei64_v_i64m1_m
#define vsuxe_v_u64m1_m	vsuxei64_v_u64m1_m
#define vsuxe_v_i64m2	vsuxei64_v_i64m2
#define vsuxe_v_u64m2	vsuxei64_v_u64m2
#define vsuxe_v_i64m2_m	vsuxei64_v_i64m2_m
#define vsuxe_v_u64m2_m	vsuxei64_v_u64m2_m
#define vsuxe_v_i64m4	vsuxei64_v_i64m4
#define vsuxe_v_u64m4	vsuxei64_v_u64m4
#define vsuxe_v_i64m4_m	vsuxei64_v_i64m4_m
#define vsuxe_v_u64m4_m	vsuxei64_v_u64m4_m
#define vsuxe_v_i64m8	vsuxei64_v_i64m8
#define vsuxe_v_u64m8	vsuxei64_v_u64m8
#define vsuxe_v_i64m8_m	vsuxei64_v_i64m8_m
#define vsuxe_v_u64m8_m	vsuxei64_v_u64m8_m
#define vsuxe_v_f16m1	vsuxei16_v_f16m1
#define vsuxe_v_f16m1_m	vsuxei16_v_f16m1_m
#define vsuxe_v_f16m2	vsuxei16_v_f16m2
#define vsuxe_v_f16m2_m	vsuxei16_v_f16m2_m
#define vsuxe_v_f16m4	vsuxei16_v_f16m4
#define vsuxe_v_f16m4_m	vsuxei16_v_f16m4_m
#define vsuxe_v_f16m8	vsuxei16_v_f16m8
#define vsuxe_v_f16m8_m	vsuxei16_v_f16m8_m
#define vsuxe_v_f32m1	vsuxei32_v_f32m1
#define vsuxe_v_f32m1_m	vsuxei32_v_f32m1_m
#define vsuxe_v_f32m2	vsuxei32_v_f32m2
#define vsuxe_v_f32m2_m	vsuxei32_v_f32m2_m
#define vsuxe_v_f32m4	vsuxei32_v_f32m4
#define vsuxe_v_f32m4_m	vsuxei32_v_f32m4_m
#define vsuxe_v_f32m8	vsuxei32_v_f32m8
#define vsuxe_v_f32m8_m	vsuxei32_v_f32m8_m
#define vsuxe_v_f64m1	vsuxei64_v_f64m1
#define vsuxe_v_f64m1_m	vsuxei64_v_f64m1_m
#define vsuxe_v_f64m2	vsuxei64_v_f64m2
#define vsuxe_v_f64m2_m	vsuxei64_v_f64m2_m
#define vsuxe_v_f64m4	vsuxei64_v_f64m4
#define vsuxe_v_f64m4_m	vsuxei64_v_f64m4_m
#define vsuxe_v_f64m8	vsuxei64_v_f64m8
#define vsuxe_v_f64m8_m	vsuxei64_v_f64m8_m

/* Wrapper only.  */
#define vleff_v_i8m1	vle8ff_v_i8m1
#define vleff_v_u8m1	vle8ff_v_u8m1
#define vleff_v_i8m1_m	vle8ff_v_i8m1_m
#define vleff_v_u8m1_m	vle8ff_v_u8m1_m
#define vleff_v_i8m2	vle8ff_v_i8m2
#define vleff_v_u8m2	vle8ff_v_u8m2
#define vleff_v_i8m2_m	vle8ff_v_i8m2_m
#define vleff_v_u8m2_m	vle8ff_v_u8m2_m
#define vleff_v_i8m4	vle8ff_v_i8m4
#define vleff_v_u8m4	vle8ff_v_u8m4
#define vleff_v_i8m4_m	vle8ff_v_i8m4_m
#define vleff_v_u8m4_m	vle8ff_v_u8m4_m
#define vleff_v_i8m8	vle8ff_v_i8m8
#define vleff_v_u8m8	vle8ff_v_u8m8
#define vleff_v_i8m8_m	vle8ff_v_i8m8_m
#define vleff_v_u8m8_m	vle8ff_v_u8m8_m
#define vleff_v_i16m1	vle16ff_v_i16m1
#define vleff_v_u16m1	vle16ff_v_u16m1
#define vleff_v_i16m1_m	vle16ff_v_i16m1_m
#define vleff_v_u16m1_m	vle16ff_v_u16m1_m
#define vleff_v_i16m2	vle16ff_v_i16m2
#define vleff_v_u16m2	vle16ff_v_u16m2
#define vleff_v_i16m2_m	vle16ff_v_i16m2_m
#define vleff_v_u16m2_m	vle16ff_v_u16m2_m
#define vleff_v_i16m4	vle16ff_v_i16m4
#define vleff_v_u16m4	vle16ff_v_u16m4
#define vleff_v_i16m4_m	vle16ff_v_i16m4_m
#define vleff_v_u16m4_m	vle16ff_v_u16m4_m
#define vleff_v_i16m8	vle16ff_v_i16m8
#define vleff_v_u16m8	vle16ff_v_u16m8
#define vleff_v_i16m8_m	vle16ff_v_i16m8_m
#define vleff_v_u16m8_m	vle16ff_v_u16m8_m
#define vleff_v_i32m1	vle32ff_v_i32m1
#define vleff_v_u32m1	vle32ff_v_u32m1
#define vleff_v_i32m1_m	vle32ff_v_i32m1_m
#define vleff_v_u32m1_m	vle32ff_v_u32m1_m
#define vleff_v_i32m2	vle32ff_v_i32m2
#define vleff_v_u32m2	vle32ff_v_u32m2
#define vleff_v_i32m2_m	vle32ff_v_i32m2_m
#define vleff_v_u32m2_m	vle32ff_v_u32m2_m
#define vleff_v_i32m4	vle32ff_v_i32m4
#define vleff_v_u32m4	vle32ff_v_u32m4
#define vleff_v_i32m4_m	vle32ff_v_i32m4_m
#define vleff_v_u32m4_m	vle32ff_v_u32m4_m
#define vleff_v_i32m8	vle32ff_v_i32m8
#define vleff_v_u32m8	vle32ff_v_u32m8
#define vleff_v_i32m8_m	vle32ff_v_i32m8_m
#define vleff_v_u32m8_m	vle32ff_v_u32m8_m
#define vleff_v_i64m1	vle64ff_v_i64m1
#define vleff_v_u64m1	vle64ff_v_u64m1
#define vleff_v_i64m1_m	vle64ff_v_i64m1_m
#define vleff_v_u64m1_m	vle64ff_v_u64m1_m
#define vleff_v_i64m2	vle64ff_v_i64m2
#define vleff_v_u64m2	vle64ff_v_u64m2
#define vleff_v_i64m2_m	vle64ff_v_i64m2_m
#define vleff_v_u64m2_m	vle64ff_v_u64m2_m
#define vleff_v_i64m4	vle64ff_v_i64m4
#define vleff_v_u64m4	vle64ff_v_u64m4
#define vleff_v_i64m4_m	vle64ff_v_i64m4_m
#define vleff_v_u64m4_m	vle64ff_v_u64m4_m
#define vleff_v_i64m8	vle64ff_v_i64m8
#define vleff_v_u64m8	vle64ff_v_u64m8
#define vleff_v_i64m8_m	vle64ff_v_i64m8_m
#define vleff_v_u64m8_m	vle64ff_v_u64m8_m
#define vleff_v_f16m1	vle16ff_v_f16m1
#define vleff_v_f16m1_m	vle16ff_v_f16m1_m
#define vleff_v_f16m2	vle16ff_v_f16m2
#define vleff_v_f16m2_m	vle16ff_v_f16m2_m
#define vleff_v_f16m4	vle16ff_v_f16m4
#define vleff_v_f16m4_m	vle16ff_v_f16m4_m
#define vleff_v_f16m8	vle16ff_v_f16m8
#define vleff_v_f16m8_m	vle16ff_v_f16m8_m
#define vleff_v_f32m1	vle32ff_v_f32m1
#define vleff_v_f32m1_m	vle32ff_v_f32m1_m
#define vleff_v_f32m2	vle32ff_v_f32m2
#define vleff_v_f32m2_m	vle32ff_v_f32m2_m
#define vleff_v_f32m4	vle32ff_v_f32m4
#define vleff_v_f32m4_m	vle32ff_v_f32m4_m
#define vleff_v_f32m8	vle32ff_v_f32m8
#define vleff_v_f32m8_m	vle32ff_v_f32m8_m
#define vleff_v_f64m1	vle64ff_v_f64m1
#define vleff_v_f64m1_m	vle64ff_v_f64m1_m
#define vleff_v_f64m2	vle64ff_v_f64m2
#define vleff_v_f64m2_m	vle64ff_v_f64m2_m
#define vleff_v_f64m4	vle64ff_v_f64m4
#define vleff_v_f64m4_m	vle64ff_v_f64m4_m
#define vleff_v_f64m8	vle64ff_v_f64m8
#define vleff_v_f64m8_m	vle64ff_v_f64m8_m

/* Wrapper only.  */
#define vlseg2e_v_i8m1x2	vlseg2e8_v_i8m1x2
#define vlseg2e_v_u8m1x2	vlseg2e8_v_u8m1x2
#define vlseg2e_v_i8m1x2_m	vlseg2e8_v_i8m1x2_m
#define vlseg2e_v_u8m1x2_m	vlseg2e8_v_u8m1x2_m
#define vlseg3e_v_i8m1x3	vlseg3e8_v_i8m1x3
#define vlseg3e_v_u8m1x3	vlseg3e8_v_u8m1x3
#define vlseg3e_v_i8m1x3_m	vlseg3e8_v_i8m1x3_m
#define vlseg3e_v_u8m1x3_m	vlseg3e8_v_u8m1x3_m
#define vlseg4e_v_i8m1x4	vlseg4e8_v_i8m1x4
#define vlseg4e_v_u8m1x4	vlseg4e8_v_u8m1x4
#define vlseg4e_v_i8m1x4_m	vlseg4e8_v_i8m1x4_m
#define vlseg4e_v_u8m1x4_m	vlseg4e8_v_u8m1x4_m
#define vlseg5e_v_i8m1x5	vlseg5e8_v_i8m1x5
#define vlseg5e_v_u8m1x5	vlseg5e8_v_u8m1x5
#define vlseg5e_v_i8m1x5_m	vlseg5e8_v_i8m1x5_m
#define vlseg5e_v_u8m1x5_m	vlseg5e8_v_u8m1x5_m
#define vlseg6e_v_i8m1x6	vlseg6e8_v_i8m1x6
#define vlseg6e_v_u8m1x6	vlseg6e8_v_u8m1x6
#define vlseg6e_v_i8m1x6_m	vlseg6e8_v_i8m1x6_m
#define vlseg6e_v_u8m1x6_m	vlseg6e8_v_u8m1x6_m
#define vlseg7e_v_i8m1x7	vlseg7e8_v_i8m1x7
#define vlseg7e_v_u8m1x7	vlseg7e8_v_u8m1x7
#define vlseg7e_v_i8m1x7_m	vlseg7e8_v_i8m1x7_m
#define vlseg7e_v_u8m1x7_m	vlseg7e8_v_u8m1x7_m
#define vlseg8e_v_i8m1x8	vlseg8e8_v_i8m1x8
#define vlseg8e_v_u8m1x8	vlseg8e8_v_u8m1x8
#define vlseg8e_v_i8m1x8_m	vlseg8e8_v_i8m1x8_m
#define vlseg8e_v_u8m1x8_m	vlseg8e8_v_u8m1x8_m
#define vlseg2e_v_i8m2x2	vlseg2e8_v_i8m2x2
#define vlseg2e_v_u8m2x2	vlseg2e8_v_u8m2x2
#define vlseg2e_v_i8m2x2_m	vlseg2e8_v_i8m2x2_m
#define vlseg2e_v_u8m2x2_m	vlseg2e8_v_u8m2x2_m
#define vlseg3e_v_i8m2x3	vlseg3e8_v_i8m2x3
#define vlseg3e_v_u8m2x3	vlseg3e8_v_u8m2x3
#define vlseg3e_v_i8m2x3_m	vlseg3e8_v_i8m2x3_m
#define vlseg3e_v_u8m2x3_m	vlseg3e8_v_u8m2x3_m
#define vlseg4e_v_i8m2x4	vlseg4e8_v_i8m2x4
#define vlseg4e_v_u8m2x4	vlseg4e8_v_u8m2x4
#define vlseg4e_v_i8m2x4_m	vlseg4e8_v_i8m2x4_m
#define vlseg4e_v_u8m2x4_m	vlseg4e8_v_u8m2x4_m
#define vlseg2e_v_i8m4x2	vlseg2e8_v_i8m4x2
#define vlseg2e_v_u8m4x2	vlseg2e8_v_u8m4x2
#define vlseg2e_v_i8m4x2_m	vlseg2e8_v_i8m4x2_m
#define vlseg2e_v_u8m4x2_m	vlseg2e8_v_u8m4x2_m
#define vlseg2e_v_i16m1x2	vlseg2e16_v_i16m1x2
#define vlseg2e_v_u16m1x2	vlseg2e16_v_u16m1x2
#define vlseg2e_v_i16m1x2_m	vlseg2e16_v_i16m1x2_m
#define vlseg2e_v_u16m1x2_m	vlseg2e16_v_u16m1x2_m
#define vlseg3e_v_i16m1x3	vlseg3e16_v_i16m1x3
#define vlseg3e_v_u16m1x3	vlseg3e16_v_u16m1x3
#define vlseg3e_v_i16m1x3_m	vlseg3e16_v_i16m1x3_m
#define vlseg3e_v_u16m1x3_m	vlseg3e16_v_u16m1x3_m
#define vlseg4e_v_i16m1x4	vlseg4e16_v_i16m1x4
#define vlseg4e_v_u16m1x4	vlseg4e16_v_u16m1x4
#define vlseg4e_v_i16m1x4_m	vlseg4e16_v_i16m1x4_m
#define vlseg4e_v_u16m1x4_m	vlseg4e16_v_u16m1x4_m
#define vlseg5e_v_i16m1x5	vlseg5e16_v_i16m1x5
#define vlseg5e_v_u16m1x5	vlseg5e16_v_u16m1x5
#define vlseg5e_v_i16m1x5_m	vlseg5e16_v_i16m1x5_m
#define vlseg5e_v_u16m1x5_m	vlseg5e16_v_u16m1x5_m
#define vlseg6e_v_i16m1x6	vlseg6e16_v_i16m1x6
#define vlseg6e_v_u16m1x6	vlseg6e16_v_u16m1x6
#define vlseg6e_v_i16m1x6_m	vlseg6e16_v_i16m1x6_m
#define vlseg6e_v_u16m1x6_m	vlseg6e16_v_u16m1x6_m
#define vlseg7e_v_i16m1x7	vlseg7e16_v_i16m1x7
#define vlseg7e_v_u16m1x7	vlseg7e16_v_u16m1x7
#define vlseg7e_v_i16m1x7_m	vlseg7e16_v_i16m1x7_m
#define vlseg7e_v_u16m1x7_m	vlseg7e16_v_u16m1x7_m
#define vlseg8e_v_i16m1x8	vlseg8e16_v_i16m1x8
#define vlseg8e_v_u16m1x8	vlseg8e16_v_u16m1x8
#define vlseg8e_v_i16m1x8_m	vlseg8e16_v_i16m1x8_m
#define vlseg8e_v_u16m1x8_m	vlseg8e16_v_u16m1x8_m
#define vlseg2e_v_i16m2x2	vlseg2e16_v_i16m2x2
#define vlseg2e_v_u16m2x2	vlseg2e16_v_u16m2x2
#define vlseg2e_v_i16m2x2_m	vlseg2e16_v_i16m2x2_m
#define vlseg2e_v_u16m2x2_m	vlseg2e16_v_u16m2x2_m
#define vlseg3e_v_i16m2x3	vlseg3e16_v_i16m2x3
#define vlseg3e_v_u16m2x3	vlseg3e16_v_u16m2x3
#define vlseg3e_v_i16m2x3_m	vlseg3e16_v_i16m2x3_m
#define vlseg3e_v_u16m2x3_m	vlseg3e16_v_u16m2x3_m
#define vlseg4e_v_i16m2x4	vlseg4e16_v_i16m2x4
#define vlseg4e_v_u16m2x4	vlseg4e16_v_u16m2x4
#define vlseg4e_v_i16m2x4_m	vlseg4e16_v_i16m2x4_m
#define vlseg4e_v_u16m2x4_m	vlseg4e16_v_u16m2x4_m
#define vlseg2e_v_i16m4x2	vlseg2e16_v_i16m4x2
#define vlseg2e_v_u16m4x2	vlseg2e16_v_u16m4x2
#define vlseg2e_v_i16m4x2_m	vlseg2e16_v_i16m4x2_m
#define vlseg2e_v_u16m4x2_m	vlseg2e16_v_u16m4x2_m
#define vlseg2e_v_i32m1x2	vlseg2e32_v_i32m1x2
#define vlseg2e_v_u32m1x2	vlseg2e32_v_u32m1x2
#define vlseg2e_v_i32m1x2_m	vlseg2e32_v_i32m1x2_m
#define vlseg2e_v_u32m1x2_m	vlseg2e32_v_u32m1x2_m
#define vlseg3e_v_i32m1x3	vlseg3e32_v_i32m1x3
#define vlseg3e_v_u32m1x3	vlseg3e32_v_u32m1x3
#define vlseg3e_v_i32m1x3_m	vlseg3e32_v_i32m1x3_m
#define vlseg3e_v_u32m1x3_m	vlseg3e32_v_u32m1x3_m
#define vlseg4e_v_i32m1x4	vlseg4e32_v_i32m1x4
#define vlseg4e_v_u32m1x4	vlseg4e32_v_u32m1x4
#define vlseg4e_v_i32m1x4_m	vlseg4e32_v_i32m1x4_m
#define vlseg4e_v_u32m1x4_m	vlseg4e32_v_u32m1x4_m
#define vlseg5e_v_i32m1x5	vlseg5e32_v_i32m1x5
#define vlseg5e_v_u32m1x5	vlseg5e32_v_u32m1x5
#define vlseg5e_v_i32m1x5_m	vlseg5e32_v_i32m1x5_m
#define vlseg5e_v_u32m1x5_m	vlseg5e32_v_u32m1x5_m
#define vlseg6e_v_i32m1x6	vlseg6e32_v_i32m1x6
#define vlseg6e_v_u32m1x6	vlseg6e32_v_u32m1x6
#define vlseg6e_v_i32m1x6_m	vlseg6e32_v_i32m1x6_m
#define vlseg6e_v_u32m1x6_m	vlseg6e32_v_u32m1x6_m
#define vlseg7e_v_i32m1x7	vlseg7e32_v_i32m1x7
#define vlseg7e_v_u32m1x7	vlseg7e32_v_u32m1x7
#define vlseg7e_v_i32m1x7_m	vlseg7e32_v_i32m1x7_m
#define vlseg7e_v_u32m1x7_m	vlseg7e32_v_u32m1x7_m
#define vlseg8e_v_i32m1x8	vlseg8e32_v_i32m1x8
#define vlseg8e_v_u32m1x8	vlseg8e32_v_u32m1x8
#define vlseg8e_v_i32m1x8_m	vlseg8e32_v_i32m1x8_m
#define vlseg8e_v_u32m1x8_m	vlseg8e32_v_u32m1x8_m
#define vlseg2e_v_i32m2x2	vlseg2e32_v_i32m2x2
#define vlseg2e_v_u32m2x2	vlseg2e32_v_u32m2x2
#define vlseg2e_v_i32m2x2_m	vlseg2e32_v_i32m2x2_m
#define vlseg2e_v_u32m2x2_m	vlseg2e32_v_u32m2x2_m
#define vlseg3e_v_i32m2x3	vlseg3e32_v_i32m2x3
#define vlseg3e_v_u32m2x3	vlseg3e32_v_u32m2x3
#define vlseg3e_v_i32m2x3_m	vlseg3e32_v_i32m2x3_m
#define vlseg3e_v_u32m2x3_m	vlseg3e32_v_u32m2x3_m
#define vlseg4e_v_i32m2x4	vlseg4e32_v_i32m2x4
#define vlseg4e_v_u32m2x4	vlseg4e32_v_u32m2x4
#define vlseg4e_v_i32m2x4_m	vlseg4e32_v_i32m2x4_m
#define vlseg4e_v_u32m2x4_m	vlseg4e32_v_u32m2x4_m
#define vlseg2e_v_i32m4x2	vlseg2e32_v_i32m4x2
#define vlseg2e_v_u32m4x2	vlseg2e32_v_u32m4x2
#define vlseg2e_v_i32m4x2_m	vlseg2e32_v_i32m4x2_m
#define vlseg2e_v_u32m4x2_m	vlseg2e32_v_u32m4x2_m
#define vlseg2e_v_i64m1x2	vlseg2e64_v_i64m1x2
#define vlseg2e_v_u64m1x2	vlseg2e64_v_u64m1x2
#define vlseg2e_v_i64m1x2_m	vlseg2e64_v_i64m1x2_m
#define vlseg2e_v_u64m1x2_m	vlseg2e64_v_u64m1x2_m
#define vlseg3e_v_i64m1x3	vlseg3e64_v_i64m1x3
#define vlseg3e_v_u64m1x3	vlseg3e64_v_u64m1x3
#define vlseg3e_v_i64m1x3_m	vlseg3e64_v_i64m1x3_m
#define vlseg3e_v_u64m1x3_m	vlseg3e64_v_u64m1x3_m
#define vlseg4e_v_i64m1x4	vlseg4e64_v_i64m1x4
#define vlseg4e_v_u64m1x4	vlseg4e64_v_u64m1x4
#define vlseg4e_v_i64m1x4_m	vlseg4e64_v_i64m1x4_m
#define vlseg4e_v_u64m1x4_m	vlseg4e64_v_u64m1x4_m
#define vlseg5e_v_i64m1x5	vlseg5e64_v_i64m1x5
#define vlseg5e_v_u64m1x5	vlseg5e64_v_u64m1x5
#define vlseg5e_v_i64m1x5_m	vlseg5e64_v_i64m1x5_m
#define vlseg5e_v_u64m1x5_m	vlseg5e64_v_u64m1x5_m
#define vlseg6e_v_i64m1x6	vlseg6e64_v_i64m1x6
#define vlseg6e_v_u64m1x6	vlseg6e64_v_u64m1x6
#define vlseg6e_v_i64m1x6_m	vlseg6e64_v_i64m1x6_m
#define vlseg6e_v_u64m1x6_m	vlseg6e64_v_u64m1x6_m
#define vlseg7e_v_i64m1x7	vlseg7e64_v_i64m1x7
#define vlseg7e_v_u64m1x7	vlseg7e64_v_u64m1x7
#define vlseg7e_v_i64m1x7_m	vlseg7e64_v_i64m1x7_m
#define vlseg7e_v_u64m1x7_m	vlseg7e64_v_u64m1x7_m
#define vlseg8e_v_i64m1x8	vlseg8e64_v_i64m1x8
#define vlseg8e_v_u64m1x8	vlseg8e64_v_u64m1x8
#define vlseg8e_v_i64m1x8_m	vlseg8e64_v_i64m1x8_m
#define vlseg8e_v_u64m1x8_m	vlseg8e64_v_u64m1x8_m
#define vlseg2e_v_i64m2x2	vlseg2e64_v_i64m2x2
#define vlseg2e_v_u64m2x2	vlseg2e64_v_u64m2x2
#define vlseg2e_v_i64m2x2_m	vlseg2e64_v_i64m2x2_m
#define vlseg2e_v_u64m2x2_m	vlseg2e64_v_u64m2x2_m
#define vlseg3e_v_i64m2x3	vlseg3e64_v_i64m2x3
#define vlseg3e_v_u64m2x3	vlseg3e64_v_u64m2x3
#define vlseg3e_v_i64m2x3_m	vlseg3e64_v_i64m2x3_m
#define vlseg3e_v_u64m2x3_m	vlseg3e64_v_u64m2x3_m
#define vlseg4e_v_i64m2x4	vlseg4e64_v_i64m2x4
#define vlseg4e_v_u64m2x4	vlseg4e64_v_u64m2x4
#define vlseg4e_v_i64m2x4_m	vlseg4e64_v_i64m2x4_m
#define vlseg4e_v_u64m2x4_m	vlseg4e64_v_u64m2x4_m
#define vlseg2e_v_i64m4x2	vlseg2e64_v_i64m4x2
#define vlseg2e_v_u64m4x2	vlseg2e64_v_u64m4x2
#define vlseg2e_v_i64m4x2_m	vlseg2e64_v_i64m4x2_m
#define vlseg2e_v_u64m4x2_m	vlseg2e64_v_u64m4x2_m
#define vlseg2e_v_f16m1x2	vlseg2e16_v_f16m1x2
#define vlseg2e_v_f16m1x2_m	vlseg2e16_v_f16m1x2_m
#define vlseg3e_v_f16m1x3	vlseg3e16_v_f16m1x3
#define vlseg3e_v_f16m1x3_m	vlseg3e16_v_f16m1x3_m
#define vlseg4e_v_f16m1x4	vlseg4e16_v_f16m1x4
#define vlseg4e_v_f16m1x4_m	vlseg4e16_v_f16m1x4_m
#define vlseg5e_v_f16m1x5	vlseg5e16_v_f16m1x5
#define vlseg5e_v_f16m1x5_m	vlseg5e16_v_f16m1x5_m
#define vlseg6e_v_f16m1x6	vlseg6e16_v_f16m1x6
#define vlseg6e_v_f16m1x6_m	vlseg6e16_v_f16m1x6_m
#define vlseg7e_v_f16m1x7	vlseg7e16_v_f16m1x7
#define vlseg7e_v_f16m1x7_m	vlseg7e16_v_f16m1x7_m
#define vlseg8e_v_f16m1x8	vlseg8e16_v_f16m1x8
#define vlseg8e_v_f16m1x8_m	vlseg8e16_v_f16m1x8_m
#define vlseg2e_v_f16m2x2	vlseg2e16_v_f16m2x2
#define vlseg2e_v_f16m2x2_m	vlseg2e16_v_f16m2x2_m
#define vlseg3e_v_f16m2x3	vlseg3e16_v_f16m2x3
#define vlseg3e_v_f16m2x3_m	vlseg3e16_v_f16m2x3_m
#define vlseg4e_v_f16m2x4	vlseg4e16_v_f16m2x4
#define vlseg4e_v_f16m2x4_m	vlseg4e16_v_f16m2x4_m
#define vlseg2e_v_f16m4x2	vlseg2e16_v_f16m4x2
#define vlseg2e_v_f16m4x2_m	vlseg2e16_v_f16m4x2_m
#define vlseg2e_v_f32m1x2	vlseg2e32_v_f32m1x2
#define vlseg2e_v_f32m1x2_m	vlseg2e32_v_f32m1x2_m
#define vlseg3e_v_f32m1x3	vlseg3e32_v_f32m1x3
#define vlseg3e_v_f32m1x3_m	vlseg3e32_v_f32m1x3_m
#define vlseg4e_v_f32m1x4	vlseg4e32_v_f32m1x4
#define vlseg4e_v_f32m1x4_m	vlseg4e32_v_f32m1x4_m
#define vlseg5e_v_f32m1x5	vlseg5e32_v_f32m1x5
#define vlseg5e_v_f32m1x5_m	vlseg5e32_v_f32m1x5_m
#define vlseg6e_v_f32m1x6	vlseg6e32_v_f32m1x6
#define vlseg6e_v_f32m1x6_m	vlseg6e32_v_f32m1x6_m
#define vlseg7e_v_f32m1x7	vlseg7e32_v_f32m1x7
#define vlseg7e_v_f32m1x7_m	vlseg7e32_v_f32m1x7_m
#define vlseg8e_v_f32m1x8	vlseg8e32_v_f32m1x8
#define vlseg8e_v_f32m1x8_m	vlseg8e32_v_f32m1x8_m
#define vlseg2e_v_f32m2x2	vlseg2e32_v_f32m2x2
#define vlseg2e_v_f32m2x2_m	vlseg2e32_v_f32m2x2_m
#define vlseg3e_v_f32m2x3	vlseg3e32_v_f32m2x3
#define vlseg3e_v_f32m2x3_m	vlseg3e32_v_f32m2x3_m
#define vlseg4e_v_f32m2x4	vlseg4e32_v_f32m2x4
#define vlseg4e_v_f32m2x4_m	vlseg4e32_v_f32m2x4_m
#define vlseg2e_v_f32m4x2	vlseg2e32_v_f32m4x2
#define vlseg2e_v_f32m4x2_m	vlseg2e32_v_f32m4x2_m
#define vlseg2e_v_f64m1x2	vlseg2e64_v_f64m1x2
#define vlseg2e_v_f64m1x2_m	vlseg2e64_v_f64m1x2_m
#define vlseg3e_v_f64m1x3	vlseg3e64_v_f64m1x3
#define vlseg3e_v_f64m1x3_m	vlseg3e64_v_f64m1x3_m
#define vlseg4e_v_f64m1x4	vlseg4e64_v_f64m1x4
#define vlseg4e_v_f64m1x4_m	vlseg4e64_v_f64m1x4_m
#define vlseg5e_v_f64m1x5	vlseg5e64_v_f64m1x5
#define vlseg5e_v_f64m1x5_m	vlseg5e64_v_f64m1x5_m
#define vlseg6e_v_f64m1x6	vlseg6e64_v_f64m1x6
#define vlseg6e_v_f64m1x6_m	vlseg6e64_v_f64m1x6_m
#define vlseg7e_v_f64m1x7	vlseg7e64_v_f64m1x7
#define vlseg7e_v_f64m1x7_m	vlseg7e64_v_f64m1x7_m
#define vlseg8e_v_f64m1x8	vlseg8e64_v_f64m1x8
#define vlseg8e_v_f64m1x8_m	vlseg8e64_v_f64m1x8_m
#define vlseg2e_v_f64m2x2	vlseg2e64_v_f64m2x2
#define vlseg2e_v_f64m2x2_m	vlseg2e64_v_f64m2x2_m
#define vlseg3e_v_f64m2x3	vlseg3e64_v_f64m2x3
#define vlseg3e_v_f64m2x3_m	vlseg3e64_v_f64m2x3_m
#define vlseg4e_v_f64m2x4	vlseg4e64_v_f64m2x4
#define vlseg4e_v_f64m2x4_m	vlseg4e64_v_f64m2x4_m
#define vlseg2e_v_f64m4x2	vlseg2e64_v_f64m4x2
#define vlseg2e_v_f64m4x2_m	vlseg2e64_v_f64m4x2_m

/* Wrapper only.  */
#define vsseg2e_v_i8m1x2	vsseg2e8_v_i8m1x2
#define vsseg2e_v_u8m1x2	vsseg2e8_v_u8m1x2
#define vsseg2e_v_i8m1x2_m	vsseg2e8_v_i8m1x2_m
#define vsseg2e_v_u8m1x2_m	vsseg2e8_v_u8m1x2_m
#define vsseg3e_v_i8m1x3	vsseg3e8_v_i8m1x3
#define vsseg3e_v_u8m1x3	vsseg3e8_v_u8m1x3
#define vsseg3e_v_i8m1x3_m	vsseg3e8_v_i8m1x3_m
#define vsseg3e_v_u8m1x3_m	vsseg3e8_v_u8m1x3_m
#define vsseg4e_v_i8m1x4	vsseg4e8_v_i8m1x4
#define vsseg4e_v_u8m1x4	vsseg4e8_v_u8m1x4
#define vsseg4e_v_i8m1x4_m	vsseg4e8_v_i8m1x4_m
#define vsseg4e_v_u8m1x4_m	vsseg4e8_v_u8m1x4_m
#define vsseg5e_v_i8m1x5	vsseg5e8_v_i8m1x5
#define vsseg5e_v_u8m1x5	vsseg5e8_v_u8m1x5
#define vsseg5e_v_i8m1x5_m	vsseg5e8_v_i8m1x5_m
#define vsseg5e_v_u8m1x5_m	vsseg5e8_v_u8m1x5_m
#define vsseg6e_v_i8m1x6	vsseg6e8_v_i8m1x6
#define vsseg6e_v_u8m1x6	vsseg6e8_v_u8m1x6
#define vsseg6e_v_i8m1x6_m	vsseg6e8_v_i8m1x6_m
#define vsseg6e_v_u8m1x6_m	vsseg6e8_v_u8m1x6_m
#define vsseg7e_v_i8m1x7	vsseg7e8_v_i8m1x7
#define vsseg7e_v_u8m1x7	vsseg7e8_v_u8m1x7
#define vsseg7e_v_i8m1x7_m	vsseg7e8_v_i8m1x7_m
#define vsseg7e_v_u8m1x7_m	vsseg7e8_v_u8m1x7_m
#define vsseg8e_v_i8m1x8	vsseg8e8_v_i8m1x8
#define vsseg8e_v_u8m1x8	vsseg8e8_v_u8m1x8
#define vsseg8e_v_i8m1x8_m	vsseg8e8_v_i8m1x8_m
#define vsseg8e_v_u8m1x8_m	vsseg8e8_v_u8m1x8_m
#define vsseg2e_v_i8m2x2	vsseg2e8_v_i8m2x2
#define vsseg2e_v_u8m2x2	vsseg2e8_v_u8m2x2
#define vsseg2e_v_i8m2x2_m	vsseg2e8_v_i8m2x2_m
#define vsseg2e_v_u8m2x2_m	vsseg2e8_v_u8m2x2_m
#define vsseg3e_v_i8m2x3	vsseg3e8_v_i8m2x3
#define vsseg3e_v_u8m2x3	vsseg3e8_v_u8m2x3
#define vsseg3e_v_i8m2x3_m	vsseg3e8_v_i8m2x3_m
#define vsseg3e_v_u8m2x3_m	vsseg3e8_v_u8m2x3_m
#define vsseg4e_v_i8m2x4	vsseg4e8_v_i8m2x4
#define vsseg4e_v_u8m2x4	vsseg4e8_v_u8m2x4
#define vsseg4e_v_i8m2x4_m	vsseg4e8_v_i8m2x4_m
#define vsseg4e_v_u8m2x4_m	vsseg4e8_v_u8m2x4_m
#define vsseg2e_v_i8m4x2	vsseg2e8_v_i8m4x2
#define vsseg2e_v_u8m4x2	vsseg2e8_v_u8m4x2
#define vsseg2e_v_i8m4x2_m	vsseg2e8_v_i8m4x2_m
#define vsseg2e_v_u8m4x2_m	vsseg2e8_v_u8m4x2_m
#define vsseg2e_v_i16m1x2	vsseg2e16_v_i16m1x2
#define vsseg2e_v_u16m1x2	vsseg2e16_v_u16m1x2
#define vsseg2e_v_i16m1x2_m	vsseg2e16_v_i16m1x2_m
#define vsseg2e_v_u16m1x2_m	vsseg2e16_v_u16m1x2_m
#define vsseg3e_v_i16m1x3	vsseg3e16_v_i16m1x3
#define vsseg3e_v_u16m1x3	vsseg3e16_v_u16m1x3
#define vsseg3e_v_i16m1x3_m	vsseg3e16_v_i16m1x3_m
#define vsseg3e_v_u16m1x3_m	vsseg3e16_v_u16m1x3_m
#define vsseg4e_v_i16m1x4	vsseg4e16_v_i16m1x4
#define vsseg4e_v_u16m1x4	vsseg4e16_v_u16m1x4
#define vsseg4e_v_i16m1x4_m	vsseg4e16_v_i16m1x4_m
#define vsseg4e_v_u16m1x4_m	vsseg4e16_v_u16m1x4_m
#define vsseg5e_v_i16m1x5	vsseg5e16_v_i16m1x5
#define vsseg5e_v_u16m1x5	vsseg5e16_v_u16m1x5
#define vsseg5e_v_i16m1x5_m	vsseg5e16_v_i16m1x5_m
#define vsseg5e_v_u16m1x5_m	vsseg5e16_v_u16m1x5_m
#define vsseg6e_v_i16m1x6	vsseg6e16_v_i16m1x6
#define vsseg6e_v_u16m1x6	vsseg6e16_v_u16m1x6
#define vsseg6e_v_i16m1x6_m	vsseg6e16_v_i16m1x6_m
#define vsseg6e_v_u16m1x6_m	vsseg6e16_v_u16m1x6_m
#define vsseg7e_v_i16m1x7	vsseg7e16_v_i16m1x7
#define vsseg7e_v_u16m1x7	vsseg7e16_v_u16m1x7
#define vsseg7e_v_i16m1x7_m	vsseg7e16_v_i16m1x7_m
#define vsseg7e_v_u16m1x7_m	vsseg7e16_v_u16m1x7_m
#define vsseg8e_v_i16m1x8	vsseg8e16_v_i16m1x8
#define vsseg8e_v_u16m1x8	vsseg8e16_v_u16m1x8
#define vsseg8e_v_i16m1x8_m	vsseg8e16_v_i16m1x8_m
#define vsseg8e_v_u16m1x8_m	vsseg8e16_v_u16m1x8_m
#define vsseg2e_v_i16m2x2	vsseg2e16_v_i16m2x2
#define vsseg2e_v_u16m2x2	vsseg2e16_v_u16m2x2
#define vsseg2e_v_i16m2x2_m	vsseg2e16_v_i16m2x2_m
#define vsseg2e_v_u16m2x2_m	vsseg2e16_v_u16m2x2_m
#define vsseg3e_v_i16m2x3	vsseg3e16_v_i16m2x3
#define vsseg3e_v_u16m2x3	vsseg3e16_v_u16m2x3
#define vsseg3e_v_i16m2x3_m	vsseg3e16_v_i16m2x3_m
#define vsseg3e_v_u16m2x3_m	vsseg3e16_v_u16m2x3_m
#define vsseg4e_v_i16m2x4	vsseg4e16_v_i16m2x4
#define vsseg4e_v_u16m2x4	vsseg4e16_v_u16m2x4
#define vsseg4e_v_i16m2x4_m	vsseg4e16_v_i16m2x4_m
#define vsseg4e_v_u16m2x4_m	vsseg4e16_v_u16m2x4_m
#define vsseg2e_v_i16m4x2	vsseg2e16_v_i16m4x2
#define vsseg2e_v_u16m4x2	vsseg2e16_v_u16m4x2
#define vsseg2e_v_i16m4x2_m	vsseg2e16_v_i16m4x2_m
#define vsseg2e_v_u16m4x2_m	vsseg2e16_v_u16m4x2_m
#define vsseg2e_v_i32m1x2	vsseg2e32_v_i32m1x2
#define vsseg2e_v_u32m1x2	vsseg2e32_v_u32m1x2
#define vsseg2e_v_i32m1x2_m	vsseg2e32_v_i32m1x2_m
#define vsseg2e_v_u32m1x2_m	vsseg2e32_v_u32m1x2_m
#define vsseg3e_v_i32m1x3	vsseg3e32_v_i32m1x3
#define vsseg3e_v_u32m1x3	vsseg3e32_v_u32m1x3
#define vsseg3e_v_i32m1x3_m	vsseg3e32_v_i32m1x3_m
#define vsseg3e_v_u32m1x3_m	vsseg3e32_v_u32m1x3_m
#define vsseg4e_v_i32m1x4	vsseg4e32_v_i32m1x4
#define vsseg4e_v_u32m1x4	vsseg4e32_v_u32m1x4
#define vsseg4e_v_i32m1x4_m	vsseg4e32_v_i32m1x4_m
#define vsseg4e_v_u32m1x4_m	vsseg4e32_v_u32m1x4_m
#define vsseg5e_v_i32m1x5	vsseg5e32_v_i32m1x5
#define vsseg5e_v_u32m1x5	vsseg5e32_v_u32m1x5
#define vsseg5e_v_i32m1x5_m	vsseg5e32_v_i32m1x5_m
#define vsseg5e_v_u32m1x5_m	vsseg5e32_v_u32m1x5_m
#define vsseg6e_v_i32m1x6	vsseg6e32_v_i32m1x6
#define vsseg6e_v_u32m1x6	vsseg6e32_v_u32m1x6
#define vsseg6e_v_i32m1x6_m	vsseg6e32_v_i32m1x6_m
#define vsseg6e_v_u32m1x6_m	vsseg6e32_v_u32m1x6_m
#define vsseg7e_v_i32m1x7	vsseg7e32_v_i32m1x7
#define vsseg7e_v_u32m1x7	vsseg7e32_v_u32m1x7
#define vsseg7e_v_i32m1x7_m	vsseg7e32_v_i32m1x7_m
#define vsseg7e_v_u32m1x7_m	vsseg7e32_v_u32m1x7_m
#define vsseg8e_v_i32m1x8	vsseg8e32_v_i32m1x8
#define vsseg8e_v_u32m1x8	vsseg8e32_v_u32m1x8
#define vsseg8e_v_i32m1x8_m	vsseg8e32_v_i32m1x8_m
#define vsseg8e_v_u32m1x8_m	vsseg8e32_v_u32m1x8_m
#define vsseg2e_v_i32m2x2	vsseg2e32_v_i32m2x2
#define vsseg2e_v_u32m2x2	vsseg2e32_v_u32m2x2
#define vsseg2e_v_i32m2x2_m	vsseg2e32_v_i32m2x2_m
#define vsseg2e_v_u32m2x2_m	vsseg2e32_v_u32m2x2_m
#define vsseg3e_v_i32m2x3	vsseg3e32_v_i32m2x3
#define vsseg3e_v_u32m2x3	vsseg3e32_v_u32m2x3
#define vsseg3e_v_i32m2x3_m	vsseg3e32_v_i32m2x3_m
#define vsseg3e_v_u32m2x3_m	vsseg3e32_v_u32m2x3_m
#define vsseg4e_v_i32m2x4	vsseg4e32_v_i32m2x4
#define vsseg4e_v_u32m2x4	vsseg4e32_v_u32m2x4
#define vsseg4e_v_i32m2x4_m	vsseg4e32_v_i32m2x4_m
#define vsseg4e_v_u32m2x4_m	vsseg4e32_v_u32m2x4_m
#define vsseg2e_v_i32m4x2	vsseg2e32_v_i32m4x2
#define vsseg2e_v_u32m4x2	vsseg2e32_v_u32m4x2
#define vsseg2e_v_i32m4x2_m	vsseg2e32_v_i32m4x2_m
#define vsseg2e_v_u32m4x2_m	vsseg2e32_v_u32m4x2_m
#define vsseg2e_v_i64m1x2	vsseg2e64_v_i64m1x2
#define vsseg2e_v_u64m1x2	vsseg2e64_v_u64m1x2
#define vsseg2e_v_i64m1x2_m	vsseg2e64_v_i64m1x2_m
#define vsseg2e_v_u64m1x2_m	vsseg2e64_v_u64m1x2_m
#define vsseg3e_v_i64m1x3	vsseg3e64_v_i64m1x3
#define vsseg3e_v_u64m1x3	vsseg3e64_v_u64m1x3
#define vsseg3e_v_i64m1x3_m	vsseg3e64_v_i64m1x3_m
#define vsseg3e_v_u64m1x3_m	vsseg3e64_v_u64m1x3_m
#define vsseg4e_v_i64m1x4	vsseg4e64_v_i64m1x4
#define vsseg4e_v_u64m1x4	vsseg4e64_v_u64m1x4
#define vsseg4e_v_i64m1x4_m	vsseg4e64_v_i64m1x4_m
#define vsseg4e_v_u64m1x4_m	vsseg4e64_v_u64m1x4_m
#define vsseg5e_v_i64m1x5	vsseg5e64_v_i64m1x5
#define vsseg5e_v_u64m1x5	vsseg5e64_v_u64m1x5
#define vsseg5e_v_i64m1x5_m	vsseg5e64_v_i64m1x5_m
#define vsseg5e_v_u64m1x5_m	vsseg5e64_v_u64m1x5_m
#define vsseg6e_v_i64m1x6	vsseg6e64_v_i64m1x6
#define vsseg6e_v_u64m1x6	vsseg6e64_v_u64m1x6
#define vsseg6e_v_i64m1x6_m	vsseg6e64_v_i64m1x6_m
#define vsseg6e_v_u64m1x6_m	vsseg6e64_v_u64m1x6_m
#define vsseg7e_v_i64m1x7	vsseg7e64_v_i64m1x7
#define vsseg7e_v_u64m1x7	vsseg7e64_v_u64m1x7
#define vsseg7e_v_i64m1x7_m	vsseg7e64_v_i64m1x7_m
#define vsseg7e_v_u64m1x7_m	vsseg7e64_v_u64m1x7_m
#define vsseg8e_v_i64m1x8	vsseg8e64_v_i64m1x8
#define vsseg8e_v_u64m1x8	vsseg8e64_v_u64m1x8
#define vsseg8e_v_i64m1x8_m	vsseg8e64_v_i64m1x8_m
#define vsseg8e_v_u64m1x8_m	vsseg8e64_v_u64m1x8_m
#define vsseg2e_v_i64m2x2	vsseg2e64_v_i64m2x2
#define vsseg2e_v_u64m2x2	vsseg2e64_v_u64m2x2
#define vsseg2e_v_i64m2x2_m	vsseg2e64_v_i64m2x2_m
#define vsseg2e_v_u64m2x2_m	vsseg2e64_v_u64m2x2_m
#define vsseg3e_v_i64m2x3	vsseg3e64_v_i64m2x3
#define vsseg3e_v_u64m2x3	vsseg3e64_v_u64m2x3
#define vsseg3e_v_i64m2x3_m	vsseg3e64_v_i64m2x3_m
#define vsseg3e_v_u64m2x3_m	vsseg3e64_v_u64m2x3_m
#define vsseg4e_v_i64m2x4	vsseg4e64_v_i64m2x4
#define vsseg4e_v_u64m2x4	vsseg4e64_v_u64m2x4
#define vsseg4e_v_i64m2x4_m	vsseg4e64_v_i64m2x4_m
#define vsseg4e_v_u64m2x4_m	vsseg4e64_v_u64m2x4_m
#define vsseg2e_v_i64m4x2	vsseg2e64_v_i64m4x2
#define vsseg2e_v_u64m4x2	vsseg2e64_v_u64m4x2
#define vsseg2e_v_i64m4x2_m	vsseg2e64_v_i64m4x2_m
#define vsseg2e_v_u64m4x2_m	vsseg2e64_v_u64m4x2_m
#define vsseg2e_v_f16m1x2	vsseg2e16_v_f16m1x2
#define vsseg2e_v_f16m1x2_m	vsseg2e16_v_f16m1x2_m
#define vsseg3e_v_f16m1x3	vsseg3e16_v_f16m1x3
#define vsseg3e_v_f16m1x3_m	vsseg3e16_v_f16m1x3_m
#define vsseg4e_v_f16m1x4	vsseg4e16_v_f16m1x4
#define vsseg4e_v_f16m1x4_m	vsseg4e16_v_f16m1x4_m
#define vsseg5e_v_f16m1x5	vsseg5e16_v_f16m1x5
#define vsseg5e_v_f16m1x5_m	vsseg5e16_v_f16m1x5_m
#define vsseg6e_v_f16m1x6	vsseg6e16_v_f16m1x6
#define vsseg6e_v_f16m1x6_m	vsseg6e16_v_f16m1x6_m
#define vsseg7e_v_f16m1x7	vsseg7e16_v_f16m1x7
#define vsseg7e_v_f16m1x7_m	vsseg7e16_v_f16m1x7_m
#define vsseg8e_v_f16m1x8	vsseg8e16_v_f16m1x8
#define vsseg8e_v_f16m1x8_m	vsseg8e16_v_f16m1x8_m
#define vsseg2e_v_f16m2x2	vsseg2e16_v_f16m2x2
#define vsseg2e_v_f16m2x2_m	vsseg2e16_v_f16m2x2_m
#define vsseg3e_v_f16m2x3	vsseg3e16_v_f16m2x3
#define vsseg3e_v_f16m2x3_m	vsseg3e16_v_f16m2x3_m
#define vsseg4e_v_f16m2x4	vsseg4e16_v_f16m2x4
#define vsseg4e_v_f16m2x4_m	vsseg4e16_v_f16m2x4_m
#define vsseg2e_v_f16m4x2	vsseg2e16_v_f16m4x2
#define vsseg2e_v_f16m4x2_m	vsseg2e16_v_f16m4x2_m
#define vsseg2e_v_f32m1x2	vsseg2e32_v_f32m1x2
#define vsseg2e_v_f32m1x2_m	vsseg2e32_v_f32m1x2_m
#define vsseg3e_v_f32m1x3	vsseg3e32_v_f32m1x3
#define vsseg3e_v_f32m1x3_m	vsseg3e32_v_f32m1x3_m
#define vsseg4e_v_f32m1x4	vsseg4e32_v_f32m1x4
#define vsseg4e_v_f32m1x4_m	vsseg4e32_v_f32m1x4_m
#define vsseg5e_v_f32m1x5	vsseg5e32_v_f32m1x5
#define vsseg5e_v_f32m1x5_m	vsseg5e32_v_f32m1x5_m
#define vsseg6e_v_f32m1x6	vsseg6e32_v_f32m1x6
#define vsseg6e_v_f32m1x6_m	vsseg6e32_v_f32m1x6_m
#define vsseg7e_v_f32m1x7	vsseg7e32_v_f32m1x7
#define vsseg7e_v_f32m1x7_m	vsseg7e32_v_f32m1x7_m
#define vsseg8e_v_f32m1x8	vsseg8e32_v_f32m1x8
#define vsseg8e_v_f32m1x8_m	vsseg8e32_v_f32m1x8_m
#define vsseg2e_v_f32m2x2	vsseg2e32_v_f32m2x2
#define vsseg2e_v_f32m2x2_m	vsseg2e32_v_f32m2x2_m
#define vsseg3e_v_f32m2x3	vsseg3e32_v_f32m2x3
#define vsseg3e_v_f32m2x3_m	vsseg3e32_v_f32m2x3_m
#define vsseg4e_v_f32m2x4	vsseg4e32_v_f32m2x4
#define vsseg4e_v_f32m2x4_m	vsseg4e32_v_f32m2x4_m
#define vsseg2e_v_f32m4x2	vsseg2e32_v_f32m4x2
#define vsseg2e_v_f32m4x2_m	vsseg2e32_v_f32m4x2_m
#define vsseg2e_v_f64m1x2	vsseg2e64_v_f64m1x2
#define vsseg2e_v_f64m1x2_m	vsseg2e64_v_f64m1x2_m
#define vsseg3e_v_f64m1x3	vsseg3e64_v_f64m1x3
#define vsseg3e_v_f64m1x3_m	vsseg3e64_v_f64m1x3_m
#define vsseg4e_v_f64m1x4	vsseg4e64_v_f64m1x4
#define vsseg4e_v_f64m1x4_m	vsseg4e64_v_f64m1x4_m
#define vsseg5e_v_f64m1x5	vsseg5e64_v_f64m1x5
#define vsseg5e_v_f64m1x5_m	vsseg5e64_v_f64m1x5_m
#define vsseg6e_v_f64m1x6	vsseg6e64_v_f64m1x6
#define vsseg6e_v_f64m1x6_m	vsseg6e64_v_f64m1x6_m
#define vsseg7e_v_f64m1x7	vsseg7e64_v_f64m1x7
#define vsseg7e_v_f64m1x7_m	vsseg7e64_v_f64m1x7_m
#define vsseg8e_v_f64m1x8	vsseg8e64_v_f64m1x8
#define vsseg8e_v_f64m1x8_m	vsseg8e64_v_f64m1x8_m
#define vsseg2e_v_f64m2x2	vsseg2e64_v_f64m2x2
#define vsseg2e_v_f64m2x2_m	vsseg2e64_v_f64m2x2_m
#define vsseg3e_v_f64m2x3	vsseg3e64_v_f64m2x3
#define vsseg3e_v_f64m2x3_m	vsseg3e64_v_f64m2x3_m
#define vsseg4e_v_f64m2x4	vsseg4e64_v_f64m2x4
#define vsseg4e_v_f64m2x4_m	vsseg4e64_v_f64m2x4_m
#define vsseg2e_v_f64m4x2	vsseg2e64_v_f64m4x2
#define vsseg2e_v_f64m4x2_m	vsseg2e64_v_f64m4x2_m

/* Wrapper only.  */
#define vlsseg2e_v_i8m1x2	vlsseg2e8_v_i8m1x2
#define vlsseg2e_v_u8m1x2	vlsseg2e8_v_u8m1x2
#define vlsseg2e_v_i8m1x2_m	vlsseg2e8_v_i8m1x2_m
#define vlsseg2e_v_u8m1x2_m	vlsseg2e8_v_u8m1x2_m
#define vlsseg3e_v_i8m1x3	vlsseg3e8_v_i8m1x3
#define vlsseg3e_v_u8m1x3	vlsseg3e8_v_u8m1x3
#define vlsseg3e_v_i8m1x3_m	vlsseg3e8_v_i8m1x3_m
#define vlsseg3e_v_u8m1x3_m	vlsseg3e8_v_u8m1x3_m
#define vlsseg4e_v_i8m1x4	vlsseg4e8_v_i8m1x4
#define vlsseg4e_v_u8m1x4	vlsseg4e8_v_u8m1x4
#define vlsseg4e_v_i8m1x4_m	vlsseg4e8_v_i8m1x4_m
#define vlsseg4e_v_u8m1x4_m	vlsseg4e8_v_u8m1x4_m
#define vlsseg5e_v_i8m1x5	vlsseg5e8_v_i8m1x5
#define vlsseg5e_v_u8m1x5	vlsseg5e8_v_u8m1x5
#define vlsseg5e_v_i8m1x5_m	vlsseg5e8_v_i8m1x5_m
#define vlsseg5e_v_u8m1x5_m	vlsseg5e8_v_u8m1x5_m
#define vlsseg6e_v_i8m1x6	vlsseg6e8_v_i8m1x6
#define vlsseg6e_v_u8m1x6	vlsseg6e8_v_u8m1x6
#define vlsseg6e_v_i8m1x6_m	vlsseg6e8_v_i8m1x6_m
#define vlsseg6e_v_u8m1x6_m	vlsseg6e8_v_u8m1x6_m
#define vlsseg7e_v_i8m1x7	vlsseg7e8_v_i8m1x7
#define vlsseg7e_v_u8m1x7	vlsseg7e8_v_u8m1x7
#define vlsseg7e_v_i8m1x7_m	vlsseg7e8_v_i8m1x7_m
#define vlsseg7e_v_u8m1x7_m	vlsseg7e8_v_u8m1x7_m
#define vlsseg8e_v_i8m1x8	vlsseg8e8_v_i8m1x8
#define vlsseg8e_v_u8m1x8	vlsseg8e8_v_u8m1x8
#define vlsseg8e_v_i8m1x8_m	vlsseg8e8_v_i8m1x8_m
#define vlsseg8e_v_u8m1x8_m	vlsseg8e8_v_u8m1x8_m
#define vlsseg2e_v_i8m2x2	vlsseg2e8_v_i8m2x2
#define vlsseg2e_v_u8m2x2	vlsseg2e8_v_u8m2x2
#define vlsseg2e_v_i8m2x2_m	vlsseg2e8_v_i8m2x2_m
#define vlsseg2e_v_u8m2x2_m	vlsseg2e8_v_u8m2x2_m
#define vlsseg3e_v_i8m2x3	vlsseg3e8_v_i8m2x3
#define vlsseg3e_v_u8m2x3	vlsseg3e8_v_u8m2x3
#define vlsseg3e_v_i8m2x3_m	vlsseg3e8_v_i8m2x3_m
#define vlsseg3e_v_u8m2x3_m	vlsseg3e8_v_u8m2x3_m
#define vlsseg4e_v_i8m2x4	vlsseg4e8_v_i8m2x4
#define vlsseg4e_v_u8m2x4	vlsseg4e8_v_u8m2x4
#define vlsseg4e_v_i8m2x4_m	vlsseg4e8_v_i8m2x4_m
#define vlsseg4e_v_u8m2x4_m	vlsseg4e8_v_u8m2x4_m
#define vlsseg2e_v_i8m4x2	vlsseg2e8_v_i8m4x2
#define vlsseg2e_v_u8m4x2	vlsseg2e8_v_u8m4x2
#define vlsseg2e_v_i8m4x2_m	vlsseg2e8_v_i8m4x2_m
#define vlsseg2e_v_u8m4x2_m	vlsseg2e8_v_u8m4x2_m
#define vlsseg2e_v_i16m1x2	vlsseg2e16_v_i16m1x2
#define vlsseg2e_v_u16m1x2	vlsseg2e16_v_u16m1x2
#define vlsseg2e_v_i16m1x2_m	vlsseg2e16_v_i16m1x2_m
#define vlsseg2e_v_u16m1x2_m	vlsseg2e16_v_u16m1x2_m
#define vlsseg3e_v_i16m1x3	vlsseg3e16_v_i16m1x3
#define vlsseg3e_v_u16m1x3	vlsseg3e16_v_u16m1x3
#define vlsseg3e_v_i16m1x3_m	vlsseg3e16_v_i16m1x3_m
#define vlsseg3e_v_u16m1x3_m	vlsseg3e16_v_u16m1x3_m
#define vlsseg4e_v_i16m1x4	vlsseg4e16_v_i16m1x4
#define vlsseg4e_v_u16m1x4	vlsseg4e16_v_u16m1x4
#define vlsseg4e_v_i16m1x4_m	vlsseg4e16_v_i16m1x4_m
#define vlsseg4e_v_u16m1x4_m	vlsseg4e16_v_u16m1x4_m
#define vlsseg5e_v_i16m1x5	vlsseg5e16_v_i16m1x5
#define vlsseg5e_v_u16m1x5	vlsseg5e16_v_u16m1x5
#define vlsseg5e_v_i16m1x5_m	vlsseg5e16_v_i16m1x5_m
#define vlsseg5e_v_u16m1x5_m	vlsseg5e16_v_u16m1x5_m
#define vlsseg6e_v_i16m1x6	vlsseg6e16_v_i16m1x6
#define vlsseg6e_v_u16m1x6	vlsseg6e16_v_u16m1x6
#define vlsseg6e_v_i16m1x6_m	vlsseg6e16_v_i16m1x6_m
#define vlsseg6e_v_u16m1x6_m	vlsseg6e16_v_u16m1x6_m
#define vlsseg7e_v_i16m1x7	vlsseg7e16_v_i16m1x7
#define vlsseg7e_v_u16m1x7	vlsseg7e16_v_u16m1x7
#define vlsseg7e_v_i16m1x7_m	vlsseg7e16_v_i16m1x7_m
#define vlsseg7e_v_u16m1x7_m	vlsseg7e16_v_u16m1x7_m
#define vlsseg8e_v_i16m1x8	vlsseg8e16_v_i16m1x8
#define vlsseg8e_v_u16m1x8	vlsseg8e16_v_u16m1x8
#define vlsseg8e_v_i16m1x8_m	vlsseg8e16_v_i16m1x8_m
#define vlsseg8e_v_u16m1x8_m	vlsseg8e16_v_u16m1x8_m
#define vlsseg2e_v_i16m2x2	vlsseg2e16_v_i16m2x2
#define vlsseg2e_v_u16m2x2	vlsseg2e16_v_u16m2x2
#define vlsseg2e_v_i16m2x2_m	vlsseg2e16_v_i16m2x2_m
#define vlsseg2e_v_u16m2x2_m	vlsseg2e16_v_u16m2x2_m
#define vlsseg3e_v_i16m2x3	vlsseg3e16_v_i16m2x3
#define vlsseg3e_v_u16m2x3	vlsseg3e16_v_u16m2x3
#define vlsseg3e_v_i16m2x3_m	vlsseg3e16_v_i16m2x3_m
#define vlsseg3e_v_u16m2x3_m	vlsseg3e16_v_u16m2x3_m
#define vlsseg4e_v_i16m2x4	vlsseg4e16_v_i16m2x4
#define vlsseg4e_v_u16m2x4	vlsseg4e16_v_u16m2x4
#define vlsseg4e_v_i16m2x4_m	vlsseg4e16_v_i16m2x4_m
#define vlsseg4e_v_u16m2x4_m	vlsseg4e16_v_u16m2x4_m
#define vlsseg2e_v_i16m4x2	vlsseg2e16_v_i16m4x2
#define vlsseg2e_v_u16m4x2	vlsseg2e16_v_u16m4x2
#define vlsseg2e_v_i16m4x2_m	vlsseg2e16_v_i16m4x2_m
#define vlsseg2e_v_u16m4x2_m	vlsseg2e16_v_u16m4x2_m
#define vlsseg2e_v_i32m1x2	vlsseg2e32_v_i32m1x2
#define vlsseg2e_v_u32m1x2	vlsseg2e32_v_u32m1x2
#define vlsseg2e_v_i32m1x2_m	vlsseg2e32_v_i32m1x2_m
#define vlsseg2e_v_u32m1x2_m	vlsseg2e32_v_u32m1x2_m
#define vlsseg3e_v_i32m1x3	vlsseg3e32_v_i32m1x3
#define vlsseg3e_v_u32m1x3	vlsseg3e32_v_u32m1x3
#define vlsseg3e_v_i32m1x3_m	vlsseg3e32_v_i32m1x3_m
#define vlsseg3e_v_u32m1x3_m	vlsseg3e32_v_u32m1x3_m
#define vlsseg4e_v_i32m1x4	vlsseg4e32_v_i32m1x4
#define vlsseg4e_v_u32m1x4	vlsseg4e32_v_u32m1x4
#define vlsseg4e_v_i32m1x4_m	vlsseg4e32_v_i32m1x4_m
#define vlsseg4e_v_u32m1x4_m	vlsseg4e32_v_u32m1x4_m
#define vlsseg5e_v_i32m1x5	vlsseg5e32_v_i32m1x5
#define vlsseg5e_v_u32m1x5	vlsseg5e32_v_u32m1x5
#define vlsseg5e_v_i32m1x5_m	vlsseg5e32_v_i32m1x5_m
#define vlsseg5e_v_u32m1x5_m	vlsseg5e32_v_u32m1x5_m
#define vlsseg6e_v_i32m1x6	vlsseg6e32_v_i32m1x6
#define vlsseg6e_v_u32m1x6	vlsseg6e32_v_u32m1x6
#define vlsseg6e_v_i32m1x6_m	vlsseg6e32_v_i32m1x6_m
#define vlsseg6e_v_u32m1x6_m	vlsseg6e32_v_u32m1x6_m
#define vlsseg7e_v_i32m1x7	vlsseg7e32_v_i32m1x7
#define vlsseg7e_v_u32m1x7	vlsseg7e32_v_u32m1x7
#define vlsseg7e_v_i32m1x7_m	vlsseg7e32_v_i32m1x7_m
#define vlsseg7e_v_u32m1x7_m	vlsseg7e32_v_u32m1x7_m
#define vlsseg8e_v_i32m1x8	vlsseg8e32_v_i32m1x8
#define vlsseg8e_v_u32m1x8	vlsseg8e32_v_u32m1x8
#define vlsseg8e_v_i32m1x8_m	vlsseg8e32_v_i32m1x8_m
#define vlsseg8e_v_u32m1x8_m	vlsseg8e32_v_u32m1x8_m
#define vlsseg2e_v_i32m2x2	vlsseg2e32_v_i32m2x2
#define vlsseg2e_v_u32m2x2	vlsseg2e32_v_u32m2x2
#define vlsseg2e_v_i32m2x2_m	vlsseg2e32_v_i32m2x2_m
#define vlsseg2e_v_u32m2x2_m	vlsseg2e32_v_u32m2x2_m
#define vlsseg3e_v_i32m2x3	vlsseg3e32_v_i32m2x3
#define vlsseg3e_v_u32m2x3	vlsseg3e32_v_u32m2x3
#define vlsseg3e_v_i32m2x3_m	vlsseg3e32_v_i32m2x3_m
#define vlsseg3e_v_u32m2x3_m	vlsseg3e32_v_u32m2x3_m
#define vlsseg4e_v_i32m2x4	vlsseg4e32_v_i32m2x4
#define vlsseg4e_v_u32m2x4	vlsseg4e32_v_u32m2x4
#define vlsseg4e_v_i32m2x4_m	vlsseg4e32_v_i32m2x4_m
#define vlsseg4e_v_u32m2x4_m	vlsseg4e32_v_u32m2x4_m
#define vlsseg2e_v_i32m4x2	vlsseg2e32_v_i32m4x2
#define vlsseg2e_v_u32m4x2	vlsseg2e32_v_u32m4x2
#define vlsseg2e_v_i32m4x2_m	vlsseg2e32_v_i32m4x2_m
#define vlsseg2e_v_u32m4x2_m	vlsseg2e32_v_u32m4x2_m
#define vlsseg2e_v_i64m1x2	vlsseg2e64_v_i64m1x2
#define vlsseg2e_v_u64m1x2	vlsseg2e64_v_u64m1x2
#define vlsseg2e_v_i64m1x2_m	vlsseg2e64_v_i64m1x2_m
#define vlsseg2e_v_u64m1x2_m	vlsseg2e64_v_u64m1x2_m
#define vlsseg3e_v_i64m1x3	vlsseg3e64_v_i64m1x3
#define vlsseg3e_v_u64m1x3	vlsseg3e64_v_u64m1x3
#define vlsseg3e_v_i64m1x3_m	vlsseg3e64_v_i64m1x3_m
#define vlsseg3e_v_u64m1x3_m	vlsseg3e64_v_u64m1x3_m
#define vlsseg4e_v_i64m1x4	vlsseg4e64_v_i64m1x4
#define vlsseg4e_v_u64m1x4	vlsseg4e64_v_u64m1x4
#define vlsseg4e_v_i64m1x4_m	vlsseg4e64_v_i64m1x4_m
#define vlsseg4e_v_u64m1x4_m	vlsseg4e64_v_u64m1x4_m
#define vlsseg5e_v_i64m1x5	vlsseg5e64_v_i64m1x5
#define vlsseg5e_v_u64m1x5	vlsseg5e64_v_u64m1x5
#define vlsseg5e_v_i64m1x5_m	vlsseg5e64_v_i64m1x5_m
#define vlsseg5e_v_u64m1x5_m	vlsseg5e64_v_u64m1x5_m
#define vlsseg6e_v_i64m1x6	vlsseg6e64_v_i64m1x6
#define vlsseg6e_v_u64m1x6	vlsseg6e64_v_u64m1x6
#define vlsseg6e_v_i64m1x6_m	vlsseg6e64_v_i64m1x6_m
#define vlsseg6e_v_u64m1x6_m	vlsseg6e64_v_u64m1x6_m
#define vlsseg7e_v_i64m1x7	vlsseg7e64_v_i64m1x7
#define vlsseg7e_v_u64m1x7	vlsseg7e64_v_u64m1x7
#define vlsseg7e_v_i64m1x7_m	vlsseg7e64_v_i64m1x7_m
#define vlsseg7e_v_u64m1x7_m	vlsseg7e64_v_u64m1x7_m
#define vlsseg8e_v_i64m1x8	vlsseg8e64_v_i64m1x8
#define vlsseg8e_v_u64m1x8	vlsseg8e64_v_u64m1x8
#define vlsseg8e_v_i64m1x8_m	vlsseg8e64_v_i64m1x8_m
#define vlsseg8e_v_u64m1x8_m	vlsseg8e64_v_u64m1x8_m
#define vlsseg2e_v_i64m2x2	vlsseg2e64_v_i64m2x2
#define vlsseg2e_v_u64m2x2	vlsseg2e64_v_u64m2x2
#define vlsseg2e_v_i64m2x2_m	vlsseg2e64_v_i64m2x2_m
#define vlsseg2e_v_u64m2x2_m	vlsseg2e64_v_u64m2x2_m
#define vlsseg3e_v_i64m2x3	vlsseg3e64_v_i64m2x3
#define vlsseg3e_v_u64m2x3	vlsseg3e64_v_u64m2x3
#define vlsseg3e_v_i64m2x3_m	vlsseg3e64_v_i64m2x3_m
#define vlsseg3e_v_u64m2x3_m	vlsseg3e64_v_u64m2x3_m
#define vlsseg4e_v_i64m2x4	vlsseg4e64_v_i64m2x4
#define vlsseg4e_v_u64m2x4	vlsseg4e64_v_u64m2x4
#define vlsseg4e_v_i64m2x4_m	vlsseg4e64_v_i64m2x4_m
#define vlsseg4e_v_u64m2x4_m	vlsseg4e64_v_u64m2x4_m
#define vlsseg2e_v_i64m4x2	vlsseg2e64_v_i64m4x2
#define vlsseg2e_v_u64m4x2	vlsseg2e64_v_u64m4x2
#define vlsseg2e_v_i64m4x2_m	vlsseg2e64_v_i64m4x2_m
#define vlsseg2e_v_u64m4x2_m	vlsseg2e64_v_u64m4x2_m
#define vlsseg2e_v_f16m1x2	vlsseg2e16_v_f16m1x2
#define vlsseg2e_v_f16m1x2_m	vlsseg2e16_v_f16m1x2_m
#define vlsseg3e_v_f16m1x3	vlsseg3e16_v_f16m1x3
#define vlsseg3e_v_f16m1x3_m	vlsseg3e16_v_f16m1x3_m
#define vlsseg4e_v_f16m1x4	vlsseg4e16_v_f16m1x4
#define vlsseg4e_v_f16m1x4_m	vlsseg4e16_v_f16m1x4_m
#define vlsseg5e_v_f16m1x5	vlsseg5e16_v_f16m1x5
#define vlsseg5e_v_f16m1x5_m	vlsseg5e16_v_f16m1x5_m
#define vlsseg6e_v_f16m1x6	vlsseg6e16_v_f16m1x6
#define vlsseg6e_v_f16m1x6_m	vlsseg6e16_v_f16m1x6_m
#define vlsseg7e_v_f16m1x7	vlsseg7e16_v_f16m1x7
#define vlsseg7e_v_f16m1x7_m	vlsseg7e16_v_f16m1x7_m
#define vlsseg8e_v_f16m1x8	vlsseg8e16_v_f16m1x8
#define vlsseg8e_v_f16m1x8_m	vlsseg8e16_v_f16m1x8_m
#define vlsseg2e_v_f16m2x2	vlsseg2e16_v_f16m2x2
#define vlsseg2e_v_f16m2x2_m	vlsseg2e16_v_f16m2x2_m
#define vlsseg3e_v_f16m2x3	vlsseg3e16_v_f16m2x3
#define vlsseg3e_v_f16m2x3_m	vlsseg3e16_v_f16m2x3_m
#define vlsseg4e_v_f16m2x4	vlsseg4e16_v_f16m2x4
#define vlsseg4e_v_f16m2x4_m	vlsseg4e16_v_f16m2x4_m
#define vlsseg2e_v_f16m4x2	vlsseg2e16_v_f16m4x2
#define vlsseg2e_v_f16m4x2_m	vlsseg2e16_v_f16m4x2_m
#define vlsseg2e_v_f32m1x2	vlsseg2e32_v_f32m1x2
#define vlsseg2e_v_f32m1x2_m	vlsseg2e32_v_f32m1x2_m
#define vlsseg3e_v_f32m1x3	vlsseg3e32_v_f32m1x3
#define vlsseg3e_v_f32m1x3_m	vlsseg3e32_v_f32m1x3_m
#define vlsseg4e_v_f32m1x4	vlsseg4e32_v_f32m1x4
#define vlsseg4e_v_f32m1x4_m	vlsseg4e32_v_f32m1x4_m
#define vlsseg5e_v_f32m1x5	vlsseg5e32_v_f32m1x5
#define vlsseg5e_v_f32m1x5_m	vlsseg5e32_v_f32m1x5_m
#define vlsseg6e_v_f32m1x6	vlsseg6e32_v_f32m1x6
#define vlsseg6e_v_f32m1x6_m	vlsseg6e32_v_f32m1x6_m
#define vlsseg7e_v_f32m1x7	vlsseg7e32_v_f32m1x7
#define vlsseg7e_v_f32m1x7_m	vlsseg7e32_v_f32m1x7_m
#define vlsseg8e_v_f32m1x8	vlsseg8e32_v_f32m1x8
#define vlsseg8e_v_f32m1x8_m	vlsseg8e32_v_f32m1x8_m
#define vlsseg2e_v_f32m2x2	vlsseg2e32_v_f32m2x2
#define vlsseg2e_v_f32m2x2_m	vlsseg2e32_v_f32m2x2_m
#define vlsseg3e_v_f32m2x3	vlsseg3e32_v_f32m2x3
#define vlsseg3e_v_f32m2x3_m	vlsseg3e32_v_f32m2x3_m
#define vlsseg4e_v_f32m2x4	vlsseg4e32_v_f32m2x4
#define vlsseg4e_v_f32m2x4_m	vlsseg4e32_v_f32m2x4_m
#define vlsseg2e_v_f32m4x2	vlsseg2e32_v_f32m4x2
#define vlsseg2e_v_f32m4x2_m	vlsseg2e32_v_f32m4x2_m
#define vlsseg2e_v_f64m1x2	vlsseg2e64_v_f64m1x2
#define vlsseg2e_v_f64m1x2_m	vlsseg2e64_v_f64m1x2_m
#define vlsseg3e_v_f64m1x3	vlsseg3e64_v_f64m1x3
#define vlsseg3e_v_f64m1x3_m	vlsseg3e64_v_f64m1x3_m
#define vlsseg4e_v_f64m1x4	vlsseg4e64_v_f64m1x4
#define vlsseg4e_v_f64m1x4_m	vlsseg4e64_v_f64m1x4_m
#define vlsseg5e_v_f64m1x5	vlsseg5e64_v_f64m1x5
#define vlsseg5e_v_f64m1x5_m	vlsseg5e64_v_f64m1x5_m
#define vlsseg6e_v_f64m1x6	vlsseg6e64_v_f64m1x6
#define vlsseg6e_v_f64m1x6_m	vlsseg6e64_v_f64m1x6_m
#define vlsseg7e_v_f64m1x7	vlsseg7e64_v_f64m1x7
#define vlsseg7e_v_f64m1x7_m	vlsseg7e64_v_f64m1x7_m
#define vlsseg8e_v_f64m1x8	vlsseg8e64_v_f64m1x8
#define vlsseg8e_v_f64m1x8_m	vlsseg8e64_v_f64m1x8_m
#define vlsseg2e_v_f64m2x2	vlsseg2e64_v_f64m2x2
#define vlsseg2e_v_f64m2x2_m	vlsseg2e64_v_f64m2x2_m
#define vlsseg3e_v_f64m2x3	vlsseg3e64_v_f64m2x3
#define vlsseg3e_v_f64m2x3_m	vlsseg3e64_v_f64m2x3_m
#define vlsseg4e_v_f64m2x4	vlsseg4e64_v_f64m2x4
#define vlsseg4e_v_f64m2x4_m	vlsseg4e64_v_f64m2x4_m
#define vlsseg2e_v_f64m4x2	vlsseg2e64_v_f64m4x2
#define vlsseg2e_v_f64m4x2_m	vlsseg2e64_v_f64m4x2_m

/* Wrapper only.  */
#define vssseg2e_v_i8m1x2	vssseg2e8_v_i8m1x2
#define vssseg2e_v_u8m1x2	vssseg2e8_v_u8m1x2
#define vssseg2e_v_i8m1x2_m	vssseg2e8_v_i8m1x2_m
#define vssseg2e_v_u8m1x2_m	vssseg2e8_v_u8m1x2_m
#define vssseg3e_v_i8m1x3	vssseg3e8_v_i8m1x3
#define vssseg3e_v_u8m1x3	vssseg3e8_v_u8m1x3
#define vssseg3e_v_i8m1x3_m	vssseg3e8_v_i8m1x3_m
#define vssseg3e_v_u8m1x3_m	vssseg3e8_v_u8m1x3_m
#define vssseg4e_v_i8m1x4	vssseg4e8_v_i8m1x4
#define vssseg4e_v_u8m1x4	vssseg4e8_v_u8m1x4
#define vssseg4e_v_i8m1x4_m	vssseg4e8_v_i8m1x4_m
#define vssseg4e_v_u8m1x4_m	vssseg4e8_v_u8m1x4_m
#define vssseg5e_v_i8m1x5	vssseg5e8_v_i8m1x5
#define vssseg5e_v_u8m1x5	vssseg5e8_v_u8m1x5
#define vssseg5e_v_i8m1x5_m	vssseg5e8_v_i8m1x5_m
#define vssseg5e_v_u8m1x5_m	vssseg5e8_v_u8m1x5_m
#define vssseg6e_v_i8m1x6	vssseg6e8_v_i8m1x6
#define vssseg6e_v_u8m1x6	vssseg6e8_v_u8m1x6
#define vssseg6e_v_i8m1x6_m	vssseg6e8_v_i8m1x6_m
#define vssseg6e_v_u8m1x6_m	vssseg6e8_v_u8m1x6_m
#define vssseg7e_v_i8m1x7	vssseg7e8_v_i8m1x7
#define vssseg7e_v_u8m1x7	vssseg7e8_v_u8m1x7
#define vssseg7e_v_i8m1x7_m	vssseg7e8_v_i8m1x7_m
#define vssseg7e_v_u8m1x7_m	vssseg7e8_v_u8m1x7_m
#define vssseg8e_v_i8m1x8	vssseg8e8_v_i8m1x8
#define vssseg8e_v_u8m1x8	vssseg8e8_v_u8m1x8
#define vssseg8e_v_i8m1x8_m	vssseg8e8_v_i8m1x8_m
#define vssseg8e_v_u8m1x8_m	vssseg8e8_v_u8m1x8_m
#define vssseg2e_v_i8m2x2	vssseg2e8_v_i8m2x2
#define vssseg2e_v_u8m2x2	vssseg2e8_v_u8m2x2
#define vssseg2e_v_i8m2x2_m	vssseg2e8_v_i8m2x2_m
#define vssseg2e_v_u8m2x2_m	vssseg2e8_v_u8m2x2_m
#define vssseg3e_v_i8m2x3	vssseg3e8_v_i8m2x3
#define vssseg3e_v_u8m2x3	vssseg3e8_v_u8m2x3
#define vssseg3e_v_i8m2x3_m	vssseg3e8_v_i8m2x3_m
#define vssseg3e_v_u8m2x3_m	vssseg3e8_v_u8m2x3_m
#define vssseg4e_v_i8m2x4	vssseg4e8_v_i8m2x4
#define vssseg4e_v_u8m2x4	vssseg4e8_v_u8m2x4
#define vssseg4e_v_i8m2x4_m	vssseg4e8_v_i8m2x4_m
#define vssseg4e_v_u8m2x4_m	vssseg4e8_v_u8m2x4_m
#define vssseg2e_v_i8m4x2	vssseg2e8_v_i8m4x2
#define vssseg2e_v_u8m4x2	vssseg2e8_v_u8m4x2
#define vssseg2e_v_i8m4x2_m	vssseg2e8_v_i8m4x2_m
#define vssseg2e_v_u8m4x2_m	vssseg2e8_v_u8m4x2_m
#define vssseg2e_v_i16m1x2	vssseg2e16_v_i16m1x2
#define vssseg2e_v_u16m1x2	vssseg2e16_v_u16m1x2
#define vssseg2e_v_i16m1x2_m	vssseg2e16_v_i16m1x2_m
#define vssseg2e_v_u16m1x2_m	vssseg2e16_v_u16m1x2_m
#define vssseg3e_v_i16m1x3	vssseg3e16_v_i16m1x3
#define vssseg3e_v_u16m1x3	vssseg3e16_v_u16m1x3
#define vssseg3e_v_i16m1x3_m	vssseg3e16_v_i16m1x3_m
#define vssseg3e_v_u16m1x3_m	vssseg3e16_v_u16m1x3_m
#define vssseg4e_v_i16m1x4	vssseg4e16_v_i16m1x4
#define vssseg4e_v_u16m1x4	vssseg4e16_v_u16m1x4
#define vssseg4e_v_i16m1x4_m	vssseg4e16_v_i16m1x4_m
#define vssseg4e_v_u16m1x4_m	vssseg4e16_v_u16m1x4_m
#define vssseg5e_v_i16m1x5	vssseg5e16_v_i16m1x5
#define vssseg5e_v_u16m1x5	vssseg5e16_v_u16m1x5
#define vssseg5e_v_i16m1x5_m	vssseg5e16_v_i16m1x5_m
#define vssseg5e_v_u16m1x5_m	vssseg5e16_v_u16m1x5_m
#define vssseg6e_v_i16m1x6	vssseg6e16_v_i16m1x6
#define vssseg6e_v_u16m1x6	vssseg6e16_v_u16m1x6
#define vssseg6e_v_i16m1x6_m	vssseg6e16_v_i16m1x6_m
#define vssseg6e_v_u16m1x6_m	vssseg6e16_v_u16m1x6_m
#define vssseg7e_v_i16m1x7	vssseg7e16_v_i16m1x7
#define vssseg7e_v_u16m1x7	vssseg7e16_v_u16m1x7
#define vssseg7e_v_i16m1x7_m	vssseg7e16_v_i16m1x7_m
#define vssseg7e_v_u16m1x7_m	vssseg7e16_v_u16m1x7_m
#define vssseg8e_v_i16m1x8	vssseg8e16_v_i16m1x8
#define vssseg8e_v_u16m1x8	vssseg8e16_v_u16m1x8
#define vssseg8e_v_i16m1x8_m	vssseg8e16_v_i16m1x8_m
#define vssseg8e_v_u16m1x8_m	vssseg8e16_v_u16m1x8_m
#define vssseg2e_v_i16m2x2	vssseg2e16_v_i16m2x2
#define vssseg2e_v_u16m2x2	vssseg2e16_v_u16m2x2
#define vssseg2e_v_i16m2x2_m	vssseg2e16_v_i16m2x2_m
#define vssseg2e_v_u16m2x2_m	vssseg2e16_v_u16m2x2_m
#define vssseg3e_v_i16m2x3	vssseg3e16_v_i16m2x3
#define vssseg3e_v_u16m2x3	vssseg3e16_v_u16m2x3
#define vssseg3e_v_i16m2x3_m	vssseg3e16_v_i16m2x3_m
#define vssseg3e_v_u16m2x3_m	vssseg3e16_v_u16m2x3_m
#define vssseg4e_v_i16m2x4	vssseg4e16_v_i16m2x4
#define vssseg4e_v_u16m2x4	vssseg4e16_v_u16m2x4
#define vssseg4e_v_i16m2x4_m	vssseg4e16_v_i16m2x4_m
#define vssseg4e_v_u16m2x4_m	vssseg4e16_v_u16m2x4_m
#define vssseg2e_v_i16m4x2	vssseg2e16_v_i16m4x2
#define vssseg2e_v_u16m4x2	vssseg2e16_v_u16m4x2
#define vssseg2e_v_i16m4x2_m	vssseg2e16_v_i16m4x2_m
#define vssseg2e_v_u16m4x2_m	vssseg2e16_v_u16m4x2_m
#define vssseg2e_v_i32m1x2	vssseg2e32_v_i32m1x2
#define vssseg2e_v_u32m1x2	vssseg2e32_v_u32m1x2
#define vssseg2e_v_i32m1x2_m	vssseg2e32_v_i32m1x2_m
#define vssseg2e_v_u32m1x2_m	vssseg2e32_v_u32m1x2_m
#define vssseg3e_v_i32m1x3	vssseg3e32_v_i32m1x3
#define vssseg3e_v_u32m1x3	vssseg3e32_v_u32m1x3
#define vssseg3e_v_i32m1x3_m	vssseg3e32_v_i32m1x3_m
#define vssseg3e_v_u32m1x3_m	vssseg3e32_v_u32m1x3_m
#define vssseg4e_v_i32m1x4	vssseg4e32_v_i32m1x4
#define vssseg4e_v_u32m1x4	vssseg4e32_v_u32m1x4
#define vssseg4e_v_i32m1x4_m	vssseg4e32_v_i32m1x4_m
#define vssseg4e_v_u32m1x4_m	vssseg4e32_v_u32m1x4_m
#define vssseg5e_v_i32m1x5	vssseg5e32_v_i32m1x5
#define vssseg5e_v_u32m1x5	vssseg5e32_v_u32m1x5
#define vssseg5e_v_i32m1x5_m	vssseg5e32_v_i32m1x5_m
#define vssseg5e_v_u32m1x5_m	vssseg5e32_v_u32m1x5_m
#define vssseg6e_v_i32m1x6	vssseg6e32_v_i32m1x6
#define vssseg6e_v_u32m1x6	vssseg6e32_v_u32m1x6
#define vssseg6e_v_i32m1x6_m	vssseg6e32_v_i32m1x6_m
#define vssseg6e_v_u32m1x6_m	vssseg6e32_v_u32m1x6_m
#define vssseg7e_v_i32m1x7	vssseg7e32_v_i32m1x7
#define vssseg7e_v_u32m1x7	vssseg7e32_v_u32m1x7
#define vssseg7e_v_i32m1x7_m	vssseg7e32_v_i32m1x7_m
#define vssseg7e_v_u32m1x7_m	vssseg7e32_v_u32m1x7_m
#define vssseg8e_v_i32m1x8	vssseg8e32_v_i32m1x8
#define vssseg8e_v_u32m1x8	vssseg8e32_v_u32m1x8
#define vssseg8e_v_i32m1x8_m	vssseg8e32_v_i32m1x8_m
#define vssseg8e_v_u32m1x8_m	vssseg8e32_v_u32m1x8_m
#define vssseg2e_v_i32m2x2	vssseg2e32_v_i32m2x2
#define vssseg2e_v_u32m2x2	vssseg2e32_v_u32m2x2
#define vssseg2e_v_i32m2x2_m	vssseg2e32_v_i32m2x2_m
#define vssseg2e_v_u32m2x2_m	vssseg2e32_v_u32m2x2_m
#define vssseg3e_v_i32m2x3	vssseg3e32_v_i32m2x3
#define vssseg3e_v_u32m2x3	vssseg3e32_v_u32m2x3
#define vssseg3e_v_i32m2x3_m	vssseg3e32_v_i32m2x3_m
#define vssseg3e_v_u32m2x3_m	vssseg3e32_v_u32m2x3_m
#define vssseg4e_v_i32m2x4	vssseg4e32_v_i32m2x4
#define vssseg4e_v_u32m2x4	vssseg4e32_v_u32m2x4
#define vssseg4e_v_i32m2x4_m	vssseg4e32_v_i32m2x4_m
#define vssseg4e_v_u32m2x4_m	vssseg4e32_v_u32m2x4_m
#define vssseg2e_v_i32m4x2	vssseg2e32_v_i32m4x2
#define vssseg2e_v_u32m4x2	vssseg2e32_v_u32m4x2
#define vssseg2e_v_i32m4x2_m	vssseg2e32_v_i32m4x2_m
#define vssseg2e_v_u32m4x2_m	vssseg2e32_v_u32m4x2_m
#define vssseg2e_v_i64m1x2	vssseg2e64_v_i64m1x2
#define vssseg2e_v_u64m1x2	vssseg2e64_v_u64m1x2
#define vssseg2e_v_i64m1x2_m	vssseg2e64_v_i64m1x2_m
#define vssseg2e_v_u64m1x2_m	vssseg2e64_v_u64m1x2_m
#define vssseg3e_v_i64m1x3	vssseg3e64_v_i64m1x3
#define vssseg3e_v_u64m1x3	vssseg3e64_v_u64m1x3
#define vssseg3e_v_i64m1x3_m	vssseg3e64_v_i64m1x3_m
#define vssseg3e_v_u64m1x3_m	vssseg3e64_v_u64m1x3_m
#define vssseg4e_v_i64m1x4	vssseg4e64_v_i64m1x4
#define vssseg4e_v_u64m1x4	vssseg4e64_v_u64m1x4
#define vssseg4e_v_i64m1x4_m	vssseg4e64_v_i64m1x4_m
#define vssseg4e_v_u64m1x4_m	vssseg4e64_v_u64m1x4_m
#define vssseg5e_v_i64m1x5	vssseg5e64_v_i64m1x5
#define vssseg5e_v_u64m1x5	vssseg5e64_v_u64m1x5
#define vssseg5e_v_i64m1x5_m	vssseg5e64_v_i64m1x5_m
#define vssseg5e_v_u64m1x5_m	vssseg5e64_v_u64m1x5_m
#define vssseg6e_v_i64m1x6	vssseg6e64_v_i64m1x6
#define vssseg6e_v_u64m1x6	vssseg6e64_v_u64m1x6
#define vssseg6e_v_i64m1x6_m	vssseg6e64_v_i64m1x6_m
#define vssseg6e_v_u64m1x6_m	vssseg6e64_v_u64m1x6_m
#define vssseg7e_v_i64m1x7	vssseg7e64_v_i64m1x7
#define vssseg7e_v_u64m1x7	vssseg7e64_v_u64m1x7
#define vssseg7e_v_i64m1x7_m	vssseg7e64_v_i64m1x7_m
#define vssseg7e_v_u64m1x7_m	vssseg7e64_v_u64m1x7_m
#define vssseg8e_v_i64m1x8	vssseg8e64_v_i64m1x8
#define vssseg8e_v_u64m1x8	vssseg8e64_v_u64m1x8
#define vssseg8e_v_i64m1x8_m	vssseg8e64_v_i64m1x8_m
#define vssseg8e_v_u64m1x8_m	vssseg8e64_v_u64m1x8_m
#define vssseg2e_v_i64m2x2	vssseg2e64_v_i64m2x2
#define vssseg2e_v_u64m2x2	vssseg2e64_v_u64m2x2
#define vssseg2e_v_i64m2x2_m	vssseg2e64_v_i64m2x2_m
#define vssseg2e_v_u64m2x2_m	vssseg2e64_v_u64m2x2_m
#define vssseg3e_v_i64m2x3	vssseg3e64_v_i64m2x3
#define vssseg3e_v_u64m2x3	vssseg3e64_v_u64m2x3
#define vssseg3e_v_i64m2x3_m	vssseg3e64_v_i64m2x3_m
#define vssseg3e_v_u64m2x3_m	vssseg3e64_v_u64m2x3_m
#define vssseg4e_v_i64m2x4	vssseg4e64_v_i64m2x4
#define vssseg4e_v_u64m2x4	vssseg4e64_v_u64m2x4
#define vssseg4e_v_i64m2x4_m	vssseg4e64_v_i64m2x4_m
#define vssseg4e_v_u64m2x4_m	vssseg4e64_v_u64m2x4_m
#define vssseg2e_v_i64m4x2	vssseg2e64_v_i64m4x2
#define vssseg2e_v_u64m4x2	vssseg2e64_v_u64m4x2
#define vssseg2e_v_i64m4x2_m	vssseg2e64_v_i64m4x2_m
#define vssseg2e_v_u64m4x2_m	vssseg2e64_v_u64m4x2_m
#define vssseg2e_v_f16m1x2	vssseg2e16_v_f16m1x2
#define vssseg2e_v_f16m1x2_m	vssseg2e16_v_f16m1x2_m
#define vssseg3e_v_f16m1x3	vssseg3e16_v_f16m1x3
#define vssseg3e_v_f16m1x3_m	vssseg3e16_v_f16m1x3_m
#define vssseg4e_v_f16m1x4	vssseg4e16_v_f16m1x4
#define vssseg4e_v_f16m1x4_m	vssseg4e16_v_f16m1x4_m
#define vssseg5e_v_f16m1x5	vssseg5e16_v_f16m1x5
#define vssseg5e_v_f16m1x5_m	vssseg5e16_v_f16m1x5_m
#define vssseg6e_v_f16m1x6	vssseg6e16_v_f16m1x6
#define vssseg6e_v_f16m1x6_m	vssseg6e16_v_f16m1x6_m
#define vssseg7e_v_f16m1x7	vssseg7e16_v_f16m1x7
#define vssseg7e_v_f16m1x7_m	vssseg7e16_v_f16m1x7_m
#define vssseg8e_v_f16m1x8	vssseg8e16_v_f16m1x8
#define vssseg8e_v_f16m1x8_m	vssseg8e16_v_f16m1x8_m
#define vssseg2e_v_f16m2x2	vssseg2e16_v_f16m2x2
#define vssseg2e_v_f16m2x2_m	vssseg2e16_v_f16m2x2_m
#define vssseg3e_v_f16m2x3	vssseg3e16_v_f16m2x3
#define vssseg3e_v_f16m2x3_m	vssseg3e16_v_f16m2x3_m
#define vssseg4e_v_f16m2x4	vssseg4e16_v_f16m2x4
#define vssseg4e_v_f16m2x4_m	vssseg4e16_v_f16m2x4_m
#define vssseg2e_v_f16m4x2	vssseg2e16_v_f16m4x2
#define vssseg2e_v_f16m4x2_m	vssseg2e16_v_f16m4x2_m
#define vssseg2e_v_f32m1x2	vssseg2e32_v_f32m1x2
#define vssseg2e_v_f32m1x2_m	vssseg2e32_v_f32m1x2_m
#define vssseg3e_v_f32m1x3	vssseg3e32_v_f32m1x3
#define vssseg3e_v_f32m1x3_m	vssseg3e32_v_f32m1x3_m
#define vssseg4e_v_f32m1x4	vssseg4e32_v_f32m1x4
#define vssseg4e_v_f32m1x4_m	vssseg4e32_v_f32m1x4_m
#define vssseg5e_v_f32m1x5	vssseg5e32_v_f32m1x5
#define vssseg5e_v_f32m1x5_m	vssseg5e32_v_f32m1x5_m
#define vssseg6e_v_f32m1x6	vssseg6e32_v_f32m1x6
#define vssseg6e_v_f32m1x6_m	vssseg6e32_v_f32m1x6_m
#define vssseg7e_v_f32m1x7	vssseg7e32_v_f32m1x7
#define vssseg7e_v_f32m1x7_m	vssseg7e32_v_f32m1x7_m
#define vssseg8e_v_f32m1x8	vssseg8e32_v_f32m1x8
#define vssseg8e_v_f32m1x8_m	vssseg8e32_v_f32m1x8_m
#define vssseg2e_v_f32m2x2	vssseg2e32_v_f32m2x2
#define vssseg2e_v_f32m2x2_m	vssseg2e32_v_f32m2x2_m
#define vssseg3e_v_f32m2x3	vssseg3e32_v_f32m2x3
#define vssseg3e_v_f32m2x3_m	vssseg3e32_v_f32m2x3_m
#define vssseg4e_v_f32m2x4	vssseg4e32_v_f32m2x4
#define vssseg4e_v_f32m2x4_m	vssseg4e32_v_f32m2x4_m
#define vssseg2e_v_f32m4x2	vssseg2e32_v_f32m4x2
#define vssseg2e_v_f32m4x2_m	vssseg2e32_v_f32m4x2_m
#define vssseg2e_v_f64m1x2	vssseg2e64_v_f64m1x2
#define vssseg2e_v_f64m1x2_m	vssseg2e64_v_f64m1x2_m
#define vssseg3e_v_f64m1x3	vssseg3e64_v_f64m1x3
#define vssseg3e_v_f64m1x3_m	vssseg3e64_v_f64m1x3_m
#define vssseg4e_v_f64m1x4	vssseg4e64_v_f64m1x4
#define vssseg4e_v_f64m1x4_m	vssseg4e64_v_f64m1x4_m
#define vssseg5e_v_f64m1x5	vssseg5e64_v_f64m1x5
#define vssseg5e_v_f64m1x5_m	vssseg5e64_v_f64m1x5_m
#define vssseg6e_v_f64m1x6	vssseg6e64_v_f64m1x6
#define vssseg6e_v_f64m1x6_m	vssseg6e64_v_f64m1x6_m
#define vssseg7e_v_f64m1x7	vssseg7e64_v_f64m1x7
#define vssseg7e_v_f64m1x7_m	vssseg7e64_v_f64m1x7_m
#define vssseg8e_v_f64m1x8	vssseg8e64_v_f64m1x8
#define vssseg8e_v_f64m1x8_m	vssseg8e64_v_f64m1x8_m
#define vssseg2e_v_f64m2x2	vssseg2e64_v_f64m2x2
#define vssseg2e_v_f64m2x2_m	vssseg2e64_v_f64m2x2_m
#define vssseg3e_v_f64m2x3	vssseg3e64_v_f64m2x3
#define vssseg3e_v_f64m2x3_m	vssseg3e64_v_f64m2x3_m
#define vssseg4e_v_f64m2x4	vssseg4e64_v_f64m2x4
#define vssseg4e_v_f64m2x4_m	vssseg4e64_v_f64m2x4_m
#define vssseg2e_v_f64m4x2	vssseg2e64_v_f64m4x2
#define vssseg2e_v_f64m4x2_m	vssseg2e64_v_f64m4x2_m

/* Wrapper only.  */
#define vlxseg2e_v_i8m1x2	vloxseg2ei8_v_i8m1x2
#define vlxseg2e_v_u8m1x2	vloxseg2ei8_v_u8m1x2
#define vlxseg2e_v_i8m1x2_m	vloxseg2ei8_v_i8m1x2_m
#define vlxseg2e_v_u8m1x2_m	vloxseg2ei8_v_u8m1x2_m
#define vlxseg3e_v_i8m1x3	vloxseg3ei8_v_i8m1x3
#define vlxseg3e_v_u8m1x3	vloxseg3ei8_v_u8m1x3
#define vlxseg3e_v_i8m1x3_m	vloxseg3ei8_v_i8m1x3_m
#define vlxseg3e_v_u8m1x3_m	vloxseg3ei8_v_u8m1x3_m
#define vlxseg4e_v_i8m1x4	vloxseg4ei8_v_i8m1x4
#define vlxseg4e_v_u8m1x4	vloxseg4ei8_v_u8m1x4
#define vlxseg4e_v_i8m1x4_m	vloxseg4ei8_v_i8m1x4_m
#define vlxseg4e_v_u8m1x4_m	vloxseg4ei8_v_u8m1x4_m
#define vlxseg5e_v_i8m1x5	vloxseg5ei8_v_i8m1x5
#define vlxseg5e_v_u8m1x5	vloxseg5ei8_v_u8m1x5
#define vlxseg5e_v_i8m1x5_m	vloxseg5ei8_v_i8m1x5_m
#define vlxseg5e_v_u8m1x5_m	vloxseg5ei8_v_u8m1x5_m
#define vlxseg6e_v_i8m1x6	vloxseg6ei8_v_i8m1x6
#define vlxseg6e_v_u8m1x6	vloxseg6ei8_v_u8m1x6
#define vlxseg6e_v_i8m1x6_m	vloxseg6ei8_v_i8m1x6_m
#define vlxseg6e_v_u8m1x6_m	vloxseg6ei8_v_u8m1x6_m
#define vlxseg7e_v_i8m1x7	vloxseg7ei8_v_i8m1x7
#define vlxseg7e_v_u8m1x7	vloxseg7ei8_v_u8m1x7
#define vlxseg7e_v_i8m1x7_m	vloxseg7ei8_v_i8m1x7_m
#define vlxseg7e_v_u8m1x7_m	vloxseg7ei8_v_u8m1x7_m
#define vlxseg8e_v_i8m1x8	vloxseg8ei8_v_i8m1x8
#define vlxseg8e_v_u8m1x8	vloxseg8ei8_v_u8m1x8
#define vlxseg8e_v_i8m1x8_m	vloxseg8ei8_v_i8m1x8_m
#define vlxseg8e_v_u8m1x8_m	vloxseg8ei8_v_u8m1x8_m
#define vlxseg2e_v_i8m2x2	vloxseg2ei8_v_i8m2x2
#define vlxseg2e_v_u8m2x2	vloxseg2ei8_v_u8m2x2
#define vlxseg2e_v_i8m2x2_m	vloxseg2ei8_v_i8m2x2_m
#define vlxseg2e_v_u8m2x2_m	vloxseg2ei8_v_u8m2x2_m
#define vlxseg3e_v_i8m2x3	vloxseg3ei8_v_i8m2x3
#define vlxseg3e_v_u8m2x3	vloxseg3ei8_v_u8m2x3
#define vlxseg3e_v_i8m2x3_m	vloxseg3ei8_v_i8m2x3_m
#define vlxseg3e_v_u8m2x3_m	vloxseg3ei8_v_u8m2x3_m
#define vlxseg4e_v_i8m2x4	vloxseg4ei8_v_i8m2x4
#define vlxseg4e_v_u8m2x4	vloxseg4ei8_v_u8m2x4
#define vlxseg4e_v_i8m2x4_m	vloxseg4ei8_v_i8m2x4_m
#define vlxseg4e_v_u8m2x4_m	vloxseg4ei8_v_u8m2x4_m
#define vlxseg2e_v_i8m4x2	vloxseg2ei8_v_i8m4x2
#define vlxseg2e_v_u8m4x2	vloxseg2ei8_v_u8m4x2
#define vlxseg2e_v_i8m4x2_m	vloxseg2ei8_v_i8m4x2_m
#define vlxseg2e_v_u8m4x2_m	vloxseg2ei8_v_u8m4x2_m
#define vlxseg2e_v_i16m1x2	vloxseg2ei16_v_i16m1x2
#define vlxseg2e_v_u16m1x2	vloxseg2ei16_v_u16m1x2
#define vlxseg2e_v_i16m1x2_m	vloxseg2ei16_v_i16m1x2_m
#define vlxseg2e_v_u16m1x2_m	vloxseg2ei16_v_u16m1x2_m
#define vlxseg3e_v_i16m1x3	vloxseg3ei16_v_i16m1x3
#define vlxseg3e_v_u16m1x3	vloxseg3ei16_v_u16m1x3
#define vlxseg3e_v_i16m1x3_m	vloxseg3ei16_v_i16m1x3_m
#define vlxseg3e_v_u16m1x3_m	vloxseg3ei16_v_u16m1x3_m
#define vlxseg4e_v_i16m1x4	vloxseg4ei16_v_i16m1x4
#define vlxseg4e_v_u16m1x4	vloxseg4ei16_v_u16m1x4
#define vlxseg4e_v_i16m1x4_m	vloxseg4ei16_v_i16m1x4_m
#define vlxseg4e_v_u16m1x4_m	vloxseg4ei16_v_u16m1x4_m
#define vlxseg5e_v_i16m1x5	vloxseg5ei16_v_i16m1x5
#define vlxseg5e_v_u16m1x5	vloxseg5ei16_v_u16m1x5
#define vlxseg5e_v_i16m1x5_m	vloxseg5ei16_v_i16m1x5_m
#define vlxseg5e_v_u16m1x5_m	vloxseg5ei16_v_u16m1x5_m
#define vlxseg6e_v_i16m1x6	vloxseg6ei16_v_i16m1x6
#define vlxseg6e_v_u16m1x6	vloxseg6ei16_v_u16m1x6
#define vlxseg6e_v_i16m1x6_m	vloxseg6ei16_v_i16m1x6_m
#define vlxseg6e_v_u16m1x6_m	vloxseg6ei16_v_u16m1x6_m
#define vlxseg7e_v_i16m1x7	vloxseg7ei16_v_i16m1x7
#define vlxseg7e_v_u16m1x7	vloxseg7ei16_v_u16m1x7
#define vlxseg7e_v_i16m1x7_m	vloxseg7ei16_v_i16m1x7_m
#define vlxseg7e_v_u16m1x7_m	vloxseg7ei16_v_u16m1x7_m
#define vlxseg8e_v_i16m1x8	vloxseg8ei16_v_i16m1x8
#define vlxseg8e_v_u16m1x8	vloxseg8ei16_v_u16m1x8
#define vlxseg8e_v_i16m1x8_m	vloxseg8ei16_v_i16m1x8_m
#define vlxseg8e_v_u16m1x8_m	vloxseg8ei16_v_u16m1x8_m
#define vlxseg2e_v_i16m2x2	vloxseg2ei16_v_i16m2x2
#define vlxseg2e_v_u16m2x2	vloxseg2ei16_v_u16m2x2
#define vlxseg2e_v_i16m2x2_m	vloxseg2ei16_v_i16m2x2_m
#define vlxseg2e_v_u16m2x2_m	vloxseg2ei16_v_u16m2x2_m
#define vlxseg3e_v_i16m2x3	vloxseg3ei16_v_i16m2x3
#define vlxseg3e_v_u16m2x3	vloxseg3ei16_v_u16m2x3
#define vlxseg3e_v_i16m2x3_m	vloxseg3ei16_v_i16m2x3_m
#define vlxseg3e_v_u16m2x3_m	vloxseg3ei16_v_u16m2x3_m
#define vlxseg4e_v_i16m2x4	vloxseg4ei16_v_i16m2x4
#define vlxseg4e_v_u16m2x4	vloxseg4ei16_v_u16m2x4
#define vlxseg4e_v_i16m2x4_m	vloxseg4ei16_v_i16m2x4_m
#define vlxseg4e_v_u16m2x4_m	vloxseg4ei16_v_u16m2x4_m
#define vlxseg2e_v_i16m4x2	vloxseg2ei16_v_i16m4x2
#define vlxseg2e_v_u16m4x2	vloxseg2ei16_v_u16m4x2
#define vlxseg2e_v_i16m4x2_m	vloxseg2ei16_v_i16m4x2_m
#define vlxseg2e_v_u16m4x2_m	vloxseg2ei16_v_u16m4x2_m
#define vlxseg2e_v_i32m1x2	vloxseg2ei32_v_i32m1x2
#define vlxseg2e_v_u32m1x2	vloxseg2ei32_v_u32m1x2
#define vlxseg2e_v_i32m1x2_m	vloxseg2ei32_v_i32m1x2_m
#define vlxseg2e_v_u32m1x2_m	vloxseg2ei32_v_u32m1x2_m
#define vlxseg3e_v_i32m1x3	vloxseg3ei32_v_i32m1x3
#define vlxseg3e_v_u32m1x3	vloxseg3ei32_v_u32m1x3
#define vlxseg3e_v_i32m1x3_m	vloxseg3ei32_v_i32m1x3_m
#define vlxseg3e_v_u32m1x3_m	vloxseg3ei32_v_u32m1x3_m
#define vlxseg4e_v_i32m1x4	vloxseg4ei32_v_i32m1x4
#define vlxseg4e_v_u32m1x4	vloxseg4ei32_v_u32m1x4
#define vlxseg4e_v_i32m1x4_m	vloxseg4ei32_v_i32m1x4_m
#define vlxseg4e_v_u32m1x4_m	vloxseg4ei32_v_u32m1x4_m
#define vlxseg5e_v_i32m1x5	vloxseg5ei32_v_i32m1x5
#define vlxseg5e_v_u32m1x5	vloxseg5ei32_v_u32m1x5
#define vlxseg5e_v_i32m1x5_m	vloxseg5ei32_v_i32m1x5_m
#define vlxseg5e_v_u32m1x5_m	vloxseg5ei32_v_u32m1x5_m
#define vlxseg6e_v_i32m1x6	vloxseg6ei32_v_i32m1x6
#define vlxseg6e_v_u32m1x6	vloxseg6ei32_v_u32m1x6
#define vlxseg6e_v_i32m1x6_m	vloxseg6ei32_v_i32m1x6_m
#define vlxseg6e_v_u32m1x6_m	vloxseg6ei32_v_u32m1x6_m
#define vlxseg7e_v_i32m1x7	vloxseg7ei32_v_i32m1x7
#define vlxseg7e_v_u32m1x7	vloxseg7ei32_v_u32m1x7
#define vlxseg7e_v_i32m1x7_m	vloxseg7ei32_v_i32m1x7_m
#define vlxseg7e_v_u32m1x7_m	vloxseg7ei32_v_u32m1x7_m
#define vlxseg8e_v_i32m1x8	vloxseg8ei32_v_i32m1x8
#define vlxseg8e_v_u32m1x8	vloxseg8ei32_v_u32m1x8
#define vlxseg8e_v_i32m1x8_m	vloxseg8ei32_v_i32m1x8_m
#define vlxseg8e_v_u32m1x8_m	vloxseg8ei32_v_u32m1x8_m
#define vlxseg2e_v_i32m2x2	vloxseg2ei32_v_i32m2x2
#define vlxseg2e_v_u32m2x2	vloxseg2ei32_v_u32m2x2
#define vlxseg2e_v_i32m2x2_m	vloxseg2ei32_v_i32m2x2_m
#define vlxseg2e_v_u32m2x2_m	vloxseg2ei32_v_u32m2x2_m
#define vlxseg3e_v_i32m2x3	vloxseg3ei32_v_i32m2x3
#define vlxseg3e_v_u32m2x3	vloxseg3ei32_v_u32m2x3
#define vlxseg3e_v_i32m2x3_m	vloxseg3ei32_v_i32m2x3_m
#define vlxseg3e_v_u32m2x3_m	vloxseg3ei32_v_u32m2x3_m
#define vlxseg4e_v_i32m2x4	vloxseg4ei32_v_i32m2x4
#define vlxseg4e_v_u32m2x4	vloxseg4ei32_v_u32m2x4
#define vlxseg4e_v_i32m2x4_m	vloxseg4ei32_v_i32m2x4_m
#define vlxseg4e_v_u32m2x4_m	vloxseg4ei32_v_u32m2x4_m
#define vlxseg2e_v_i32m4x2	vloxseg2ei32_v_i32m4x2
#define vlxseg2e_v_u32m4x2	vloxseg2ei32_v_u32m4x2
#define vlxseg2e_v_i32m4x2_m	vloxseg2ei32_v_i32m4x2_m
#define vlxseg2e_v_u32m4x2_m	vloxseg2ei32_v_u32m4x2_m
#define vlxseg2e_v_i64m1x2	vloxseg2ei64_v_i64m1x2
#define vlxseg2e_v_u64m1x2	vloxseg2ei64_v_u64m1x2
#define vlxseg2e_v_i64m1x2_m	vloxseg2ei64_v_i64m1x2_m
#define vlxseg2e_v_u64m1x2_m	vloxseg2ei64_v_u64m1x2_m
#define vlxseg3e_v_i64m1x3	vloxseg3ei64_v_i64m1x3
#define vlxseg3e_v_u64m1x3	vloxseg3ei64_v_u64m1x3
#define vlxseg3e_v_i64m1x3_m	vloxseg3ei64_v_i64m1x3_m
#define vlxseg3e_v_u64m1x3_m	vloxseg3ei64_v_u64m1x3_m
#define vlxseg4e_v_i64m1x4	vloxseg4ei64_v_i64m1x4
#define vlxseg4e_v_u64m1x4	vloxseg4ei64_v_u64m1x4
#define vlxseg4e_v_i64m1x4_m	vloxseg4ei64_v_i64m1x4_m
#define vlxseg4e_v_u64m1x4_m	vloxseg4ei64_v_u64m1x4_m
#define vlxseg5e_v_i64m1x5	vloxseg5ei64_v_i64m1x5
#define vlxseg5e_v_u64m1x5	vloxseg5ei64_v_u64m1x5
#define vlxseg5e_v_i64m1x5_m	vloxseg5ei64_v_i64m1x5_m
#define vlxseg5e_v_u64m1x5_m	vloxseg5ei64_v_u64m1x5_m
#define vlxseg6e_v_i64m1x6	vloxseg6ei64_v_i64m1x6
#define vlxseg6e_v_u64m1x6	vloxseg6ei64_v_u64m1x6
#define vlxseg6e_v_i64m1x6_m	vloxseg6ei64_v_i64m1x6_m
#define vlxseg6e_v_u64m1x6_m	vloxseg6ei64_v_u64m1x6_m
#define vlxseg7e_v_i64m1x7	vloxseg7ei64_v_i64m1x7
#define vlxseg7e_v_u64m1x7	vloxseg7ei64_v_u64m1x7
#define vlxseg7e_v_i64m1x7_m	vloxseg7ei64_v_i64m1x7_m
#define vlxseg7e_v_u64m1x7_m	vloxseg7ei64_v_u64m1x7_m
#define vlxseg8e_v_i64m1x8	vloxseg8ei64_v_i64m1x8
#define vlxseg8e_v_u64m1x8	vloxseg8ei64_v_u64m1x8
#define vlxseg8e_v_i64m1x8_m	vloxseg8ei64_v_i64m1x8_m
#define vlxseg8e_v_u64m1x8_m	vloxseg8ei64_v_u64m1x8_m
#define vlxseg2e_v_i64m2x2	vloxseg2ei64_v_i64m2x2
#define vlxseg2e_v_u64m2x2	vloxseg2ei64_v_u64m2x2
#define vlxseg2e_v_i64m2x2_m	vloxseg2ei64_v_i64m2x2_m
#define vlxseg2e_v_u64m2x2_m	vloxseg2ei64_v_u64m2x2_m
#define vlxseg3e_v_i64m2x3	vloxseg3ei64_v_i64m2x3
#define vlxseg3e_v_u64m2x3	vloxseg3ei64_v_u64m2x3
#define vlxseg3e_v_i64m2x3_m	vloxseg3ei64_v_i64m2x3_m
#define vlxseg3e_v_u64m2x3_m	vloxseg3ei64_v_u64m2x3_m
#define vlxseg4e_v_i64m2x4	vloxseg4ei64_v_i64m2x4
#define vlxseg4e_v_u64m2x4	vloxseg4ei64_v_u64m2x4
#define vlxseg4e_v_i64m2x4_m	vloxseg4ei64_v_i64m2x4_m
#define vlxseg4e_v_u64m2x4_m	vloxseg4ei64_v_u64m2x4_m
#define vlxseg2e_v_i64m4x2	vloxseg2ei64_v_i64m4x2
#define vlxseg2e_v_u64m4x2	vloxseg2ei64_v_u64m4x2
#define vlxseg2e_v_i64m4x2_m	vloxseg2ei64_v_i64m4x2_m
#define vlxseg2e_v_u64m4x2_m	vloxseg2ei64_v_u64m4x2_m
#define vlxseg2e_v_f16m1x2	vloxseg2ei16_v_f16m1x2
#define vlxseg2e_v_f16m1x2_m	vloxseg2ei16_v_f16m1x2_m
#define vlxseg3e_v_f16m1x3	vloxseg3ei16_v_f16m1x3
#define vlxseg3e_v_f16m1x3_m	vloxseg3ei16_v_f16m1x3_m
#define vlxseg4e_v_f16m1x4	vloxseg4ei16_v_f16m1x4
#define vlxseg4e_v_f16m1x4_m	vloxseg4ei16_v_f16m1x4_m
#define vlxseg5e_v_f16m1x5	vloxseg5ei16_v_f16m1x5
#define vlxseg5e_v_f16m1x5_m	vloxseg5ei16_v_f16m1x5_m
#define vlxseg6e_v_f16m1x6	vloxseg6ei16_v_f16m1x6
#define vlxseg6e_v_f16m1x6_m	vloxseg6ei16_v_f16m1x6_m
#define vlxseg7e_v_f16m1x7	vloxseg7ei16_v_f16m1x7
#define vlxseg7e_v_f16m1x7_m	vloxseg7ei16_v_f16m1x7_m
#define vlxseg8e_v_f16m1x8	vloxseg8ei16_v_f16m1x8
#define vlxseg8e_v_f16m1x8_m	vloxseg8ei16_v_f16m1x8_m
#define vlxseg2e_v_f16m2x2	vloxseg2ei16_v_f16m2x2
#define vlxseg2e_v_f16m2x2_m	vloxseg2ei16_v_f16m2x2_m
#define vlxseg3e_v_f16m2x3	vloxseg3ei16_v_f16m2x3
#define vlxseg3e_v_f16m2x3_m	vloxseg3ei16_v_f16m2x3_m
#define vlxseg4e_v_f16m2x4	vloxseg4ei16_v_f16m2x4
#define vlxseg4e_v_f16m2x4_m	vloxseg4ei16_v_f16m2x4_m
#define vlxseg2e_v_f16m4x2	vloxseg2ei16_v_f16m4x2
#define vlxseg2e_v_f16m4x2_m	vloxseg2ei16_v_f16m4x2_m
#define vlxseg2e_v_f32m1x2	vloxseg2ei32_v_f32m1x2
#define vlxseg2e_v_f32m1x2_m	vloxseg2ei32_v_f32m1x2_m
#define vlxseg3e_v_f32m1x3	vloxseg3ei32_v_f32m1x3
#define vlxseg3e_v_f32m1x3_m	vloxseg3ei32_v_f32m1x3_m
#define vlxseg4e_v_f32m1x4	vloxseg4ei32_v_f32m1x4
#define vlxseg4e_v_f32m1x4_m	vloxseg4ei32_v_f32m1x4_m
#define vlxseg5e_v_f32m1x5	vloxseg5ei32_v_f32m1x5
#define vlxseg5e_v_f32m1x5_m	vloxseg5ei32_v_f32m1x5_m
#define vlxseg6e_v_f32m1x6	vloxseg6ei32_v_f32m1x6
#define vlxseg6e_v_f32m1x6_m	vloxseg6ei32_v_f32m1x6_m
#define vlxseg7e_v_f32m1x7	vloxseg7ei32_v_f32m1x7
#define vlxseg7e_v_f32m1x7_m	vloxseg7ei32_v_f32m1x7_m
#define vlxseg8e_v_f32m1x8	vloxseg8ei32_v_f32m1x8
#define vlxseg8e_v_f32m1x8_m	vloxseg8ei32_v_f32m1x8_m
#define vlxseg2e_v_f32m2x2	vloxseg2ei32_v_f32m2x2
#define vlxseg2e_v_f32m2x2_m	vloxseg2ei32_v_f32m2x2_m
#define vlxseg3e_v_f32m2x3	vloxseg3ei32_v_f32m2x3
#define vlxseg3e_v_f32m2x3_m	vloxseg3ei32_v_f32m2x3_m
#define vlxseg4e_v_f32m2x4	vloxseg4ei32_v_f32m2x4
#define vlxseg4e_v_f32m2x4_m	vloxseg4ei32_v_f32m2x4_m
#define vlxseg2e_v_f32m4x2	vloxseg2ei32_v_f32m4x2
#define vlxseg2e_v_f32m4x2_m	vloxseg2ei32_v_f32m4x2_m
#define vlxseg2e_v_f64m1x2	vloxseg2ei64_v_f64m1x2
#define vlxseg2e_v_f64m1x2_m	vloxseg2ei64_v_f64m1x2_m
#define vlxseg3e_v_f64m1x3	vloxseg3ei64_v_f64m1x3
#define vlxseg3e_v_f64m1x3_m	vloxseg3ei64_v_f64m1x3_m
#define vlxseg4e_v_f64m1x4	vloxseg4ei64_v_f64m1x4
#define vlxseg4e_v_f64m1x4_m	vloxseg4ei64_v_f64m1x4_m
#define vlxseg5e_v_f64m1x5	vloxseg5ei64_v_f64m1x5
#define vlxseg5e_v_f64m1x5_m	vloxseg5ei64_v_f64m1x5_m
#define vlxseg6e_v_f64m1x6	vloxseg6ei64_v_f64m1x6
#define vlxseg6e_v_f64m1x6_m	vloxseg6ei64_v_f64m1x6_m
#define vlxseg7e_v_f64m1x7	vloxseg7ei64_v_f64m1x7
#define vlxseg7e_v_f64m1x7_m	vloxseg7ei64_v_f64m1x7_m
#define vlxseg8e_v_f64m1x8	vloxseg8ei64_v_f64m1x8
#define vlxseg8e_v_f64m1x8_m	vloxseg8ei64_v_f64m1x8_m
#define vlxseg2e_v_f64m2x2	vloxseg2ei64_v_f64m2x2
#define vlxseg2e_v_f64m2x2_m	vloxseg2ei64_v_f64m2x2_m
#define vlxseg3e_v_f64m2x3	vloxseg3ei64_v_f64m2x3
#define vlxseg3e_v_f64m2x3_m	vloxseg3ei64_v_f64m2x3_m
#define vlxseg4e_v_f64m2x4	vloxseg4ei64_v_f64m2x4
#define vlxseg4e_v_f64m2x4_m	vloxseg4ei64_v_f64m2x4_m
#define vlxseg2e_v_f64m4x2	vloxseg2ei64_v_f64m4x2
#define vlxseg2e_v_f64m4x2_m	vloxseg2ei64_v_f64m4x2_m

/* Wrapper only.  */
#define vsxseg2e_v_i8m1x2	vsoxseg2ei8_v_i8m1x2
#define vsxseg2e_v_u8m1x2	vsoxseg2ei8_v_u8m1x2
#define vsxseg2e_v_i8m1x2_m	vsoxseg2ei8_v_i8m1x2_m
#define vsxseg2e_v_u8m1x2_m	vsoxseg2ei8_v_u8m1x2_m
#define vsxseg3e_v_i8m1x3	vsoxseg3ei8_v_i8m1x3
#define vsxseg3e_v_u8m1x3	vsoxseg3ei8_v_u8m1x3
#define vsxseg3e_v_i8m1x3_m	vsoxseg3ei8_v_i8m1x3_m
#define vsxseg3e_v_u8m1x3_m	vsoxseg3ei8_v_u8m1x3_m
#define vsxseg4e_v_i8m1x4	vsoxseg4ei8_v_i8m1x4
#define vsxseg4e_v_u8m1x4	vsoxseg4ei8_v_u8m1x4
#define vsxseg4e_v_i8m1x4_m	vsoxseg4ei8_v_i8m1x4_m
#define vsxseg4e_v_u8m1x4_m	vsoxseg4ei8_v_u8m1x4_m
#define vsxseg5e_v_i8m1x5	vsoxseg5ei8_v_i8m1x5
#define vsxseg5e_v_u8m1x5	vsoxseg5ei8_v_u8m1x5
#define vsxseg5e_v_i8m1x5_m	vsoxseg5ei8_v_i8m1x5_m
#define vsxseg5e_v_u8m1x5_m	vsoxseg5ei8_v_u8m1x5_m
#define vsxseg6e_v_i8m1x6	vsoxseg6ei8_v_i8m1x6
#define vsxseg6e_v_u8m1x6	vsoxseg6ei8_v_u8m1x6
#define vsxseg6e_v_i8m1x6_m	vsoxseg6ei8_v_i8m1x6_m
#define vsxseg6e_v_u8m1x6_m	vsoxseg6ei8_v_u8m1x6_m
#define vsxseg7e_v_i8m1x7	vsoxseg7ei8_v_i8m1x7
#define vsxseg7e_v_u8m1x7	vsoxseg7ei8_v_u8m1x7
#define vsxseg7e_v_i8m1x7_m	vsoxseg7ei8_v_i8m1x7_m
#define vsxseg7e_v_u8m1x7_m	vsoxseg7ei8_v_u8m1x7_m
#define vsxseg8e_v_i8m1x8	vsoxseg8ei8_v_i8m1x8
#define vsxseg8e_v_u8m1x8	vsoxseg8ei8_v_u8m1x8
#define vsxseg8e_v_i8m1x8_m	vsoxseg8ei8_v_i8m1x8_m
#define vsxseg8e_v_u8m1x8_m	vsoxseg8ei8_v_u8m1x8_m
#define vsxseg2e_v_i8m2x2	vsoxseg2ei8_v_i8m2x2
#define vsxseg2e_v_u8m2x2	vsoxseg2ei8_v_u8m2x2
#define vsxseg2e_v_i8m2x2_m	vsoxseg2ei8_v_i8m2x2_m
#define vsxseg2e_v_u8m2x2_m	vsoxseg2ei8_v_u8m2x2_m
#define vsxseg3e_v_i8m2x3	vsoxseg3ei8_v_i8m2x3
#define vsxseg3e_v_u8m2x3	vsoxseg3ei8_v_u8m2x3
#define vsxseg3e_v_i8m2x3_m	vsoxseg3ei8_v_i8m2x3_m
#define vsxseg3e_v_u8m2x3_m	vsoxseg3ei8_v_u8m2x3_m
#define vsxseg4e_v_i8m2x4	vsoxseg4ei8_v_i8m2x4
#define vsxseg4e_v_u8m2x4	vsoxseg4ei8_v_u8m2x4
#define vsxseg4e_v_i8m2x4_m	vsoxseg4ei8_v_i8m2x4_m
#define vsxseg4e_v_u8m2x4_m	vsoxseg4ei8_v_u8m2x4_m
#define vsxseg2e_v_i8m4x2	vsoxseg2ei8_v_i8m4x2
#define vsxseg2e_v_u8m4x2	vsoxseg2ei8_v_u8m4x2
#define vsxseg2e_v_i8m4x2_m	vsoxseg2ei8_v_i8m4x2_m
#define vsxseg2e_v_u8m4x2_m	vsoxseg2ei8_v_u8m4x2_m
#define vsxseg2e_v_i16m1x2	vsoxseg2ei16_v_i16m1x2
#define vsxseg2e_v_u16m1x2	vsoxseg2ei16_v_u16m1x2
#define vsxseg2e_v_i16m1x2_m	vsoxseg2ei16_v_i16m1x2_m
#define vsxseg2e_v_u16m1x2_m	vsoxseg2ei16_v_u16m1x2_m
#define vsxseg3e_v_i16m1x3	vsoxseg3ei16_v_i16m1x3
#define vsxseg3e_v_u16m1x3	vsoxseg3ei16_v_u16m1x3
#define vsxseg3e_v_i16m1x3_m	vsoxseg3ei16_v_i16m1x3_m
#define vsxseg3e_v_u16m1x3_m	vsoxseg3ei16_v_u16m1x3_m
#define vsxseg4e_v_i16m1x4	vsoxseg4ei16_v_i16m1x4
#define vsxseg4e_v_u16m1x4	vsoxseg4ei16_v_u16m1x4
#define vsxseg4e_v_i16m1x4_m	vsoxseg4ei16_v_i16m1x4_m
#define vsxseg4e_v_u16m1x4_m	vsoxseg4ei16_v_u16m1x4_m
#define vsxseg5e_v_i16m1x5	vsoxseg5ei16_v_i16m1x5
#define vsxseg5e_v_u16m1x5	vsoxseg5ei16_v_u16m1x5
#define vsxseg5e_v_i16m1x5_m	vsoxseg5ei16_v_i16m1x5_m
#define vsxseg5e_v_u16m1x5_m	vsoxseg5ei16_v_u16m1x5_m
#define vsxseg6e_v_i16m1x6	vsoxseg6ei16_v_i16m1x6
#define vsxseg6e_v_u16m1x6	vsoxseg6ei16_v_u16m1x6
#define vsxseg6e_v_i16m1x6_m	vsoxseg6ei16_v_i16m1x6_m
#define vsxseg6e_v_u16m1x6_m	vsoxseg6ei16_v_u16m1x6_m
#define vsxseg7e_v_i16m1x7	vsoxseg7ei16_v_i16m1x7
#define vsxseg7e_v_u16m1x7	vsoxseg7ei16_v_u16m1x7
#define vsxseg7e_v_i16m1x7_m	vsoxseg7ei16_v_i16m1x7_m
#define vsxseg7e_v_u16m1x7_m	vsoxseg7ei16_v_u16m1x7_m
#define vsxseg8e_v_i16m1x8	vsoxseg8ei16_v_i16m1x8
#define vsxseg8e_v_u16m1x8	vsoxseg8ei16_v_u16m1x8
#define vsxseg8e_v_i16m1x8_m	vsoxseg8ei16_v_i16m1x8_m
#define vsxseg8e_v_u16m1x8_m	vsoxseg8ei16_v_u16m1x8_m
#define vsxseg2e_v_i16m2x2	vsoxseg2ei16_v_i16m2x2
#define vsxseg2e_v_u16m2x2	vsoxseg2ei16_v_u16m2x2
#define vsxseg2e_v_i16m2x2_m	vsoxseg2ei16_v_i16m2x2_m
#define vsxseg2e_v_u16m2x2_m	vsoxseg2ei16_v_u16m2x2_m
#define vsxseg3e_v_i16m2x3	vsoxseg3ei16_v_i16m2x3
#define vsxseg3e_v_u16m2x3	vsoxseg3ei16_v_u16m2x3
#define vsxseg3e_v_i16m2x3_m	vsoxseg3ei16_v_i16m2x3_m
#define vsxseg3e_v_u16m2x3_m	vsoxseg3ei16_v_u16m2x3_m
#define vsxseg4e_v_i16m2x4	vsoxseg4ei16_v_i16m2x4
#define vsxseg4e_v_u16m2x4	vsoxseg4ei16_v_u16m2x4
#define vsxseg4e_v_i16m2x4_m	vsoxseg4ei16_v_i16m2x4_m
#define vsxseg4e_v_u16m2x4_m	vsoxseg4ei16_v_u16m2x4_m
#define vsxseg2e_v_i16m4x2	vsoxseg2ei16_v_i16m4x2
#define vsxseg2e_v_u16m4x2	vsoxseg2ei16_v_u16m4x2
#define vsxseg2e_v_i16m4x2_m	vsoxseg2ei16_v_i16m4x2_m
#define vsxseg2e_v_u16m4x2_m	vsoxseg2ei16_v_u16m4x2_m
#define vsxseg2e_v_i32m1x2	vsoxseg2ei32_v_i32m1x2
#define vsxseg2e_v_u32m1x2	vsoxseg2ei32_v_u32m1x2
#define vsxseg2e_v_i32m1x2_m	vsoxseg2ei32_v_i32m1x2_m
#define vsxseg2e_v_u32m1x2_m	vsoxseg2ei32_v_u32m1x2_m
#define vsxseg3e_v_i32m1x3	vsoxseg3ei32_v_i32m1x3
#define vsxseg3e_v_u32m1x3	vsoxseg3ei32_v_u32m1x3
#define vsxseg3e_v_i32m1x3_m	vsoxseg3ei32_v_i32m1x3_m
#define vsxseg3e_v_u32m1x3_m	vsoxseg3ei32_v_u32m1x3_m
#define vsxseg4e_v_i32m1x4	vsoxseg4ei32_v_i32m1x4
#define vsxseg4e_v_u32m1x4	vsoxseg4ei32_v_u32m1x4
#define vsxseg4e_v_i32m1x4_m	vsoxseg4ei32_v_i32m1x4_m
#define vsxseg4e_v_u32m1x4_m	vsoxseg4ei32_v_u32m1x4_m
#define vsxseg5e_v_i32m1x5	vsoxseg5ei32_v_i32m1x5
#define vsxseg5e_v_u32m1x5	vsoxseg5ei32_v_u32m1x5
#define vsxseg5e_v_i32m1x5_m	vsoxseg5ei32_v_i32m1x5_m
#define vsxseg5e_v_u32m1x5_m	vsoxseg5ei32_v_u32m1x5_m
#define vsxseg6e_v_i32m1x6	vsoxseg6ei32_v_i32m1x6
#define vsxseg6e_v_u32m1x6	vsoxseg6ei32_v_u32m1x6
#define vsxseg6e_v_i32m1x6_m	vsoxseg6ei32_v_i32m1x6_m
#define vsxseg6e_v_u32m1x6_m	vsoxseg6ei32_v_u32m1x6_m
#define vsxseg7e_v_i32m1x7	vsoxseg7ei32_v_i32m1x7
#define vsxseg7e_v_u32m1x7	vsoxseg7ei32_v_u32m1x7
#define vsxseg7e_v_i32m1x7_m	vsoxseg7ei32_v_i32m1x7_m
#define vsxseg7e_v_u32m1x7_m	vsoxseg7ei32_v_u32m1x7_m
#define vsxseg8e_v_i32m1x8	vsoxseg8ei32_v_i32m1x8
#define vsxseg8e_v_u32m1x8	vsoxseg8ei32_v_u32m1x8
#define vsxseg8e_v_i32m1x8_m	vsoxseg8ei32_v_i32m1x8_m
#define vsxseg8e_v_u32m1x8_m	vsoxseg8ei32_v_u32m1x8_m
#define vsxseg2e_v_i32m2x2	vsoxseg2ei32_v_i32m2x2
#define vsxseg2e_v_u32m2x2	vsoxseg2ei32_v_u32m2x2
#define vsxseg2e_v_i32m2x2_m	vsoxseg2ei32_v_i32m2x2_m
#define vsxseg2e_v_u32m2x2_m	vsoxseg2ei32_v_u32m2x2_m
#define vsxseg3e_v_i32m2x3	vsoxseg3ei32_v_i32m2x3
#define vsxseg3e_v_u32m2x3	vsoxseg3ei32_v_u32m2x3
#define vsxseg3e_v_i32m2x3_m	vsoxseg3ei32_v_i32m2x3_m
#define vsxseg3e_v_u32m2x3_m	vsoxseg3ei32_v_u32m2x3_m
#define vsxseg4e_v_i32m2x4	vsoxseg4ei32_v_i32m2x4
#define vsxseg4e_v_u32m2x4	vsoxseg4ei32_v_u32m2x4
#define vsxseg4e_v_i32m2x4_m	vsoxseg4ei32_v_i32m2x4_m
#define vsxseg4e_v_u32m2x4_m	vsoxseg4ei32_v_u32m2x4_m
#define vsxseg2e_v_i32m4x2	vsoxseg2ei32_v_i32m4x2
#define vsxseg2e_v_u32m4x2	vsoxseg2ei32_v_u32m4x2
#define vsxseg2e_v_i32m4x2_m	vsoxseg2ei32_v_i32m4x2_m
#define vsxseg2e_v_u32m4x2_m	vsoxseg2ei32_v_u32m4x2_m
#define vsxseg2e_v_i64m1x2	vsoxseg2ei64_v_i64m1x2
#define vsxseg2e_v_u64m1x2	vsoxseg2ei64_v_u64m1x2
#define vsxseg2e_v_i64m1x2_m	vsoxseg2ei64_v_i64m1x2_m
#define vsxseg2e_v_u64m1x2_m	vsoxseg2ei64_v_u64m1x2_m
#define vsxseg3e_v_i64m1x3	vsoxseg3ei64_v_i64m1x3
#define vsxseg3e_v_u64m1x3	vsoxseg3ei64_v_u64m1x3
#define vsxseg3e_v_i64m1x3_m	vsoxseg3ei64_v_i64m1x3_m
#define vsxseg3e_v_u64m1x3_m	vsoxseg3ei64_v_u64m1x3_m
#define vsxseg4e_v_i64m1x4	vsoxseg4ei64_v_i64m1x4
#define vsxseg4e_v_u64m1x4	vsoxseg4ei64_v_u64m1x4
#define vsxseg4e_v_i64m1x4_m	vsoxseg4ei64_v_i64m1x4_m
#define vsxseg4e_v_u64m1x4_m	vsoxseg4ei64_v_u64m1x4_m
#define vsxseg5e_v_i64m1x5	vsoxseg5ei64_v_i64m1x5
#define vsxseg5e_v_u64m1x5	vsoxseg5ei64_v_u64m1x5
#define vsxseg5e_v_i64m1x5_m	vsoxseg5ei64_v_i64m1x5_m
#define vsxseg5e_v_u64m1x5_m	vsoxseg5ei64_v_u64m1x5_m
#define vsxseg6e_v_i64m1x6	vsoxseg6ei64_v_i64m1x6
#define vsxseg6e_v_u64m1x6	vsoxseg6ei64_v_u64m1x6
#define vsxseg6e_v_i64m1x6_m	vsoxseg6ei64_v_i64m1x6_m
#define vsxseg6e_v_u64m1x6_m	vsoxseg6ei64_v_u64m1x6_m
#define vsxseg7e_v_i64m1x7	vsoxseg7ei64_v_i64m1x7
#define vsxseg7e_v_u64m1x7	vsoxseg7ei64_v_u64m1x7
#define vsxseg7e_v_i64m1x7_m	vsoxseg7ei64_v_i64m1x7_m
#define vsxseg7e_v_u64m1x7_m	vsoxseg7ei64_v_u64m1x7_m
#define vsxseg8e_v_i64m1x8	vsoxseg8ei64_v_i64m1x8
#define vsxseg8e_v_u64m1x8	vsoxseg8ei64_v_u64m1x8
#define vsxseg8e_v_i64m1x8_m	vsoxseg8ei64_v_i64m1x8_m
#define vsxseg8e_v_u64m1x8_m	vsoxseg8ei64_v_u64m1x8_m
#define vsxseg2e_v_i64m2x2	vsoxseg2ei64_v_i64m2x2
#define vsxseg2e_v_u64m2x2	vsoxseg2ei64_v_u64m2x2
#define vsxseg2e_v_i64m2x2_m	vsoxseg2ei64_v_i64m2x2_m
#define vsxseg2e_v_u64m2x2_m	vsoxseg2ei64_v_u64m2x2_m
#define vsxseg3e_v_i64m2x3	vsoxseg3ei64_v_i64m2x3
#define vsxseg3e_v_u64m2x3	vsoxseg3ei64_v_u64m2x3
#define vsxseg3e_v_i64m2x3_m	vsoxseg3ei64_v_i64m2x3_m
#define vsxseg3e_v_u64m2x3_m	vsoxseg3ei64_v_u64m2x3_m
#define vsxseg4e_v_i64m2x4	vsoxseg4ei64_v_i64m2x4
#define vsxseg4e_v_u64m2x4	vsoxseg4ei64_v_u64m2x4
#define vsxseg4e_v_i64m2x4_m	vsoxseg4ei64_v_i64m2x4_m
#define vsxseg4e_v_u64m2x4_m	vsoxseg4ei64_v_u64m2x4_m
#define vsxseg2e_v_i64m4x2	vsoxseg2ei64_v_i64m4x2
#define vsxseg2e_v_u64m4x2	vsoxseg2ei64_v_u64m4x2
#define vsxseg2e_v_i64m4x2_m	vsoxseg2ei64_v_i64m4x2_m
#define vsxseg2e_v_u64m4x2_m	vsoxseg2ei64_v_u64m4x2_m
#define vsxseg2e_v_f16m1x2	vsoxseg2ei16_v_f16m1x2
#define vsxseg2e_v_f16m1x2_m	vsoxseg2ei16_v_f16m1x2_m
#define vsxseg3e_v_f16m1x3	vsoxseg3ei16_v_f16m1x3
#define vsxseg3e_v_f16m1x3_m	vsoxseg3ei16_v_f16m1x3_m
#define vsxseg4e_v_f16m1x4	vsoxseg4ei16_v_f16m1x4
#define vsxseg4e_v_f16m1x4_m	vsoxseg4ei16_v_f16m1x4_m
#define vsxseg5e_v_f16m1x5	vsoxseg5ei16_v_f16m1x5
#define vsxseg5e_v_f16m1x5_m	vsoxseg5ei16_v_f16m1x5_m
#define vsxseg6e_v_f16m1x6	vsoxseg6ei16_v_f16m1x6
#define vsxseg6e_v_f16m1x6_m	vsoxseg6ei16_v_f16m1x6_m
#define vsxseg7e_v_f16m1x7	vsoxseg7ei16_v_f16m1x7
#define vsxseg7e_v_f16m1x7_m	vsoxseg7ei16_v_f16m1x7_m
#define vsxseg8e_v_f16m1x8	vsoxseg8ei16_v_f16m1x8
#define vsxseg8e_v_f16m1x8_m	vsoxseg8ei16_v_f16m1x8_m
#define vsxseg2e_v_f16m2x2	vsoxseg2ei16_v_f16m2x2
#define vsxseg2e_v_f16m2x2_m	vsoxseg2ei16_v_f16m2x2_m
#define vsxseg3e_v_f16m2x3	vsoxseg3ei16_v_f16m2x3
#define vsxseg3e_v_f16m2x3_m	vsoxseg3ei16_v_f16m2x3_m
#define vsxseg4e_v_f16m2x4	vsoxseg4ei16_v_f16m2x4
#define vsxseg4e_v_f16m2x4_m	vsoxseg4ei16_v_f16m2x4_m
#define vsxseg2e_v_f16m4x2	vsoxseg2ei16_v_f16m4x2
#define vsxseg2e_v_f16m4x2_m	vsoxseg2ei16_v_f16m4x2_m
#define vsxseg2e_v_f32m1x2	vsoxseg2ei32_v_f32m1x2
#define vsxseg2e_v_f32m1x2_m	vsoxseg2ei32_v_f32m1x2_m
#define vsxseg3e_v_f32m1x3	vsoxseg3ei32_v_f32m1x3
#define vsxseg3e_v_f32m1x3_m	vsoxseg3ei32_v_f32m1x3_m
#define vsxseg4e_v_f32m1x4	vsoxseg4ei32_v_f32m1x4
#define vsxseg4e_v_f32m1x4_m	vsoxseg4ei32_v_f32m1x4_m
#define vsxseg5e_v_f32m1x5	vsoxseg5ei32_v_f32m1x5
#define vsxseg5e_v_f32m1x5_m	vsoxseg5ei32_v_f32m1x5_m
#define vsxseg6e_v_f32m1x6	vsoxseg6ei32_v_f32m1x6
#define vsxseg6e_v_f32m1x6_m	vsoxseg6ei32_v_f32m1x6_m
#define vsxseg7e_v_f32m1x7	vsoxseg7ei32_v_f32m1x7
#define vsxseg7e_v_f32m1x7_m	vsoxseg7ei32_v_f32m1x7_m
#define vsxseg8e_v_f32m1x8	vsoxseg8ei32_v_f32m1x8
#define vsxseg8e_v_f32m1x8_m	vsoxseg8ei32_v_f32m1x8_m
#define vsxseg2e_v_f32m2x2	vsoxseg2ei32_v_f32m2x2
#define vsxseg2e_v_f32m2x2_m	vsoxseg2ei32_v_f32m2x2_m
#define vsxseg3e_v_f32m2x3	vsoxseg3ei32_v_f32m2x3
#define vsxseg3e_v_f32m2x3_m	vsoxseg3ei32_v_f32m2x3_m
#define vsxseg4e_v_f32m2x4	vsoxseg4ei32_v_f32m2x4
#define vsxseg4e_v_f32m2x4_m	vsoxseg4ei32_v_f32m2x4_m
#define vsxseg2e_v_f32m4x2	vsoxseg2ei32_v_f32m4x2
#define vsxseg2e_v_f32m4x2_m	vsoxseg2ei32_v_f32m4x2_m
#define vsxseg2e_v_f64m1x2	vsoxseg2ei64_v_f64m1x2
#define vsxseg2e_v_f64m1x2_m	vsoxseg2ei64_v_f64m1x2_m
#define vsxseg3e_v_f64m1x3	vsoxseg3ei64_v_f64m1x3
#define vsxseg3e_v_f64m1x3_m	vsoxseg3ei64_v_f64m1x3_m
#define vsxseg4e_v_f64m1x4	vsoxseg4ei64_v_f64m1x4
#define vsxseg4e_v_f64m1x4_m	vsoxseg4ei64_v_f64m1x4_m
#define vsxseg5e_v_f64m1x5	vsoxseg5ei64_v_f64m1x5
#define vsxseg5e_v_f64m1x5_m	vsoxseg5ei64_v_f64m1x5_m
#define vsxseg6e_v_f64m1x6	vsoxseg6ei64_v_f64m1x6
#define vsxseg6e_v_f64m1x6_m	vsoxseg6ei64_v_f64m1x6_m
#define vsxseg7e_v_f64m1x7	vsoxseg7ei64_v_f64m1x7
#define vsxseg7e_v_f64m1x7_m	vsoxseg7ei64_v_f64m1x7_m
#define vsxseg8e_v_f64m1x8	vsoxseg8ei64_v_f64m1x8
#define vsxseg8e_v_f64m1x8_m	vsoxseg8ei64_v_f64m1x8_m
#define vsxseg2e_v_f64m2x2	vsoxseg2ei64_v_f64m2x2
#define vsxseg2e_v_f64m2x2_m	vsoxseg2ei64_v_f64m2x2_m
#define vsxseg3e_v_f64m2x3	vsoxseg3ei64_v_f64m2x3
#define vsxseg3e_v_f64m2x3_m	vsoxseg3ei64_v_f64m2x3_m
#define vsxseg4e_v_f64m2x4	vsoxseg4ei64_v_f64m2x4
#define vsxseg4e_v_f64m2x4_m	vsoxseg4ei64_v_f64m2x4_m
#define vsxseg2e_v_f64m4x2	vsoxseg2ei64_v_f64m4x2
#define vsxseg2e_v_f64m4x2_m	vsoxseg2ei64_v_f64m4x2_m

/* Wrapper only.  */
#define vlseg2eff_v_i8m1x2	vlseg2e8ff_v_i8m1x2
#define vlseg2eff_v_u8m1x2	vlseg2e8ff_v_u8m1x2
#define vlseg2eff_v_i8m1x2_m	vlseg2e8ff_v_i8m1x2_m
#define vlseg2eff_v_u8m1x2_m	vlseg2e8ff_v_u8m1x2_m
#define vlseg3eff_v_i8m1x3	vlseg3e8ff_v_i8m1x3
#define vlseg3eff_v_u8m1x3	vlseg3e8ff_v_u8m1x3
#define vlseg3eff_v_i8m1x3_m	vlseg3e8ff_v_i8m1x3_m
#define vlseg3eff_v_u8m1x3_m	vlseg3e8ff_v_u8m1x3_m
#define vlseg4eff_v_i8m1x4	vlseg4e8ff_v_i8m1x4
#define vlseg4eff_v_u8m1x4	vlseg4e8ff_v_u8m1x4
#define vlseg4eff_v_i8m1x4_m	vlseg4e8ff_v_i8m1x4_m
#define vlseg4eff_v_u8m1x4_m	vlseg4e8ff_v_u8m1x4_m
#define vlseg5eff_v_i8m1x5	vlseg5e8ff_v_i8m1x5
#define vlseg5eff_v_u8m1x5	vlseg5e8ff_v_u8m1x5
#define vlseg5eff_v_i8m1x5_m	vlseg5e8ff_v_i8m1x5_m
#define vlseg5eff_v_u8m1x5_m	vlseg5e8ff_v_u8m1x5_m
#define vlseg6eff_v_i8m1x6	vlseg6e8ff_v_i8m1x6
#define vlseg6eff_v_u8m1x6	vlseg6e8ff_v_u8m1x6
#define vlseg6eff_v_i8m1x6_m	vlseg6e8ff_v_i8m1x6_m
#define vlseg6eff_v_u8m1x6_m	vlseg6e8ff_v_u8m1x6_m
#define vlseg7eff_v_i8m1x7	vlseg7e8ff_v_i8m1x7
#define vlseg7eff_v_u8m1x7	vlseg7e8ff_v_u8m1x7
#define vlseg7eff_v_i8m1x7_m	vlseg7e8ff_v_i8m1x7_m
#define vlseg7eff_v_u8m1x7_m	vlseg7e8ff_v_u8m1x7_m
#define vlseg8eff_v_i8m1x8	vlseg8e8ff_v_i8m1x8
#define vlseg8eff_v_u8m1x8	vlseg8e8ff_v_u8m1x8
#define vlseg8eff_v_i8m1x8_m	vlseg8e8ff_v_i8m1x8_m
#define vlseg8eff_v_u8m1x8_m	vlseg8e8ff_v_u8m1x8_m
#define vlseg2eff_v_i8m2x2	vlseg2e8ff_v_i8m2x2
#define vlseg2eff_v_u8m2x2	vlseg2e8ff_v_u8m2x2
#define vlseg2eff_v_i8m2x2_m	vlseg2e8ff_v_i8m2x2_m
#define vlseg2eff_v_u8m2x2_m	vlseg2e8ff_v_u8m2x2_m
#define vlseg3eff_v_i8m2x3	vlseg3e8ff_v_i8m2x3
#define vlseg3eff_v_u8m2x3	vlseg3e8ff_v_u8m2x3
#define vlseg3eff_v_i8m2x3_m	vlseg3e8ff_v_i8m2x3_m
#define vlseg3eff_v_u8m2x3_m	vlseg3e8ff_v_u8m2x3_m
#define vlseg4eff_v_i8m2x4	vlseg4e8ff_v_i8m2x4
#define vlseg4eff_v_u8m2x4	vlseg4e8ff_v_u8m2x4
#define vlseg4eff_v_i8m2x4_m	vlseg4e8ff_v_i8m2x4_m
#define vlseg4eff_v_u8m2x4_m	vlseg4e8ff_v_u8m2x4_m
#define vlseg2eff_v_i8m4x2	vlseg2e8ff_v_i8m4x2
#define vlseg2eff_v_u8m4x2	vlseg2e8ff_v_u8m4x2
#define vlseg2eff_v_i8m4x2_m	vlseg2e8ff_v_i8m4x2_m
#define vlseg2eff_v_u8m4x2_m	vlseg2e8ff_v_u8m4x2_m
#define vlseg2eff_v_i16m1x2	vlseg2e16ff_v_i16m1x2
#define vlseg2eff_v_u16m1x2	vlseg2e16ff_v_u16m1x2
#define vlseg2eff_v_i16m1x2_m	vlseg2e16ff_v_i16m1x2_m
#define vlseg2eff_v_u16m1x2_m	vlseg2e16ff_v_u16m1x2_m
#define vlseg3eff_v_i16m1x3	vlseg3e16ff_v_i16m1x3
#define vlseg3eff_v_u16m1x3	vlseg3e16ff_v_u16m1x3
#define vlseg3eff_v_i16m1x3_m	vlseg3e16ff_v_i16m1x3_m
#define vlseg3eff_v_u16m1x3_m	vlseg3e16ff_v_u16m1x3_m
#define vlseg4eff_v_i16m1x4	vlseg4e16ff_v_i16m1x4
#define vlseg4eff_v_u16m1x4	vlseg4e16ff_v_u16m1x4
#define vlseg4eff_v_i16m1x4_m	vlseg4e16ff_v_i16m1x4_m
#define vlseg4eff_v_u16m1x4_m	vlseg4e16ff_v_u16m1x4_m
#define vlseg5eff_v_i16m1x5	vlseg5e16ff_v_i16m1x5
#define vlseg5eff_v_u16m1x5	vlseg5e16ff_v_u16m1x5
#define vlseg5eff_v_i16m1x5_m	vlseg5e16ff_v_i16m1x5_m
#define vlseg5eff_v_u16m1x5_m	vlseg5e16ff_v_u16m1x5_m
#define vlseg6eff_v_i16m1x6	vlseg6e16ff_v_i16m1x6
#define vlseg6eff_v_u16m1x6	vlseg6e16ff_v_u16m1x6
#define vlseg6eff_v_i16m1x6_m	vlseg6e16ff_v_i16m1x6_m
#define vlseg6eff_v_u16m1x6_m	vlseg6e16ff_v_u16m1x6_m
#define vlseg7eff_v_i16m1x7	vlseg7e16ff_v_i16m1x7
#define vlseg7eff_v_u16m1x7	vlseg7e16ff_v_u16m1x7
#define vlseg7eff_v_i16m1x7_m	vlseg7e16ff_v_i16m1x7_m
#define vlseg7eff_v_u16m1x7_m	vlseg7e16ff_v_u16m1x7_m
#define vlseg8eff_v_i16m1x8	vlseg8e16ff_v_i16m1x8
#define vlseg8eff_v_u16m1x8	vlseg8e16ff_v_u16m1x8
#define vlseg8eff_v_i16m1x8_m	vlseg8e16ff_v_i16m1x8_m
#define vlseg8eff_v_u16m1x8_m	vlseg8e16ff_v_u16m1x8_m
#define vlseg2eff_v_i16m2x2	vlseg2e16ff_v_i16m2x2
#define vlseg2eff_v_u16m2x2	vlseg2e16ff_v_u16m2x2
#define vlseg2eff_v_i16m2x2_m	vlseg2e16ff_v_i16m2x2_m
#define vlseg2eff_v_u16m2x2_m	vlseg2e16ff_v_u16m2x2_m
#define vlseg3eff_v_i16m2x3	vlseg3e16ff_v_i16m2x3
#define vlseg3eff_v_u16m2x3	vlseg3e16ff_v_u16m2x3
#define vlseg3eff_v_i16m2x3_m	vlseg3e16ff_v_i16m2x3_m
#define vlseg3eff_v_u16m2x3_m	vlseg3e16ff_v_u16m2x3_m
#define vlseg4eff_v_i16m2x4	vlseg4e16ff_v_i16m2x4
#define vlseg4eff_v_u16m2x4	vlseg4e16ff_v_u16m2x4
#define vlseg4eff_v_i16m2x4_m	vlseg4e16ff_v_i16m2x4_m
#define vlseg4eff_v_u16m2x4_m	vlseg4e16ff_v_u16m2x4_m
#define vlseg2eff_v_i16m4x2	vlseg2e16ff_v_i16m4x2
#define vlseg2eff_v_u16m4x2	vlseg2e16ff_v_u16m4x2
#define vlseg2eff_v_i16m4x2_m	vlseg2e16ff_v_i16m4x2_m
#define vlseg2eff_v_u16m4x2_m	vlseg2e16ff_v_u16m4x2_m
#define vlseg2eff_v_i32m1x2	vlseg2e32ff_v_i32m1x2
#define vlseg2eff_v_u32m1x2	vlseg2e32ff_v_u32m1x2
#define vlseg2eff_v_i32m1x2_m	vlseg2e32ff_v_i32m1x2_m
#define vlseg2eff_v_u32m1x2_m	vlseg2e32ff_v_u32m1x2_m
#define vlseg3eff_v_i32m1x3	vlseg3e32ff_v_i32m1x3
#define vlseg3eff_v_u32m1x3	vlseg3e32ff_v_u32m1x3
#define vlseg3eff_v_i32m1x3_m	vlseg3e32ff_v_i32m1x3_m
#define vlseg3eff_v_u32m1x3_m	vlseg3e32ff_v_u32m1x3_m
#define vlseg4eff_v_i32m1x4	vlseg4e32ff_v_i32m1x4
#define vlseg4eff_v_u32m1x4	vlseg4e32ff_v_u32m1x4
#define vlseg4eff_v_i32m1x4_m	vlseg4e32ff_v_i32m1x4_m
#define vlseg4eff_v_u32m1x4_m	vlseg4e32ff_v_u32m1x4_m
#define vlseg5eff_v_i32m1x5	vlseg5e32ff_v_i32m1x5
#define vlseg5eff_v_u32m1x5	vlseg5e32ff_v_u32m1x5
#define vlseg5eff_v_i32m1x5_m	vlseg5e32ff_v_i32m1x5_m
#define vlseg5eff_v_u32m1x5_m	vlseg5e32ff_v_u32m1x5_m
#define vlseg6eff_v_i32m1x6	vlseg6e32ff_v_i32m1x6
#define vlseg6eff_v_u32m1x6	vlseg6e32ff_v_u32m1x6
#define vlseg6eff_v_i32m1x6_m	vlseg6e32ff_v_i32m1x6_m
#define vlseg6eff_v_u32m1x6_m	vlseg6e32ff_v_u32m1x6_m
#define vlseg7eff_v_i32m1x7	vlseg7e32ff_v_i32m1x7
#define vlseg7eff_v_u32m1x7	vlseg7e32ff_v_u32m1x7
#define vlseg7eff_v_i32m1x7_m	vlseg7e32ff_v_i32m1x7_m
#define vlseg7eff_v_u32m1x7_m	vlseg7e32ff_v_u32m1x7_m
#define vlseg8eff_v_i32m1x8	vlseg8e32ff_v_i32m1x8
#define vlseg8eff_v_u32m1x8	vlseg8e32ff_v_u32m1x8
#define vlseg8eff_v_i32m1x8_m	vlseg8e32ff_v_i32m1x8_m
#define vlseg8eff_v_u32m1x8_m	vlseg8e32ff_v_u32m1x8_m
#define vlseg2eff_v_i32m2x2	vlseg2e32ff_v_i32m2x2
#define vlseg2eff_v_u32m2x2	vlseg2e32ff_v_u32m2x2
#define vlseg2eff_v_i32m2x2_m	vlseg2e32ff_v_i32m2x2_m
#define vlseg2eff_v_u32m2x2_m	vlseg2e32ff_v_u32m2x2_m
#define vlseg3eff_v_i32m2x3	vlseg3e32ff_v_i32m2x3
#define vlseg3eff_v_u32m2x3	vlseg3e32ff_v_u32m2x3
#define vlseg3eff_v_i32m2x3_m	vlseg3e32ff_v_i32m2x3_m
#define vlseg3eff_v_u32m2x3_m	vlseg3e32ff_v_u32m2x3_m
#define vlseg4eff_v_i32m2x4	vlseg4e32ff_v_i32m2x4
#define vlseg4eff_v_u32m2x4	vlseg4e32ff_v_u32m2x4
#define vlseg4eff_v_i32m2x4_m	vlseg4e32ff_v_i32m2x4_m
#define vlseg4eff_v_u32m2x4_m	vlseg4e32ff_v_u32m2x4_m
#define vlseg2eff_v_i32m4x2	vlseg2e32ff_v_i32m4x2
#define vlseg2eff_v_u32m4x2	vlseg2e32ff_v_u32m4x2
#define vlseg2eff_v_i32m4x2_m	vlseg2e32ff_v_i32m4x2_m
#define vlseg2eff_v_u32m4x2_m	vlseg2e32ff_v_u32m4x2_m
#define vlseg2eff_v_i64m1x2	vlseg2e64ff_v_i64m1x2
#define vlseg2eff_v_u64m1x2	vlseg2e64ff_v_u64m1x2
#define vlseg2eff_v_i64m1x2_m	vlseg2e64ff_v_i64m1x2_m
#define vlseg2eff_v_u64m1x2_m	vlseg2e64ff_v_u64m1x2_m
#define vlseg3eff_v_i64m1x3	vlseg3e64ff_v_i64m1x3
#define vlseg3eff_v_u64m1x3	vlseg3e64ff_v_u64m1x3
#define vlseg3eff_v_i64m1x3_m	vlseg3e64ff_v_i64m1x3_m
#define vlseg3eff_v_u64m1x3_m	vlseg3e64ff_v_u64m1x3_m
#define vlseg4eff_v_i64m1x4	vlseg4e64ff_v_i64m1x4
#define vlseg4eff_v_u64m1x4	vlseg4e64ff_v_u64m1x4
#define vlseg4eff_v_i64m1x4_m	vlseg4e64ff_v_i64m1x4_m
#define vlseg4eff_v_u64m1x4_m	vlseg4e64ff_v_u64m1x4_m
#define vlseg5eff_v_i64m1x5	vlseg5e64ff_v_i64m1x5
#define vlseg5eff_v_u64m1x5	vlseg5e64ff_v_u64m1x5
#define vlseg5eff_v_i64m1x5_m	vlseg5e64ff_v_i64m1x5_m
#define vlseg5eff_v_u64m1x5_m	vlseg5e64ff_v_u64m1x5_m
#define vlseg6eff_v_i64m1x6	vlseg6e64ff_v_i64m1x6
#define vlseg6eff_v_u64m1x6	vlseg6e64ff_v_u64m1x6
#define vlseg6eff_v_i64m1x6_m	vlseg6e64ff_v_i64m1x6_m
#define vlseg6eff_v_u64m1x6_m	vlseg6e64ff_v_u64m1x6_m
#define vlseg7eff_v_i64m1x7	vlseg7e64ff_v_i64m1x7
#define vlseg7eff_v_u64m1x7	vlseg7e64ff_v_u64m1x7
#define vlseg7eff_v_i64m1x7_m	vlseg7e64ff_v_i64m1x7_m
#define vlseg7eff_v_u64m1x7_m	vlseg7e64ff_v_u64m1x7_m
#define vlseg8eff_v_i64m1x8	vlseg8e64ff_v_i64m1x8
#define vlseg8eff_v_u64m1x8	vlseg8e64ff_v_u64m1x8
#define vlseg8eff_v_i64m1x8_m	vlseg8e64ff_v_i64m1x8_m
#define vlseg8eff_v_u64m1x8_m	vlseg8e64ff_v_u64m1x8_m
#define vlseg2eff_v_i64m2x2	vlseg2e64ff_v_i64m2x2
#define vlseg2eff_v_u64m2x2	vlseg2e64ff_v_u64m2x2
#define vlseg2eff_v_i64m2x2_m	vlseg2e64ff_v_i64m2x2_m
#define vlseg2eff_v_u64m2x2_m	vlseg2e64ff_v_u64m2x2_m
#define vlseg3eff_v_i64m2x3	vlseg3e64ff_v_i64m2x3
#define vlseg3eff_v_u64m2x3	vlseg3e64ff_v_u64m2x3
#define vlseg3eff_v_i64m2x3_m	vlseg3e64ff_v_i64m2x3_m
#define vlseg3eff_v_u64m2x3_m	vlseg3e64ff_v_u64m2x3_m
#define vlseg4eff_v_i64m2x4	vlseg4e64ff_v_i64m2x4
#define vlseg4eff_v_u64m2x4	vlseg4e64ff_v_u64m2x4
#define vlseg4eff_v_i64m2x4_m	vlseg4e64ff_v_i64m2x4_m
#define vlseg4eff_v_u64m2x4_m	vlseg4e64ff_v_u64m2x4_m
#define vlseg2eff_v_i64m4x2	vlseg2e64ff_v_i64m4x2
#define vlseg2eff_v_u64m4x2	vlseg2e64ff_v_u64m4x2
#define vlseg2eff_v_i64m4x2_m	vlseg2e64ff_v_i64m4x2_m
#define vlseg2eff_v_u64m4x2_m	vlseg2e64ff_v_u64m4x2_m
#define vlseg2eff_v_f16m1x2	vlseg2e16ff_v_f16m1x2
#define vlseg2eff_v_f16m1x2_m	vlseg2e16ff_v_f16m1x2_m
#define vlseg3eff_v_f16m1x3	vlseg3e16ff_v_f16m1x3
#define vlseg3eff_v_f16m1x3_m	vlseg3e16ff_v_f16m1x3_m
#define vlseg4eff_v_f16m1x4	vlseg4e16ff_v_f16m1x4
#define vlseg4eff_v_f16m1x4_m	vlseg4e16ff_v_f16m1x4_m
#define vlseg5eff_v_f16m1x5	vlseg5e16ff_v_f16m1x5
#define vlseg5eff_v_f16m1x5_m	vlseg5e16ff_v_f16m1x5_m
#define vlseg6eff_v_f16m1x6	vlseg6e16ff_v_f16m1x6
#define vlseg6eff_v_f16m1x6_m	vlseg6e16ff_v_f16m1x6_m
#define vlseg7eff_v_f16m1x7	vlseg7e16ff_v_f16m1x7
#define vlseg7eff_v_f16m1x7_m	vlseg7e16ff_v_f16m1x7_m
#define vlseg8eff_v_f16m1x8	vlseg8e16ff_v_f16m1x8
#define vlseg8eff_v_f16m1x8_m	vlseg8e16ff_v_f16m1x8_m
#define vlseg2eff_v_f16m2x2	vlseg2e16ff_v_f16m2x2
#define vlseg2eff_v_f16m2x2_m	vlseg2e16ff_v_f16m2x2_m
#define vlseg3eff_v_f16m2x3	vlseg3e16ff_v_f16m2x3
#define vlseg3eff_v_f16m2x3_m	vlseg3e16ff_v_f16m2x3_m
#define vlseg4eff_v_f16m2x4	vlseg4e16ff_v_f16m2x4
#define vlseg4eff_v_f16m2x4_m	vlseg4e16ff_v_f16m2x4_m
#define vlseg2eff_v_f16m4x2	vlseg2e16ff_v_f16m4x2
#define vlseg2eff_v_f16m4x2_m	vlseg2e16ff_v_f16m4x2_m
#define vlseg2eff_v_f32m1x2	vlseg2e32ff_v_f32m1x2
#define vlseg2eff_v_f32m1x2_m	vlseg2e32ff_v_f32m1x2_m
#define vlseg3eff_v_f32m1x3	vlseg3e32ff_v_f32m1x3
#define vlseg3eff_v_f32m1x3_m	vlseg3e32ff_v_f32m1x3_m
#define vlseg4eff_v_f32m1x4	vlseg4e32ff_v_f32m1x4
#define vlseg4eff_v_f32m1x4_m	vlseg4e32ff_v_f32m1x4_m
#define vlseg5eff_v_f32m1x5	vlseg5e32ff_v_f32m1x5
#define vlseg5eff_v_f32m1x5_m	vlseg5e32ff_v_f32m1x5_m
#define vlseg6eff_v_f32m1x6	vlseg6e32ff_v_f32m1x6
#define vlseg6eff_v_f32m1x6_m	vlseg6e32ff_v_f32m1x6_m
#define vlseg7eff_v_f32m1x7	vlseg7e32ff_v_f32m1x7
#define vlseg7eff_v_f32m1x7_m	vlseg7e32ff_v_f32m1x7_m
#define vlseg8eff_v_f32m1x8	vlseg8e32ff_v_f32m1x8
#define vlseg8eff_v_f32m1x8_m	vlseg8e32ff_v_f32m1x8_m
#define vlseg2eff_v_f32m2x2	vlseg2e32ff_v_f32m2x2
#define vlseg2eff_v_f32m2x2_m	vlseg2e32ff_v_f32m2x2_m
#define vlseg3eff_v_f32m2x3	vlseg3e32ff_v_f32m2x3
#define vlseg3eff_v_f32m2x3_m	vlseg3e32ff_v_f32m2x3_m
#define vlseg4eff_v_f32m2x4	vlseg4e32ff_v_f32m2x4
#define vlseg4eff_v_f32m2x4_m	vlseg4e32ff_v_f32m2x4_m
#define vlseg2eff_v_f32m4x2	vlseg2e32ff_v_f32m4x2
#define vlseg2eff_v_f32m4x2_m	vlseg2e32ff_v_f32m4x2_m
#define vlseg2eff_v_f64m1x2	vlseg2e64ff_v_f64m1x2
#define vlseg2eff_v_f64m1x2_m	vlseg2e64ff_v_f64m1x2_m
#define vlseg3eff_v_f64m1x3	vlseg3e64ff_v_f64m1x3
#define vlseg3eff_v_f64m1x3_m	vlseg3e64ff_v_f64m1x3_m
#define vlseg4eff_v_f64m1x4	vlseg4e64ff_v_f64m1x4
#define vlseg4eff_v_f64m1x4_m	vlseg4e64ff_v_f64m1x4_m
#define vlseg5eff_v_f64m1x5	vlseg5e64ff_v_f64m1x5
#define vlseg5eff_v_f64m1x5_m	vlseg5e64ff_v_f64m1x5_m
#define vlseg6eff_v_f64m1x6	vlseg6e64ff_v_f64m1x6
#define vlseg6eff_v_f64m1x6_m	vlseg6e64ff_v_f64m1x6_m
#define vlseg7eff_v_f64m1x7	vlseg7e64ff_v_f64m1x7
#define vlseg7eff_v_f64m1x7_m	vlseg7e64ff_v_f64m1x7_m
#define vlseg8eff_v_f64m1x8	vlseg8e64ff_v_f64m1x8
#define vlseg8eff_v_f64m1x8_m	vlseg8e64ff_v_f64m1x8_m
#define vlseg2eff_v_f64m2x2	vlseg2e64ff_v_f64m2x2
#define vlseg2eff_v_f64m2x2_m	vlseg2e64ff_v_f64m2x2_m
#define vlseg3eff_v_f64m2x3	vlseg3e64ff_v_f64m2x3
#define vlseg3eff_v_f64m2x3_m	vlseg3e64ff_v_f64m2x3_m
#define vlseg4eff_v_f64m2x4	vlseg4e64ff_v_f64m2x4
#define vlseg4eff_v_f64m2x4_m	vlseg4e64ff_v_f64m2x4_m
#define vlseg2eff_v_f64m4x2	vlseg2e64ff_v_f64m4x2
#define vlseg2eff_v_f64m4x2_m	vlseg2e64ff_v_f64m4x2_m

/* Wrapper only.  */
#define vfncvt_x_f_v_i8m1	vfncvt_x_f_w_i8m1
#define vfncvt_x_f_v_i8m1_m	vfncvt_x_f_w_i8m1_m
#define vfncvt_x_f_v_i8m2	vfncvt_x_f_w_i8m2
#define vfncvt_x_f_v_i8m2_m	vfncvt_x_f_w_i8m2_m
#define vfncvt_x_f_v_i8m4	vfncvt_x_f_w_i8m4
#define vfncvt_x_f_v_i8m4_m	vfncvt_x_f_w_i8m4_m
#define vfncvt_x_f_v_i16m1	vfncvt_x_f_w_i16m1
#define vfncvt_x_f_v_i16m1_m	vfncvt_x_f_w_i16m1_m
#define vfncvt_x_f_v_i16m2	vfncvt_x_f_w_i16m2
#define vfncvt_x_f_v_i16m2_m	vfncvt_x_f_w_i16m2_m
#define vfncvt_x_f_v_i16m4	vfncvt_x_f_w_i16m4
#define vfncvt_x_f_v_i16m4_m	vfncvt_x_f_w_i16m4_m
#define vfncvt_x_f_v_i32m1	vfncvt_x_f_w_i32m1
#define vfncvt_x_f_v_i32m1_m	vfncvt_x_f_w_i32m1_m
#define vfncvt_x_f_v_i32m2	vfncvt_x_f_w_i32m2
#define vfncvt_x_f_v_i32m2_m	vfncvt_x_f_w_i32m2_m
#define vfncvt_x_f_v_i32m4	vfncvt_x_f_w_i32m4
#define vfncvt_x_f_v_i32m4_m	vfncvt_x_f_w_i32m4_m

/* Wrapper only.  */
#define vfncvt_xu_f_v_u8m1	vfncvt_xu_f_w_u8m1
#define vfncvt_xu_f_v_u8m1_m	vfncvt_xu_f_w_u8m1_m
#define vfncvt_xu_f_v_u8m2	vfncvt_xu_f_w_u8m2
#define vfncvt_xu_f_v_u8m2_m	vfncvt_xu_f_w_u8m2_m
#define vfncvt_xu_f_v_u8m4	vfncvt_xu_f_w_u8m4
#define vfncvt_xu_f_v_u8m4_m	vfncvt_xu_f_w_u8m4_m
#define vfncvt_xu_f_v_u16m1	vfncvt_xu_f_w_u16m1
#define vfncvt_xu_f_v_u16m1_m	vfncvt_xu_f_w_u16m1_m
#define vfncvt_xu_f_v_u16m2	vfncvt_xu_f_w_u16m2
#define vfncvt_xu_f_v_u16m2_m	vfncvt_xu_f_w_u16m2_m
#define vfncvt_xu_f_v_u16m4	vfncvt_xu_f_w_u16m4
#define vfncvt_xu_f_v_u16m4_m	vfncvt_xu_f_w_u16m4_m
#define vfncvt_xu_f_v_u32m1	vfncvt_xu_f_w_u32m1
#define vfncvt_xu_f_v_u32m1_m	vfncvt_xu_f_w_u32m1_m
#define vfncvt_xu_f_v_u32m2	vfncvt_xu_f_w_u32m2
#define vfncvt_xu_f_v_u32m2_m	vfncvt_xu_f_w_u32m2_m
#define vfncvt_xu_f_v_u32m4	vfncvt_xu_f_w_u32m4
#define vfncvt_xu_f_v_u32m4_m	vfncvt_xu_f_w_u32m4_m

/* Wrapper only.  */
#define vnsrl_vv_u8m1	vnsrl_wv_u8m1
#define vnsrl_vv_u8m1_m	vnsrl_wv_u8m1_m
#define vnsrl_vv_u8m2	vnsrl_wv_u8m2
#define vnsrl_vv_u8m2_m	vnsrl_wv_u8m2_m
#define vnsrl_vv_u8m4	vnsrl_wv_u8m4
#define vnsrl_vv_u8m4_m	vnsrl_wv_u8m4_m
#define vnsrl_vv_u16m1	vnsrl_wv_u16m1
#define vnsrl_vv_u16m1_m	vnsrl_wv_u16m1_m
#define vnsrl_vv_u16m2	vnsrl_wv_u16m2
#define vnsrl_vv_u16m2_m	vnsrl_wv_u16m2_m
#define vnsrl_vv_u16m4	vnsrl_wv_u16m4
#define vnsrl_vv_u16m4_m	vnsrl_wv_u16m4_m
#define vnsrl_vv_u32m1	vnsrl_wv_u32m1
#define vnsrl_vv_u32m1_m	vnsrl_wv_u32m1_m
#define vnsrl_vv_u32m2	vnsrl_wv_u32m2
#define vnsrl_vv_u32m2_m	vnsrl_wv_u32m2_m
#define vnsrl_vv_u32m4	vnsrl_wv_u32m4
#define vnsrl_vv_u32m4_m	vnsrl_wv_u32m4_m

/* Wrapper only.  */
#define vnsrl_vx_u8m1	vnsrl_wx_u8m1
#define vnsrl_vx_u8m1_m	vnsrl_wx_u8m1_m
#define vnsrl_vx_u8m2	vnsrl_wx_u8m2
#define vnsrl_vx_u8m2_m	vnsrl_wx_u8m2_m
#define vnsrl_vx_u8m4	vnsrl_wx_u8m4
#define vnsrl_vx_u8m4_m	vnsrl_wx_u8m4_m
#define vnsrl_vx_u16m1	vnsrl_wx_u16m1
#define vnsrl_vx_u16m1_m	vnsrl_wx_u16m1_m
#define vnsrl_vx_u16m2	vnsrl_wx_u16m2
#define vnsrl_vx_u16m2_m	vnsrl_wx_u16m2_m
#define vnsrl_vx_u16m4	vnsrl_wx_u16m4
#define vnsrl_vx_u16m4_m	vnsrl_wx_u16m4_m
#define vnsrl_vx_u32m1	vnsrl_wx_u32m1
#define vnsrl_vx_u32m1_m	vnsrl_wx_u32m1_m
#define vnsrl_vx_u32m2	vnsrl_wx_u32m2
#define vnsrl_vx_u32m2_m	vnsrl_wx_u32m2_m
#define vnsrl_vx_u32m4	vnsrl_wx_u32m4
#define vnsrl_vx_u32m4_m	vnsrl_wx_u32m4_m

/* Wrapper only.  */
#define vnsra_vv_i8m1	vnsra_wv_i8m1
#define vnsra_vv_i8m1_m	vnsra_wv_i8m1_m
#define vnsra_vv_i8m2	vnsra_wv_i8m2
#define vnsra_vv_i8m2_m	vnsra_wv_i8m2_m
#define vnsra_vv_i8m4	vnsra_wv_i8m4
#define vnsra_vv_i8m4_m	vnsra_wv_i8m4_m
#define vnsra_vv_i16m1	vnsra_wv_i16m1
#define vnsra_vv_i16m1_m	vnsra_wv_i16m1_m
#define vnsra_vv_i16m2	vnsra_wv_i16m2
#define vnsra_vv_i16m2_m	vnsra_wv_i16m2_m
#define vnsra_vv_i16m4	vnsra_wv_i16m4
#define vnsra_vv_i16m4_m	vnsra_wv_i16m4_m
#define vnsra_vv_i32m1	vnsra_wv_i32m1
#define vnsra_vv_i32m1_m	vnsra_wv_i32m1_m
#define vnsra_vv_i32m2	vnsra_wv_i32m2
#define vnsra_vv_i32m2_m	vnsra_wv_i32m2_m
#define vnsra_vv_i32m4	vnsra_wv_i32m4
#define vnsra_vv_i32m4_m	vnsra_wv_i32m4_m

/* Wrapper only.  */
#define vnsra_vx_i8m1	vnsra_wx_i8m1
#define vnsra_vx_i8m1_m	vnsra_wx_i8m1_m
#define vnsra_vx_i8m2	vnsra_wx_i8m2
#define vnsra_vx_i8m2_m	vnsra_wx_i8m2_m
#define vnsra_vx_i8m4	vnsra_wx_i8m4
#define vnsra_vx_i8m4_m	vnsra_wx_i8m4_m
#define vnsra_vx_i16m1	vnsra_wx_i16m1
#define vnsra_vx_i16m1_m	vnsra_wx_i16m1_m
#define vnsra_vx_i16m2	vnsra_wx_i16m2
#define vnsra_vx_i16m2_m	vnsra_wx_i16m2_m
#define vnsra_vx_i16m4	vnsra_wx_i16m4
#define vnsra_vx_i16m4_m	vnsra_wx_i16m4_m
#define vnsra_vx_i32m1	vnsra_wx_i32m1
#define vnsra_vx_i32m1_m	vnsra_wx_i32m1_m
#define vnsra_vx_i32m2	vnsra_wx_i32m2
#define vnsra_vx_i32m2_m	vnsra_wx_i32m2_m
#define vnsra_vx_i32m4	vnsra_wx_i32m4
#define vnsra_vx_i32m4_m	vnsra_wx_i32m4_m

/* Wrapper only.  */
#define vnclipu_vv_u8m1	vnclipu_wv_u8m1
#define vnclipu_vv_u8m1_m	vnclipu_wv_u8m1_m
#define vnclipu_vv_u8m2	vnclipu_wv_u8m2
#define vnclipu_vv_u8m2_m	vnclipu_wv_u8m2_m
#define vnclipu_vv_u8m4	vnclipu_wv_u8m4
#define vnclipu_vv_u8m4_m	vnclipu_wv_u8m4_m
#define vnclipu_vv_u16m1	vnclipu_wv_u16m1
#define vnclipu_vv_u16m1_m	vnclipu_wv_u16m1_m
#define vnclipu_vv_u16m2	vnclipu_wv_u16m2
#define vnclipu_vv_u16m2_m	vnclipu_wv_u16m2_m
#define vnclipu_vv_u16m4	vnclipu_wv_u16m4
#define vnclipu_vv_u16m4_m	vnclipu_wv_u16m4_m
#define vnclipu_vv_u32m1	vnclipu_wv_u32m1
#define vnclipu_vv_u32m1_m	vnclipu_wv_u32m1_m
#define vnclipu_vv_u32m2	vnclipu_wv_u32m2
#define vnclipu_vv_u32m2_m	vnclipu_wv_u32m2_m
#define vnclipu_vv_u32m4	vnclipu_wv_u32m4
#define vnclipu_vv_u32m4_m	vnclipu_wv_u32m4_m

/* Wrapper only.  */
#define vnclipu_vx_u8m1	vnclipu_wx_u8m1
#define vnclipu_vx_u8m1_m	vnclipu_wx_u8m1_m
#define vnclipu_vx_u8m2	vnclipu_wx_u8m2
#define vnclipu_vx_u8m2_m	vnclipu_wx_u8m2_m
#define vnclipu_vx_u8m4	vnclipu_wx_u8m4
#define vnclipu_vx_u8m4_m	vnclipu_wx_u8m4_m
#define vnclipu_vx_u16m1	vnclipu_wx_u16m1
#define vnclipu_vx_u16m1_m	vnclipu_wx_u16m1_m
#define vnclipu_vx_u16m2	vnclipu_wx_u16m2
#define vnclipu_vx_u16m2_m	vnclipu_wx_u16m2_m
#define vnclipu_vx_u16m4	vnclipu_wx_u16m4
#define vnclipu_vx_u16m4_m	vnclipu_wx_u16m4_m
#define vnclipu_vx_u32m1	vnclipu_wx_u32m1
#define vnclipu_vx_u32m1_m	vnclipu_wx_u32m1_m
#define vnclipu_vx_u32m2	vnclipu_wx_u32m2
#define vnclipu_vx_u32m2_m	vnclipu_wx_u32m2_m
#define vnclipu_vx_u32m4	vnclipu_wx_u32m4
#define vnclipu_vx_u32m4_m	vnclipu_wx_u32m4_m

/* Wrapper only.  */
#define vnclip_vv_i8m1	vnclip_wv_i8m1
#define vnclip_vv_i8m1_m	vnclip_wv_i8m1_m
#define vnclip_vv_i8m2	vnclip_wv_i8m2
#define vnclip_vv_i8m2_m	vnclip_wv_i8m2_m
#define vnclip_vv_i8m4	vnclip_wv_i8m4
#define vnclip_vv_i8m4_m	vnclip_wv_i8m4_m
#define vnclip_vv_i16m1	vnclip_wv_i16m1
#define vnclip_vv_i16m1_m	vnclip_wv_i16m1_m
#define vnclip_vv_i16m2	vnclip_wv_i16m2
#define vnclip_vv_i16m2_m	vnclip_wv_i16m2_m
#define vnclip_vv_i16m4	vnclip_wv_i16m4
#define vnclip_vv_i16m4_m	vnclip_wv_i16m4_m
#define vnclip_vv_i32m1	vnclip_wv_i32m1
#define vnclip_vv_i32m1_m	vnclip_wv_i32m1_m
#define vnclip_vv_i32m2	vnclip_wv_i32m2
#define vnclip_vv_i32m2_m	vnclip_wv_i32m2_m
#define vnclip_vv_i32m4	vnclip_wv_i32m4
#define vnclip_vv_i32m4_m	vnclip_wv_i32m4_m

/* Wrapper only.  */
#define vnclip_vx_i8m1	vnclip_wx_i8m1
#define vnclip_vx_i8m1_m	vnclip_wx_i8m1_m
#define vnclip_vx_i8m2	vnclip_wx_i8m2
#define vnclip_vx_i8m2_m	vnclip_wx_i8m2_m
#define vnclip_vx_i8m4	vnclip_wx_i8m4
#define vnclip_vx_i8m4_m	vnclip_wx_i8m4_m
#define vnclip_vx_i16m1	vnclip_wx_i16m1
#define vnclip_vx_i16m1_m	vnclip_wx_i16m1_m
#define vnclip_vx_i16m2	vnclip_wx_i16m2
#define vnclip_vx_i16m2_m	vnclip_wx_i16m2_m
#define vnclip_vx_i16m4	vnclip_wx_i16m4
#define vnclip_vx_i16m4_m	vnclip_wx_i16m4_m
#define vnclip_vx_i32m1	vnclip_wx_i32m1
#define vnclip_vx_i32m1_m	vnclip_wx_i32m1_m
#define vnclip_vx_i32m2	vnclip_wx_i32m2
#define vnclip_vx_i32m2_m	vnclip_wx_i32m2_m
#define vnclip_vx_i32m4	vnclip_wx_i32m4
#define vnclip_vx_i32m4_m	vnclip_wx_i32m4_m

/* Wrapper only.  */
#define vfncvt_f_x_v_f16m1	vfncvt_f_x_w_f16m1
#define vfncvt_f_x_v_f16m1_m	vfncvt_f_x_w_f16m1_m
#define vfncvt_f_x_v_f16m2	vfncvt_f_x_w_f16m2
#define vfncvt_f_x_v_f16m2_m	vfncvt_f_x_w_f16m2_m
#define vfncvt_f_x_v_f16m4	vfncvt_f_x_w_f16m4
#define vfncvt_f_x_v_f16m4_m	vfncvt_f_x_w_f16m4_m
#define vfncvt_f_x_v_f32m1	vfncvt_f_x_w_f32m1
#define vfncvt_f_x_v_f32m1_m	vfncvt_f_x_w_f32m1_m
#define vfncvt_f_x_v_f32m2	vfncvt_f_x_w_f32m2
#define vfncvt_f_x_v_f32m2_m	vfncvt_f_x_w_f32m2_m
#define vfncvt_f_x_v_f32m4	vfncvt_f_x_w_f32m4
#define vfncvt_f_x_v_f32m4_m	vfncvt_f_x_w_f32m4_m

/* Wrapper only.  */
#define vfncvt_f_xu_v_f16m1	vfncvt_f_xu_w_f16m1
#define vfncvt_f_xu_v_f16m1_m	vfncvt_f_xu_w_f16m1_m
#define vfncvt_f_xu_v_f16m2	vfncvt_f_xu_w_f16m2
#define vfncvt_f_xu_v_f16m2_m	vfncvt_f_xu_w_f16m2_m
#define vfncvt_f_xu_v_f16m4	vfncvt_f_xu_w_f16m4
#define vfncvt_f_xu_v_f16m4_m	vfncvt_f_xu_w_f16m4_m
#define vfncvt_f_xu_v_f32m1	vfncvt_f_xu_w_f32m1
#define vfncvt_f_xu_v_f32m1_m	vfncvt_f_xu_w_f32m1_m
#define vfncvt_f_xu_v_f32m2	vfncvt_f_xu_w_f32m2
#define vfncvt_f_xu_v_f32m2_m	vfncvt_f_xu_w_f32m2_m
#define vfncvt_f_xu_v_f32m4	vfncvt_f_xu_w_f32m4
#define vfncvt_f_xu_v_f32m4_m	vfncvt_f_xu_w_f32m4_m

/* Wrapper only.  */
#define vfncvt_f_f_v_f16m1	vfncvt_f_f_w_f16m1
#define vfncvt_f_f_v_f16m1_m	vfncvt_f_f_w_f16m1_m
#define vfncvt_f_f_v_f16m2	vfncvt_f_f_w_f16m2
#define vfncvt_f_f_v_f16m2_m	vfncvt_f_f_w_f16m2_m
#define vfncvt_f_f_v_f16m4	vfncvt_f_f_w_f16m4
#define vfncvt_f_f_v_f16m4_m	vfncvt_f_f_w_f16m4_m
#define vfncvt_f_f_v_f32m1	vfncvt_f_f_w_f32m1
#define vfncvt_f_f_v_f32m1_m	vfncvt_f_f_w_f32m1_m
#define vfncvt_f_f_v_f32m2	vfncvt_f_f_w_f32m2
#define vfncvt_f_f_v_f32m2_m	vfncvt_f_f_w_f32m2_m
#define vfncvt_f_f_v_f32m4	vfncvt_f_f_w_f32m4
#define vfncvt_f_f_v_f32m4_m	vfncvt_f_f_w_f32m4_m

#endif
